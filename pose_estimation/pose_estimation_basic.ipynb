{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From Google: https://google.github.io/mediapipe/solutions/pose_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dverm\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import keras\n",
    "from tqdm.notebook import tqdm\n",
    "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
    "from mediapipe.python.solutions import pose as mp_pose\n",
    "import vg\n",
    "import itertools\n",
    "\n",
    "# network\n",
    "from keras.utils import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the dataset\n",
    "images_in_folder = \"referee_dataset\"\n",
    "\n",
    "# Folder containing the pictures with skeleton on top\n",
    "images_out_folder = \"referee_data_out_basic\"\n",
    "\n",
    "# output csv data\n",
    "csv_out_path = \"referee_data_out.csv\"\n",
    "\n",
    "# check if dataset is in directory\n",
    "assert os.path.exists(\"referee_dataset\"), \"No dataset in directory\"\n",
    "\n",
    "# make dirs if they do not exist\n",
    "os.makedirs(images_out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This function runs blaze pose on the dataset, storing the x y and z coords in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks():\n",
    "    if os.path.exists(csv_out_path):\n",
    "        return\n",
    "    with open(csv_out_path, \"w\", newline=\"\") as csv_out_file:\n",
    "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        # Folder names are used as pose class names.\n",
    "        pose_class_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
    "        \n",
    "        for pose_class_name in tqdm(pose_class_names, desc=\"Bootstrapping\\t\"):\n",
    "            if not os.path.exists(os.path.join(images_out_folder, pose_class_name)):\n",
    "                os.makedirs(os.path.join(images_out_folder, pose_class_name))\n",
    "\n",
    "            image_names = sorted([\n",
    "                n for n in os.listdir(os.path.join(images_in_folder, pose_class_name))\n",
    "                if not n.startswith('.')])\n",
    "            for image_name in tqdm(image_names, leave=False , desc=pose_class_name+\"\\t\"):\n",
    "                input_frame = cv2.imread(os.path.join(images_in_folder, pose_class_name, image_name))\n",
    "                input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Initialize fresh pose tracker and run it.\n",
    "                with mp_pose.Pose() as pose_tracker:\n",
    "                    result = pose_tracker.process(image=input_frame)\n",
    "                    pose_landmarks = result.pose_landmarks\n",
    "\n",
    "                # Save image with pose prediction (if pose was detected).\n",
    "                output_frame = input_frame.copy()\n",
    "                if pose_landmarks is not None:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=output_frame,\n",
    "                        landmark_list=pose_landmarks,\n",
    "                        connections=mp_pose.POSE_CONNECTIONS)\n",
    "                output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(os.path.join(images_out_folder, pose_class_name, image_name), output_frame)\n",
    "\n",
    "                # Save landmarks.\n",
    "                if pose_landmarks is not None:\n",
    "                    # Check the number of landmarks and take pose landmarks.\n",
    "                    assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
    "                    pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
    "\n",
    "                    # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
    "                    # correct aspect ratio.\n",
    "                    frame_height, frame_width = output_frame.shape[:2]\n",
    "                    pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
    "\n",
    "                    # Write pose sample to CSV.\n",
    "                    pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(str).tolist()\n",
    "                    csv_out_writer.writerow([image_name, pose_class_name] + pose_landmarks)\n",
    "                \n",
    "get_landmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While these landmarks can already work pretty well as features, I also tested some additional preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(data, i):\n",
    "    return data[i+2:i+5]\n",
    "\n",
    "def normalise(vector):\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def get_angle(data, a, b, c):\n",
    "    line_1 = get_position(data, a) - get_position(data, b)\n",
    "    line_2 = get_position(data, c) - get_position(data, b)\n",
    "    return vg.angle(line_1.astype(float), line_2.astype(float))\n",
    "\n",
    "def distance(p1, p2):\n",
    "    squared_dist = np.sum((p1-p2)**2, axis=0)\n",
    "    return np.sqrt(squared_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance based features\n",
    "def get_embedding_v1(data):\n",
    "    # restack data in 3d vectors & exclude face landmarks\n",
    "    data = np.reshape(data, (-1, 3))[11:]\n",
    "    \n",
    "    # get all distance combinations\n",
    "    embedding = np.array([vector - data[0] for vector in data])\n",
    "    \n",
    "    # normalise with hips distance\n",
    "    embedding /= embedding[0]\n",
    "    return embedding\n",
    "\n",
    "# angle based features\n",
    "def get_embedding_v2(data):\n",
    "    embedding = np.array([get_angle(data, 13, 11, 23),\n",
    "                          get_angle(data, 15, 13, 11),\n",
    "                          get_angle(data, 17, 15, 13),\n",
    "                          get_angle(data, 14, 12, 24),\n",
    "                          get_angle(data, 16, 14, 12),\n",
    "                          get_angle(data, 18, 16, 14),\n",
    "                         ])\n",
    "    return embedding\n",
    "\n",
    "# vector based features\n",
    "def get_embedding_v3(data):\n",
    "    embedding = np.array([normalise(get_position(data, 13) - get_position(data, 11)),\n",
    "                          normalise(get_position(data, 15) - get_position(data, 13)),\n",
    "                          normalise(get_position(data, 17) - get_position(data, 15)),\n",
    "                          normalise(get_position(data, 14) - get_position(data, 12)),\n",
    "                          normalise(get_position(data, 16) - get_position(data, 14)),\n",
    "                          normalise(get_position(data, 18) - get_position(data, 16)),\n",
    "    ])\n",
    "    return embedding.flatten()\n",
    "\n",
    "# distance based features\n",
    "def get_embedding_v4(data):\n",
    "    # restack data in 3d vectors & exclude face landmarks\n",
    "    data = np.reshape(data, (-1, 3))[11:]\n",
    "    \n",
    "    # get all distance combinations\n",
    "    embedding = np.array([distance(p1, p2) for p1, p2 in itertools.combinations(data, 2)])\n",
    "    \n",
    "    # normalise with hips distance\n",
    "    embedding /= embedding[0]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processes single feature row\n",
    "def embedder(version, feature_array):\n",
    "    if version == 0:\n",
    "        return feature_array\n",
    "    if version == 1:\n",
    "        return get_embedding_v1(feature_array)\n",
    "    elif version  == 2:\n",
    "        return get_embedding_v2(feature_array)\n",
    "    elif version  == 3:\n",
    "        return get_embedding_v2(feature_array)\n",
    "\n",
    "# Builds feature csv from landmark data\n",
    "def featurizer(version):\n",
    "    # return features csv if it already exist\n",
    "    feature_csv_name = \"pose_features_\"+ str(version) + \".csv\"\n",
    "    if os.path.exists(feature_csv_name):\n",
    "        return pd.read_csv(feature_csv_name, index_col=0, header=None)\n",
    "    \n",
    "    # load feature data & return dataframe if version = 0\n",
    "    landmark_data = pd.read_csv(\"referee_data_out.csv\", index_col=0, header=None)\n",
    "    if version == 0:\n",
    "        return landmark_data\n",
    "    \n",
    "    # write feature csv\n",
    "    with open(feature_csv_name, \"w\", newline=\"\") as csv_out_file:\n",
    "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        for row in landmark_data.iterrows():\n",
    "            embedding = embedder(version, np.array(row[1])[1:])\n",
    "            csv_out_writer.writerow(np.append([row[0], row[1][1]], embedding))       \n",
    "    return pd.read_csv(feature_csv_name, index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomise and split dataframe into X and Y\n",
    "def feature_target_split(df, shuffle=True):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac = 1)\n",
    "    \n",
    "    dataset = df.values\n",
    "    X = dataset[:,1:].astype(float)\n",
    "    \n",
    "    Y = dataset[:,0]\n",
    "    encoder = sklearn.preprocessing.LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "    Y = to_categorical(encoder.transform(Y))\n",
    "    return X, Y\n",
    "\n",
    "def kfold_index(df, k=5):\n",
    "    N = len(df)\n",
    "    minimum_number_of_points_per_slice = N // k\n",
    "    remaining_number_of_points = N % k\n",
    "    starting_point = 0\n",
    "    out = []\n",
    "    for islice in range(0, k):\n",
    "        end_point = starting_point + minimum_number_of_points_per_slice + ( islice < remaining_number_of_points )\n",
    "        out.append((starting_point, end_point))\n",
    "        starting_point = end_point\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_data = pd.read_csv(\"referee_data_out.csv\", index_col=0, header=None)\n",
    "label_count = len(mass_data[1].unique())\n",
    "id_to_pose = [pose for pose in mass_data[1].unique()]\n",
    "\n",
    "def two_layer_integrated(X):\n",
    "    inputs = Input(shape= (X.shape[1]-1,))\n",
    "    layer = Dense(256, activation=\"relu\")(inputs)\n",
    "    outputs = Dense(label_count, activation=\"sigmoid\")(layer)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(loss = \"binary_crossentropy\",optimizer = \"adam\",metrics = [\"acc\"])\n",
    "    mc = ModelCheckpoint(\"best_pose_model.hdf5\", monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "    return model, mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train(version, plot=True):\n",
    "    mass_data = featurizer(version)\n",
    "    \n",
    "    # train test split\n",
    "    X, Y = feature_target_split(mass_data)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, \n",
    "                                                        random_state=12, shuffle=True)\n",
    "    \n",
    "    # model training\n",
    "    model, model_checkpoint = two_layer_integrated(mass_data)\n",
    "    history = model.fit(X_train, Y_train ,epochs=500, callbacks=[model_checkpoint], batch_size=32, \n",
    "                        validation_data=(X_test, Y_test))\n",
    "\n",
    "    # load the best model weights\n",
    "    model.load_weights('best_pose_model.hdf5')\n",
    "    \n",
    "    # save model\n",
    "    model.save(\"pose_model_\" + str(version) + \".h5\")\n",
    "\n",
    "    # summarize history for loss\n",
    "    if plot:\n",
    "        plt.plot(history.history[\"acc\"])\n",
    "        plt.plot(history.history[\"val_acc\"])\n",
    "        plt.title(\"model accuracy\")\n",
    "        plt.ylabel(\"accuracy\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "        plt.show()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> source: https://www.youtube.com/watch?v=06TE_U21FK4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_live(version):\n",
    "    # load model\n",
    "    try:\n",
    "        model = keras.models.load_model(\"pose_model_\" + str(version) + \".h5\")\n",
    "    except:\n",
    "        model = train(version)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 3 * 200)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 4 * 200)\n",
    "    ## Setup mediapipe instance\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make detection\n",
    "            result = pose.process(image)\n",
    "            pose_landmarks = result.pose_landmarks\n",
    "\n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, result.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                     )            \n",
    "\n",
    "            # Save landmarks.\n",
    "            if pose_landmarks is not None:\n",
    "                # Check the number of landmarks and take pose landmarks.\n",
    "                assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
    "                pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
    "                frame_height, frame_width = image.shape[:2]\n",
    "                pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
    "                #pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(str).tolist()\n",
    "                pose_landmarks = np.around(pose_landmarks, 5).flatten()\n",
    "\n",
    "                # predicting\n",
    "                features = embedder(version, pose_landmarks)\n",
    "                #print(features)\n",
    "                features = np.expand_dims(features, axis=0).astype(float)\n",
    "                prediction_list = list(model.predict(features, verbose=0)[0])\n",
    "                prediction_id = prediction_list.index(max(prediction_list))\n",
    "\n",
    "                # show on screen\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                text = 'Pose Id: ' + id_to_pose[prediction_id] + \" \" + str(round(max(prediction_list)*100)) + \"%\"\n",
    "                cv2.putText(image, text, (50, 50), font, 1, (255, 0, 0),2, cv2.LINE_4)\n",
    "\n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "detect_live(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
