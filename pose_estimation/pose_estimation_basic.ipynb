{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From Google: https://google.github.io/mediapipe/solutions/pose_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 13:22:25.997968: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dacruon/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-06-21 13:22:25.997984: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# preprocessing \n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import keras\n",
    "from tqdm.notebook import tqdm\n",
    "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
    "from mediapipe.python.solutions import pose as mp_pose\n",
    "import vg\n",
    "import itertools\n",
    "\n",
    "# network\n",
    "from keras.utils import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the dataset\n",
    "images_in_folder = \"referee_dataset\"\n",
    "\n",
    "# Folder containing the pictures with skeleton on top\n",
    "images_out_folder = \"referee_data_out_basic\"\n",
    "\n",
    "# output csv data\n",
    "csv_out_path = \"referee_data_out.csv\"\n",
    "\n",
    "# check if dataset is in directory\n",
    "assert os.path.exists(\"referee_dataset\"), \"No dataset in directory\"\n",
    "\n",
    "# make dirs if they do not exist\n",
    "os.makedirs(images_out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This function runs blaze pose on the dataset, storing the x y and z coords in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks():\n",
    "    if os.path.exists(csv_out_path):\n",
    "        return\n",
    "    with open(csv_out_path, \"w\", newline=\"\") as csv_out_file:\n",
    "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        # Folder names are used as pose class names.\n",
    "        pose_class_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
    "        \n",
    "        for pose_class_name in tqdm(pose_class_names, desc=\"Bootstrapping\\t\"):\n",
    "            if not os.path.exists(os.path.join(images_out_folder, pose_class_name)):\n",
    "                os.makedirs(os.path.join(images_out_folder, pose_class_name))\n",
    "\n",
    "            image_names = sorted([\n",
    "                n for n in os.listdir(os.path.join(images_in_folder, pose_class_name))\n",
    "                if not n.startswith('.')])\n",
    "            for image_name in tqdm(image_names, leave=False , desc=pose_class_name+\"\\t\"):\n",
    "                input_frame = cv2.imread(os.path.join(images_in_folder, pose_class_name, image_name))\n",
    "                input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Initialize fresh pose tracker and run it.\n",
    "                with mp_pose.Pose() as pose_tracker:\n",
    "                    result = pose_tracker.process(image=input_frame)\n",
    "                    pose_landmarks = result.pose_landmarks\n",
    "\n",
    "                # Save image with pose prediction (if pose was detected).\n",
    "                output_frame = input_frame.copy()\n",
    "                if pose_landmarks is not None:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=output_frame,\n",
    "                        landmark_list=pose_landmarks,\n",
    "                        connections=mp_pose.POSE_CONNECTIONS)\n",
    "                output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(os.path.join(images_out_folder, pose_class_name, image_name), output_frame)\n",
    "\n",
    "                # Save landmarks.\n",
    "                if pose_landmarks is not None:\n",
    "                    # Check the number of landmarks and take pose landmarks.\n",
    "                    assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
    "                    pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
    "\n",
    "                    # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
    "                    # correct aspect ratio.\n",
    "                    frame_height, frame_width = output_frame.shape[:2]\n",
    "                    pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
    "\n",
    "                    # Write pose sample to CSV.\n",
    "                    pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(str).tolist()\n",
    "                    csv_out_writer.writerow([image_name, pose_class_name] + pose_landmarks)\n",
    "                \n",
    "get_landmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While these landmarks can already work pretty well as features, I also tested some additional preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(data, i):\n",
    "    return data[i+2:i+5]\n",
    "\n",
    "def normalise(vector):\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def get_angle(data, a, b, c):\n",
    "    line_1 = get_position(data, a) - get_position(data, b)\n",
    "    line_2 = get_position(data, c) - get_position(data, b)\n",
    "    return vg.angle(line_1.astype(float), line_2.astype(float))\n",
    "\n",
    "def distance(p1, p2):\n",
    "    return np.sqrt(np.sum((p1-p2)**2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance based features\n",
    "def get_embedding_v1(data):\n",
    "    # restack data in 3d vectors & exclude face landmarks\n",
    "    data = np.reshape(data, (-1, 3))[11:]\n",
    "    \n",
    "    # anchor all distances on left hip (origin)\n",
    "    embedding = np.array([vector - data[23-11] for vector in data])\n",
    "    \n",
    "    # normalise with hips distance\n",
    "    hip_distance = distance(embedding[23-11], embedding[24-11])\n",
    "    embedding = np.array([vector / hip_distance for vector in embedding])\n",
    "    \n",
    "    return embedding.flatten()\n",
    "\n",
    "# angle based features\n",
    "def get_embedding_v2(data):\n",
    "    embedding = np.array([get_angle(data, 13, 11, 23),\n",
    "                          get_angle(data, 15, 13, 11),\n",
    "                          get_angle(data, 17, 15, 13),\n",
    "                          get_angle(data, 14, 12, 24),\n",
    "                          get_angle(data, 16, 14, 12),\n",
    "                          get_angle(data, 18, 16, 14),\n",
    "                         ])\n",
    "    return embedding\n",
    "\n",
    "# vector based features\n",
    "def get_embedding_v3(data):\n",
    "    embedding = np.array([normalise(get_position(data, 13) - get_position(data, 11)),\n",
    "                          normalise(get_position(data, 15) - get_position(data, 13)),\n",
    "                          normalise(get_position(data, 17) - get_position(data, 15)),\n",
    "                          normalise(get_position(data, 14) - get_position(data, 12)),\n",
    "                          normalise(get_position(data, 16) - get_position(data, 14)),\n",
    "                          normalise(get_position(data, 18) - get_position(data, 16)),\n",
    "    ])\n",
    "    return embedding.flatten()\n",
    "\n",
    "# distance based features\n",
    "def get_embedding_v4(data):\n",
    "    # restack data in 3d vectors & exclude face landmarks\n",
    "    data = np.reshape(data, (-1, 3))[11:]\n",
    "    \n",
    "    # get all distance combinations\n",
    "    embedding = np.array([distance(p1, p2) for p1, p2 in itertools.combinations(data, 2)])\n",
    "    \n",
    "    # normalise with hips distance\n",
    "    embedding /= embedding[0]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processes single feature row\n",
    "def embedder(version, feature_array):\n",
    "    if version == 0:\n",
    "        return feature_array\n",
    "    if version == 1:\n",
    "        return get_embedding_v1(feature_array)\n",
    "    elif version  == 2:\n",
    "        return get_embedding_v2(feature_array)\n",
    "    elif version  == 3:\n",
    "        return get_embedding_v2(feature_array)\n",
    "\n",
    "# Builds feature csv from landmark data\n",
    "def featurizer(version):\n",
    "    # return features csv if it already exist\n",
    "    feature_csv_name = \"pose_features_\"+ str(version) + \".csv\"\n",
    "    if os.path.exists(feature_csv_name):\n",
    "        return pd.read_csv(feature_csv_name, index_col=0, header=None)\n",
    "    \n",
    "    # load feature data & return dataframe if version = 0\n",
    "    landmark_data = pd.read_csv(\"referee_data_out.csv\", index_col=0, header=None)\n",
    "    if version == 0:\n",
    "        return landmark_data\n",
    "    \n",
    "    # write feature csv\n",
    "    with open(feature_csv_name, \"w\", newline=\"\") as csv_out_file:\n",
    "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        for row in landmark_data.iterrows():\n",
    "            embedding = embedder(version, np.array(row[1])[1:])\n",
    "            csv_out_writer.writerow(np.append([row[0], row[1][1]], embedding))       \n",
    "    return pd.read_csv(feature_csv_name, index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomise and split dataframe into X and Y\n",
    "def feature_target_split(df, shuffle=True):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac = 1)\n",
    "    \n",
    "    dataset = df.values\n",
    "    X = dataset[:,1:].astype(float)\n",
    "    \n",
    "    Y = dataset[:,0]\n",
    "    encoder = sklearn.preprocessing.LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "    Y = to_categorical(encoder.transform(Y))\n",
    "    return X, Y\n",
    "\n",
    "def kfold_index(df, k=5):\n",
    "    N = len(df)\n",
    "    minimum_number_of_points_per_slice = N // k\n",
    "    remaining_number_of_points = N % k\n",
    "    starting_point = 0\n",
    "    out = []\n",
    "    for islice in range(0, k):\n",
    "        end_point = starting_point + minimum_number_of_points_per_slice + ( islice < remaining_number_of_points )\n",
    "        out.append((starting_point, end_point))\n",
    "        starting_point = end_point\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_data = pd.read_csv(\"referee_data_out.csv\", index_col=0, header=None)\n",
    "label_count = len(mass_data[1].unique())\n",
    "id_to_pose = [pose for pose in mass_data[1].unique()]\n",
    "\n",
    "def two_layer_integrated(X):\n",
    "    inputs = Input(shape= (X.shape[1]-1,))\n",
    "    layer = Dense(256, activation=\"relu\")(inputs)\n",
    "    outputs = Dense(label_count, activation=\"sigmoid\")(layer)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(loss = \"binary_crossentropy\",optimizer = \"adam\",metrics = [\"acc\"])\n",
    "    mc = ModelCheckpoint(\"best_pose_model.hdf5\", monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "    return model, mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train(version, plot=True):\n",
    "    mass_data = featurizer(version)\n",
    "    \n",
    "    # train test split\n",
    "    X, Y = feature_target_split(mass_data)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, \n",
    "                                                        random_state=12, shuffle=True)\n",
    "    \n",
    "    # model training\n",
    "    model, model_checkpoint = two_layer_integrated(mass_data)\n",
    "    history = model.fit(X_train, Y_train ,epochs=500, callbacks=[model_checkpoint], batch_size=32, \n",
    "                        validation_data=(X_test, Y_test))\n",
    "\n",
    "    # load the best model weights\n",
    "    model.load_weights('best_pose_model.hdf5')\n",
    "    \n",
    "    # save model\n",
    "    model.save(\"pose_model_\" + str(version) + \".h5\")\n",
    "\n",
    "    # summarize history for loss\n",
    "    if plot:\n",
    "        plt.plot(history.history[\"acc\"])\n",
    "        plt.plot(history.history[\"val_acc\"])\n",
    "        plt.title(\"model accuracy\")\n",
    "        plt.ylabel(\"accuracy\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "        plt.show()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> source: https://www.youtube.com/watch?v=06TE_U21FK4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/36 [..............................] - ETA: 8s - loss: 330.5668 - acc: 0.1875\n",
      "Epoch 1: val_loss improved from inf to 8.96896, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 51.9494 - acc: 0.2744 - val_loss: 8.9690 - val_acc: 0.5106\n",
      "Epoch 2/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 10.3018 - acc: 0.5000\n",
      "Epoch 2: val_loss improved from 8.96896 to 4.08307, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.9520 - acc: 0.5497 - val_loss: 4.0831 - val_acc: 0.6064\n",
      "Epoch 3/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 5.2999 - acc: 0.5625\n",
      "Epoch 3: val_loss improved from 4.08307 to 3.41861, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.8779 - acc: 0.6883 - val_loss: 3.4186 - val_acc: 0.6773\n",
      "Epoch 4/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.8668 - acc: 0.6875\n",
      "Epoch 4: val_loss improved from 3.41861 to 2.33652, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 2.3986 - acc: 0.7904 - val_loss: 2.3365 - val_acc: 0.7979\n",
      "Epoch 5/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.6447 - acc: 0.7500\n",
      "Epoch 5: val_loss did not improve from 2.33652\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.9692 - acc: 0.7886 - val_loss: 2.6425 - val_acc: 0.7270\n",
      "Epoch 6/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.0895 - acc: 0.6875\n",
      "Epoch 6: val_loss improved from 2.33652 to 1.27661, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 2.0514 - acc: 0.8242 - val_loss: 1.2766 - val_acc: 0.8475\n",
      "Epoch 7/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.8727 - acc: 0.8750\n",
      "Epoch 7: val_loss did not improve from 1.27661\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.5977 - acc: 0.8455 - val_loss: 2.5328 - val_acc: 0.7660\n",
      "Epoch 8/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.6870 - acc: 0.8438\n",
      "Epoch 8: val_loss did not improve from 1.27661\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.8119 - acc: 0.8064 - val_loss: 3.9265 - val_acc: 0.7021\n",
      "Epoch 9/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.6195 - acc: 0.5938\n",
      "Epoch 9: val_loss did not improve from 1.27661\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 2.4795 - acc: 0.7957 - val_loss: 3.1098 - val_acc: 0.7979\n",
      "Epoch 10/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.7629 - acc: 0.8750\n",
      "Epoch 10: val_loss improved from 1.27661 to 1.00189, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 2.0520 - acc: 0.8330 - val_loss: 1.0019 - val_acc: 0.8759\n",
      "Epoch 11/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3115 - acc: 0.9688\n",
      "Epoch 11: val_loss did not improve from 1.00189\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.3014 - acc: 0.8845 - val_loss: 1.2005 - val_acc: 0.8404\n",
      "Epoch 12/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3088 - acc: 1.0000\n",
      "Epoch 12: val_loss did not improve from 1.00189\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.4163 - acc: 0.8721 - val_loss: 1.1892 - val_acc: 0.8617\n",
      "Epoch 13/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.8396 - acc: 0.8750\n",
      "Epoch 13: val_loss improved from 1.00189 to 0.78998, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.2556 - acc: 0.8917 - val_loss: 0.7900 - val_acc: 0.9043\n",
      "Epoch 14/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3364 - acc: 0.9688\n",
      "Epoch 14: val_loss improved from 0.78998 to 0.62036, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8784 - acc: 0.9059 - val_loss: 0.6204 - val_acc: 0.9468\n",
      "Epoch 15/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.8678 - acc: 0.9375\n",
      "Epoch 15: val_loss improved from 0.62036 to 0.42947, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0138 - acc: 0.9139 - val_loss: 0.4295 - val_acc: 0.9362\n",
      "Epoch 16/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1137 - acc: 0.9375\n",
      "Epoch 16: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8698 - acc: 0.9174 - val_loss: 3.1485 - val_acc: 0.8121\n",
      "Epoch 17/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.7406 - acc: 0.8438\n",
      "Epoch 17: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.7124 - acc: 0.8481 - val_loss: 1.9169 - val_acc: 0.8014\n",
      "Epoch 18/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.0287 - acc: 0.7500\n",
      "Epoch 18: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.8667 - acc: 0.8526 - val_loss: 1.1344 - val_acc: 0.9255\n",
      "Epoch 19/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3336 - acc: 1.0000\n",
      "Epoch 19: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9376 - acc: 0.9121 - val_loss: 1.3881 - val_acc: 0.8298\n",
      "Epoch 20/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.5249 - acc: 0.9375\n",
      "Epoch 20: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.2057 - acc: 0.8837 - val_loss: 1.5532 - val_acc: 0.8404\n",
      "Epoch 21/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.0948 - acc: 0.7812\n",
      "Epoch 21: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.4405 - acc: 0.8872 - val_loss: 0.9741 - val_acc: 0.8652\n",
      "Epoch 22/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4470 - acc: 0.9688\n",
      "Epoch 22: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9643 - acc: 0.9263 - val_loss: 0.9437 - val_acc: 0.8936\n",
      "Epoch 23/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.8461 - acc: 0.9062\n",
      "Epoch 23: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0302 - acc: 0.9254 - val_loss: 0.6399 - val_acc: 0.9504\n",
      "Epoch 24/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4321 - acc: 0.9688\n",
      "Epoch 24: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6098 - acc: 0.9547 - val_loss: 2.2415 - val_acc: 0.8191\n",
      "Epoch 25/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.8146 - acc: 0.8750\n",
      "Epoch 25: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.6821 - acc: 0.8961 - val_loss: 0.8266 - val_acc: 0.8972\n",
      "Epoch 26/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.8062 - acc: 0.9688\n",
      "Epoch 26: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6084 - acc: 0.9467 - val_loss: 0.5181 - val_acc: 0.9397\n",
      "Epoch 27/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2599 - acc: 0.9688\n",
      "Epoch 27: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7139 - acc: 0.9361 - val_loss: 0.6715 - val_acc: 0.9255\n",
      "Epoch 28/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.9091 - acc: 0.9375\n",
      "Epoch 28: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7056 - acc: 0.9476 - val_loss: 0.5141 - val_acc: 0.9291\n",
      "Epoch 29/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2281 - acc: 1.0000\n",
      "Epoch 29: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6177 - acc: 0.9467 - val_loss: 0.9425 - val_acc: 0.9113\n",
      "Epoch 30/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.5140 - acc: 0.9375\n",
      "Epoch 30: val_loss did not improve from 0.42947\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9191 - acc: 0.9236 - val_loss: 1.0689 - val_acc: 0.9291\n",
      "Epoch 31/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.8842 - acc: 1.0000\n",
      "Epoch 31: val_loss did not improve from 0.42947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5036 - acc: 0.9583 - val_loss: 0.8136 - val_acc: 0.9468\n",
      "Epoch 32/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.6071 - acc: 0.9688\n",
      "Epoch 32: val_loss improved from 0.42947 to 0.37970, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9433 - acc: 0.9307 - val_loss: 0.3797 - val_acc: 0.9645\n",
      "Epoch 33/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2097 - acc: 0.9375\n",
      "Epoch 33: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.5741 - acc: 0.8890 - val_loss: 1.4216 - val_acc: 0.9220\n",
      "Epoch 34/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.9863 - acc: 0.8750\n",
      "Epoch 34: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.2113 - acc: 0.9236 - val_loss: 3.2034 - val_acc: 0.8830\n",
      "Epoch 35/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.9630 - acc: 0.8750\n",
      "Epoch 35: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0824 - acc: 0.9290 - val_loss: 0.4849 - val_acc: 0.9433\n",
      "Epoch 36/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4545 - acc: 0.9688\n",
      "Epoch 36: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4300 - acc: 0.9680 - val_loss: 0.5173 - val_acc: 0.9362\n",
      "Epoch 37/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4149 - acc: 0.9688\n",
      "Epoch 37: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5310 - acc: 0.9529 - val_loss: 0.6540 - val_acc: 0.9468\n",
      "Epoch 38/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4396 - acc: 0.9688\n",
      "Epoch 38: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4395 - acc: 0.9663 - val_loss: 1.0436 - val_acc: 0.9291\n",
      "Epoch 39/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.7492 - acc: 0.9688\n",
      "Epoch 39: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.6020 - acc: 0.9103 - val_loss: 2.3209 - val_acc: 0.8936\n",
      "Epoch 40/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 6.7000 - acc: 0.7188\n",
      "Epoch 40: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1237 - acc: 0.9254 - val_loss: 1.4572 - val_acc: 0.9291\n",
      "Epoch 41/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.2163 - acc: 0.9375\n",
      "Epoch 41: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7556 - acc: 0.9476 - val_loss: 0.6080 - val_acc: 0.9504\n",
      "Epoch 42/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2837 - acc: 0.9688\n",
      "Epoch 42: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5957 - acc: 0.9556 - val_loss: 3.0910 - val_acc: 0.8298\n",
      "Epoch 43/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.2004 - acc: 0.8438\n",
      "Epoch 43: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.5091 - acc: 0.8943 - val_loss: 3.0259 - val_acc: 0.8652\n",
      "Epoch 44/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.7861 - acc: 0.9062\n",
      "Epoch 44: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.4106 - acc: 0.9085 - val_loss: 0.5135 - val_acc: 0.9539\n",
      "Epoch 45/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.7004 - acc: 0.9688\n",
      "Epoch 45: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5844 - acc: 0.9636 - val_loss: 0.6363 - val_acc: 0.9539\n",
      "Epoch 46/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.6143 - acc: 0.9375\n",
      "Epoch 46: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.5504 - acc: 0.9094 - val_loss: 1.4696 - val_acc: 0.8582\n",
      "Epoch 47/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.1144 - acc: 0.9062\n",
      "Epoch 47: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9082 - acc: 0.9503 - val_loss: 0.6994 - val_acc: 0.9468\n",
      "Epoch 48/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2313 - acc: 0.9688\n",
      "Epoch 48: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8462 - acc: 0.9272 - val_loss: 0.5347 - val_acc: 0.9504\n",
      "Epoch 49/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3378 - acc: 0.9375\n",
      "Epoch 49: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5910 - acc: 0.9432 - val_loss: 0.5603 - val_acc: 0.9326\n",
      "Epoch 50/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.6189 - acc: 0.9375\n",
      "Epoch 50: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5281 - acc: 0.9645 - val_loss: 0.4926 - val_acc: 0.9610\n",
      "Epoch 51/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1980 - acc: 1.0000\n",
      "Epoch 51: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7701 - acc: 0.9494 - val_loss: 0.7281 - val_acc: 0.8901\n",
      "Epoch 52/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1066 - acc: 1.0000\n",
      "Epoch 52: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6618 - acc: 0.9414 - val_loss: 0.4984 - val_acc: 0.9468\n",
      "Epoch 53/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.5010 - acc: 0.9688\n",
      "Epoch 53: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6755 - acc: 0.9538 - val_loss: 0.9516 - val_acc: 0.9113\n",
      "Epoch 54/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.8039 - acc: 0.9062\n",
      "Epoch 54: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8618 - acc: 0.9414 - val_loss: 0.9835 - val_acc: 0.9504\n",
      "Epoch 55/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.9918 - acc: 0.9688\n",
      "Epoch 55: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9695 - acc: 0.9378 - val_loss: 1.1184 - val_acc: 0.9043\n",
      "Epoch 56/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.1320 - acc: 0.9062\n",
      "Epoch 56: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0514 - acc: 0.9325 - val_loss: 0.4449 - val_acc: 0.9539\n",
      "Epoch 57/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.7689 - acc: 0.9375\n",
      "Epoch 57: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5119 - acc: 0.9618 - val_loss: 0.6076 - val_acc: 0.9574\n",
      "Epoch 58/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.9113 - acc: 0.9375\n",
      "Epoch 58: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6121 - acc: 0.9485 - val_loss: 0.4642 - val_acc: 0.9504\n",
      "Epoch 59/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0523 - acc: 1.0000\n",
      "Epoch 59: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5343 - acc: 0.9591 - val_loss: 0.3850 - val_acc: 0.9433\n",
      "Epoch 60/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.6270 - acc: 0.9062\n",
      "Epoch 60: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5730 - acc: 0.9609 - val_loss: 0.4455 - val_acc: 0.9610\n",
      "Epoch 61/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4462 - acc: 0.9688\n",
      "Epoch 61: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8914 - acc: 0.9325 - val_loss: 0.5148 - val_acc: 0.9504\n",
      "Epoch 62/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0944 - acc: 1.0000\n",
      "Epoch 62: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3255 - acc: 0.9734 - val_loss: 0.8998 - val_acc: 0.9574\n",
      "Epoch 63/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/36 [..............................] - ETA: 0s - loss: 0.6218 - acc: 1.0000\n",
      "Epoch 63: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4111 - acc: 0.9663 - val_loss: 0.4529 - val_acc: 0.9504\n",
      "Epoch 64/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4400 - acc: 0.9375\n",
      "Epoch 64: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3506 - acc: 0.9716 - val_loss: 0.6520 - val_acc: 0.9716\n",
      "Epoch 65/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4755 - acc: 1.0000\n",
      "Epoch 65: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4262 - acc: 0.9725 - val_loss: 0.7180 - val_acc: 0.9291\n",
      "Epoch 66/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.9131 - acc: 0.9062\n",
      "Epoch 66: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3775 - acc: 0.9698 - val_loss: 0.4507 - val_acc: 0.9610\n",
      "Epoch 67/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.7425 - acc: 0.8750\n",
      "Epoch 67: val_loss did not improve from 0.37970\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3683 - acc: 0.9734 - val_loss: 0.5364 - val_acc: 0.9610\n",
      "Epoch 68/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3768 - acc: 0.9688\n",
      "Epoch 68: val_loss improved from 0.37970 to 0.28420, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2317 - acc: 0.9796 - val_loss: 0.2842 - val_acc: 0.9716\n",
      "Epoch 69/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0414 - acc: 1.0000\n",
      "Epoch 69: val_loss did not improve from 0.28420\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5347 - acc: 0.9645 - val_loss: 0.9832 - val_acc: 0.9043\n",
      "Epoch 70/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.0372 - acc: 0.9375\n",
      "Epoch 70: val_loss improved from 0.28420 to 0.28283, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3724 - acc: 0.9760 - val_loss: 0.2828 - val_acc: 0.9645\n",
      "Epoch 71/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2110 - acc: 0.9688\n",
      "Epoch 71: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2632 - acc: 0.9796 - val_loss: 0.5151 - val_acc: 0.9787\n",
      "Epoch 72/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1233 - acc: 1.0000\n",
      "Epoch 72: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4455 - acc: 0.9671 - val_loss: 0.3862 - val_acc: 0.9752\n",
      "Epoch 73/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 73: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2790 - acc: 0.9751 - val_loss: 1.3452 - val_acc: 0.9184\n",
      "Epoch 74/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.5268 - acc: 0.9688\n",
      "Epoch 74: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5353 - acc: 0.9654 - val_loss: 0.4759 - val_acc: 0.9645\n",
      "Epoch 75/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1062 - acc: 1.0000\n",
      "Epoch 75: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2028 - acc: 0.9858 - val_loss: 0.5444 - val_acc: 0.9362\n",
      "Epoch 76/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4384 - acc: 0.9062\n",
      "Epoch 76: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3635 - acc: 0.9778 - val_loss: 0.4855 - val_acc: 0.9433\n",
      "Epoch 77/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2071 - acc: 1.0000\n",
      "Epoch 77: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3806 - acc: 0.9742 - val_loss: 0.4822 - val_acc: 0.9610\n",
      "Epoch 78/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.9530 - acc: 0.9688\n",
      "Epoch 78: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2626 - acc: 0.9796 - val_loss: 0.7757 - val_acc: 0.9362\n",
      "Epoch 79/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.2853 - acc: 0.9062\n",
      "Epoch 79: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7826 - acc: 0.9583 - val_loss: 0.4786 - val_acc: 0.9716\n",
      "Epoch 80/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1850 - acc: 0.9688\n",
      "Epoch 80: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2076 - acc: 0.9805 - val_loss: 0.7405 - val_acc: 0.9539\n",
      "Epoch 81/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2209 - acc: 1.0000\n",
      "Epoch 81: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - acc: 0.9716 - val_loss: 0.3161 - val_acc: 0.9823\n",
      "Epoch 82/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 82: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4622 - acc: 0.9769 - val_loss: 0.3508 - val_acc: 0.9681\n",
      "Epoch 83/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2191 - acc: 0.9688\n",
      "Epoch 83: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1549 - acc: 0.9876 - val_loss: 0.9859 - val_acc: 0.9397\n",
      "Epoch 84/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1956 - acc: 1.0000\n",
      "Epoch 84: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7591 - acc: 0.9485 - val_loss: 1.1159 - val_acc: 0.9113\n",
      "Epoch 85/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3202 - acc: 1.0000\n",
      "Epoch 85: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6650 - acc: 0.9520 - val_loss: 0.4187 - val_acc: 0.9610\n",
      "Epoch 86/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2100 - acc: 0.9688\n",
      "Epoch 86: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3340 - acc: 0.9742 - val_loss: 0.7707 - val_acc: 0.9433\n",
      "Epoch 87/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.8183 - acc: 1.0000\n",
      "Epoch 87: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3315 - acc: 0.9734 - val_loss: 0.9716 - val_acc: 0.9468\n",
      "Epoch 88/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4729 - acc: 1.0000\n",
      "Epoch 88: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4810 - acc: 0.9565 - val_loss: 1.5209 - val_acc: 0.9043\n",
      "Epoch 89/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.5843 - acc: 0.9062\n",
      "Epoch 89: val_loss did not improve from 0.28283\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6733 - acc: 0.9636 - val_loss: 0.4310 - val_acc: 0.9433\n",
      "Epoch 90/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1508 - acc: 0.9688\n",
      "Epoch 90: val_loss improved from 0.28283 to 0.16147, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3870 - acc: 0.9707 - val_loss: 0.1615 - val_acc: 0.9752\n",
      "Epoch 91/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.5592e-04 - acc: 1.0000\n",
      "Epoch 91: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1978 - acc: 0.9902 - val_loss: 0.6755 - val_acc: 0.9574\n",
      "Epoch 92/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2085 - acc: 1.0000\n",
      "Epoch 92: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2928 - acc: 0.9805 - val_loss: 0.3744 - val_acc: 0.9752\n",
      "Epoch 93/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1813 - acc: 1.0000\n",
      "Epoch 93: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4585 - acc: 0.9707 - val_loss: 0.8098 - val_acc: 0.9504\n",
      "Epoch 94/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/36 [..............................] - ETA: 0s - loss: 0.9115 - acc: 0.9062\n",
      "Epoch 94: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4799 - acc: 0.9707 - val_loss: 0.5222 - val_acc: 0.9504\n",
      "Epoch 95/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2163 - acc: 1.0000\n",
      "Epoch 95: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3858 - acc: 0.9787 - val_loss: 0.5625 - val_acc: 0.9539\n",
      "Epoch 96/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0970 - acc: 1.0000\n",
      "Epoch 96: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2926 - acc: 0.9751 - val_loss: 0.5145 - val_acc: 0.9362\n",
      "Epoch 97/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3576 - acc: 1.0000\n",
      "Epoch 97: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5673 - acc: 0.9583 - val_loss: 0.2043 - val_acc: 0.9858\n",
      "Epoch 98/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3495 - acc: 1.0000\n",
      "Epoch 98: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5644 - acc: 0.9698 - val_loss: 0.4380 - val_acc: 0.9716\n",
      "Epoch 99/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2764 - acc: 1.0000\n",
      "Epoch 99: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3247 - acc: 0.9831 - val_loss: 1.0610 - val_acc: 0.9574\n",
      "Epoch 100/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.6976 - acc: 1.0000\n",
      "Epoch 100: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3230 - acc: 0.9707 - val_loss: 0.4274 - val_acc: 0.9681\n",
      "Epoch 101/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2094 - acc: 0.9062\n",
      "Epoch 101: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1792 - acc: 0.9858 - val_loss: 0.9215 - val_acc: 0.9184\n",
      "Epoch 102/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4499 - acc: 1.0000\n",
      "Epoch 102: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2164 - acc: 0.9858 - val_loss: 0.3639 - val_acc: 0.9681\n",
      "Epoch 103/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1341 - acc: 0.9688\n",
      "Epoch 103: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3140 - acc: 0.9716 - val_loss: 1.0712 - val_acc: 0.9149\n",
      "Epoch 104/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.8922 - acc: 0.9688\n",
      "Epoch 104: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8236 - acc: 0.9538 - val_loss: 0.8411 - val_acc: 0.9433\n",
      "Epoch 105/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.9488 - acc: 0.9375\n",
      "Epoch 105: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5509 - acc: 0.9680 - val_loss: 0.3125 - val_acc: 0.9645\n",
      "Epoch 106/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0708 - acc: 0.9688\n",
      "Epoch 106: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6134 - acc: 0.9636 - val_loss: 0.6055 - val_acc: 0.9645\n",
      "Epoch 107/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0593 - acc: 1.0000\n",
      "Epoch 107: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4028 - acc: 0.9725 - val_loss: 0.4009 - val_acc: 0.9433\n",
      "Epoch 108/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.9397 - acc: 0.9062\n",
      "Epoch 108: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3072 - acc: 0.9671 - val_loss: 0.3051 - val_acc: 0.9752\n",
      "Epoch 109/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1536 - acc: 1.0000\n",
      "Epoch 109: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4937 - acc: 0.9680 - val_loss: 0.3445 - val_acc: 0.9645\n",
      "Epoch 110/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2637 - acc: 0.9688\n",
      "Epoch 110: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3246 - acc: 0.9787 - val_loss: 0.3712 - val_acc: 0.9681\n",
      "Epoch 111/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 111: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1857 - acc: 0.9840 - val_loss: 0.4497 - val_acc: 0.9539\n",
      "Epoch 112/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1318 - acc: 1.0000\n",
      "Epoch 112: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2128 - acc: 0.9885 - val_loss: 0.5324 - val_acc: 0.9539\n",
      "Epoch 113/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1130 - acc: 1.0000\n",
      "Epoch 113: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1482 - acc: 0.9911 - val_loss: 0.2487 - val_acc: 0.9681\n",
      "Epoch 114/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.0449e-17 - acc: 1.0000\n",
      "Epoch 114: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3338 - acc: 0.9787 - val_loss: 0.5004 - val_acc: 0.9645\n",
      "Epoch 115/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2994 - acc: 1.0000\n",
      "Epoch 115: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1754 - acc: 0.9840 - val_loss: 0.5133 - val_acc: 0.9645\n",
      "Epoch 116/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1404 - acc: 1.0000\n",
      "Epoch 116: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1638 - acc: 0.9858 - val_loss: 0.6632 - val_acc: 0.9397\n",
      "Epoch 117/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 117: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4283 - acc: 0.9574 - val_loss: 1.4848 - val_acc: 0.8901\n",
      "Epoch 118/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.5228 - acc: 0.9062\n",
      "Epoch 118: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6731 - acc: 0.9369 - val_loss: 0.7333 - val_acc: 0.9610\n",
      "Epoch 119/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.5637 - acc: 1.0000\n",
      "Epoch 119: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6724 - acc: 0.9538 - val_loss: 0.3488 - val_acc: 0.9681\n",
      "Epoch 120/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0788 - acc: 1.0000\n",
      "Epoch 120: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2904 - acc: 0.9742 - val_loss: 0.3805 - val_acc: 0.9752\n",
      "Epoch 121/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1746 - acc: 1.0000\n",
      "Epoch 121: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1336 - acc: 0.9893 - val_loss: 0.2278 - val_acc: 0.9681\n",
      "Epoch 122/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0491 - acc: 0.9688\n",
      "Epoch 122: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1735 - acc: 0.9893 - val_loss: 0.2737 - val_acc: 0.9823\n",
      "Epoch 123/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0683 - acc: 1.0000\n",
      "Epoch 123: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4447 - acc: 0.9734 - val_loss: 0.2117 - val_acc: 0.9858\n",
      "Epoch 124/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0589 - acc: 1.0000\n",
      "Epoch 124: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1446 - acc: 0.9840 - val_loss: 0.2576 - val_acc: 0.9645\n",
      "Epoch 125/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0439 - acc: 1.0000\n",
      "Epoch 125: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2814 - acc: 0.9742 - val_loss: 0.5249 - val_acc: 0.9539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.6428e-07 - acc: 1.0000\n",
      "Epoch 126: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2078 - acc: 0.9885 - val_loss: 0.3975 - val_acc: 0.9716\n",
      "Epoch 127/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1260 - acc: 1.0000\n",
      "Epoch 127: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1570 - acc: 0.9876 - val_loss: 0.3895 - val_acc: 0.9681\n",
      "Epoch 128/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1361 - acc: 1.0000\n",
      "Epoch 128: val_loss did not improve from 0.16147\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2237 - acc: 0.9822 - val_loss: 0.2662 - val_acc: 0.9752\n",
      "Epoch 129/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 129: val_loss improved from 0.16147 to 0.15468, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2088 - acc: 0.9787 - val_loss: 0.1547 - val_acc: 0.9787\n",
      "Epoch 130/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1442 - acc: 1.0000\n",
      "Epoch 130: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1589 - acc: 0.9849 - val_loss: 0.2552 - val_acc: 0.9787\n",
      "Epoch 131/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 131: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1544 - acc: 0.9867 - val_loss: 0.3234 - val_acc: 0.9681\n",
      "Epoch 132/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 132: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1336 - acc: 0.9831 - val_loss: 0.2862 - val_acc: 0.9645\n",
      "Epoch 133/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 133: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2856 - acc: 0.9778 - val_loss: 0.5585 - val_acc: 0.9504\n",
      "Epoch 134/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1632 - acc: 1.0000\n",
      "Epoch 134: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4355 - acc: 0.9698 - val_loss: 2.0322 - val_acc: 0.8617\n",
      "Epoch 135/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.9661 - acc: 0.8125\n",
      "Epoch 135: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4204 - acc: 0.9663 - val_loss: 0.4342 - val_acc: 0.9645\n",
      "Epoch 136/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4984 - acc: 0.9688\n",
      "Epoch 136: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2188 - acc: 0.9796 - val_loss: 0.7198 - val_acc: 0.9255\n",
      "Epoch 137/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.7973 - acc: 0.9375\n",
      "Epoch 137: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2343 - acc: 0.9796 - val_loss: 0.7716 - val_acc: 0.9184\n",
      "Epoch 138/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1550 - acc: 1.0000\n",
      "Epoch 138: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3556 - acc: 0.9618 - val_loss: 0.4016 - val_acc: 0.9574\n",
      "Epoch 139/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1249 - acc: 1.0000\n",
      "Epoch 139: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4653 - acc: 0.9618 - val_loss: 0.4143 - val_acc: 0.9645\n",
      "Epoch 140/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.8753 - acc: 0.9375\n",
      "Epoch 140: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2897 - acc: 0.9787 - val_loss: 0.2937 - val_acc: 0.9716\n",
      "Epoch 141/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0980 - acc: 1.0000\n",
      "Epoch 141: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4840 - acc: 0.9680 - val_loss: 1.0417 - val_acc: 0.9326\n",
      "Epoch 142/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.1226 - acc: 0.9062\n",
      "Epoch 142: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4880 - acc: 0.9574 - val_loss: 0.2520 - val_acc: 0.9574\n",
      "Epoch 143/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1492 - acc: 1.0000\n",
      "Epoch 143: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5682 - acc: 0.9538 - val_loss: 0.3767 - val_acc: 0.9397\n",
      "Epoch 144/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1858 - acc: 0.9688\n",
      "Epoch 144: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3419 - acc: 0.9689 - val_loss: 0.3515 - val_acc: 0.9645\n",
      "Epoch 145/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.1385e-07 - acc: 1.0000\n",
      "Epoch 145: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1122 - acc: 0.9893 - val_loss: 0.2112 - val_acc: 0.9645\n",
      "Epoch 146/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 7.9455e-05 - acc: 1.0000\n",
      "Epoch 146: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0837 - acc: 0.9893 - val_loss: 0.3376 - val_acc: 0.9787\n",
      "Epoch 147/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 147: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1829 - acc: 0.9858 - val_loss: 0.3513 - val_acc: 0.9539\n",
      "Epoch 148/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.5655e-06 - acc: 1.0000\n",
      "Epoch 148: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0915 - acc: 0.9911 - val_loss: 0.1852 - val_acc: 0.9752\n",
      "Epoch 149/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.1260e-06 - acc: 1.0000\n",
      "Epoch 149: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0795 - acc: 0.9876 - val_loss: 0.3012 - val_acc: 0.9645\n",
      "Epoch 150/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.2972e-09 - acc: 1.0000\n",
      "Epoch 150: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0908 - acc: 0.9902 - val_loss: 0.3223 - val_acc: 0.9681\n",
      "Epoch 151/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0798 - acc: 1.0000\n",
      "Epoch 151: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0609 - acc: 0.9929 - val_loss: 0.1935 - val_acc: 0.9716\n",
      "Epoch 152/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1763 - acc: 0.9688\n",
      "Epoch 152: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1194 - acc: 0.9858 - val_loss: 0.3205 - val_acc: 0.9610\n",
      "Epoch 153/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1901 - acc: 0.9688\n",
      "Epoch 153: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1011 - acc: 0.9876 - val_loss: 0.2897 - val_acc: 0.9645\n",
      "Epoch 154/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 154: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1079 - acc: 0.9885 - val_loss: 0.2994 - val_acc: 0.9752\n",
      "Epoch 155/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 155: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2381 - acc: 0.9778 - val_loss: 0.4495 - val_acc: 0.9504\n",
      "Epoch 156/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0677 - acc: 0.9688\n",
      "Epoch 156: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1900 - acc: 0.9840 - val_loss: 0.1840 - val_acc: 0.9752\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/36 [..............................] - ETA: 0s - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 157: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0646 - acc: 0.9964 - val_loss: 0.2023 - val_acc: 0.9752\n",
      "Epoch 158/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 158: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0831 - acc: 0.9938 - val_loss: 0.2015 - val_acc: 0.9752\n",
      "Epoch 159/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.1727e-09 - acc: 1.0000\n",
      "Epoch 159: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0596 - acc: 0.9929 - val_loss: 0.2301 - val_acc: 0.9716\n",
      "Epoch 160/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 160: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1599 - acc: 0.9893 - val_loss: 0.2192 - val_acc: 0.9787\n",
      "Epoch 161/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0654 - acc: 1.0000\n",
      "Epoch 161: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1281 - acc: 0.9902 - val_loss: 0.1737 - val_acc: 0.9716\n",
      "Epoch 162/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0953 - acc: 1.0000\n",
      "Epoch 162: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2425 - acc: 0.9707 - val_loss: 0.4897 - val_acc: 0.9539\n",
      "Epoch 163/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4140 - acc: 0.9375\n",
      "Epoch 163: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2403 - acc: 0.9698 - val_loss: 0.1738 - val_acc: 0.9823\n",
      "Epoch 164/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0880 - acc: 1.0000\n",
      "Epoch 164: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1076 - acc: 0.9849 - val_loss: 0.2765 - val_acc: 0.9681\n",
      "Epoch 165/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.7899e-04 - acc: 1.0000\n",
      "Epoch 165: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1501 - acc: 0.9822 - val_loss: 0.2030 - val_acc: 0.9858\n",
      "Epoch 166/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 166: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1623 - acc: 0.9822 - val_loss: 1.6987 - val_acc: 0.8830\n",
      "Epoch 167/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.2530 - acc: 0.8438\n",
      "Epoch 167: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4217 - acc: 0.9671 - val_loss: 0.1558 - val_acc: 0.9823\n",
      "Epoch 168/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1703 - acc: 1.0000\n",
      "Epoch 168: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1246 - acc: 0.9858 - val_loss: 0.1709 - val_acc: 0.9787\n",
      "Epoch 169/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 169: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0927 - acc: 0.9893 - val_loss: 0.2268 - val_acc: 0.9787\n",
      "Epoch 170/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 170: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0746 - acc: 0.9885 - val_loss: 0.2102 - val_acc: 0.9681\n",
      "Epoch 171/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 171: val_loss did not improve from 0.15468\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0466 - acc: 0.9964 - val_loss: 0.1596 - val_acc: 0.9858\n",
      "Epoch 172/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1063 - acc: 0.9688\n",
      "Epoch 172: val_loss improved from 0.15468 to 0.15143, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1381 - acc: 0.9849 - val_loss: 0.1514 - val_acc: 0.9929\n",
      "Epoch 173/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 6.5423e-13 - acc: 1.0000\n",
      "Epoch 173: val_loss did not improve from 0.15143\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0649 - acc: 0.9956 - val_loss: 0.2639 - val_acc: 0.9681\n",
      "Epoch 174/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1785 - acc: 0.9688\n",
      "Epoch 174: val_loss improved from 0.15143 to 0.13819, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0876 - acc: 0.9929 - val_loss: 0.1382 - val_acc: 0.9787\n",
      "Epoch 175/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 7.6065e-05 - acc: 1.0000\n",
      "Epoch 175: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0477 - acc: 0.9964 - val_loss: 0.2029 - val_acc: 0.9752\n",
      "Epoch 176/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 176: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0680 - acc: 0.9938 - val_loss: 0.3213 - val_acc: 0.9823\n",
      "Epoch 177/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1316 - acc: 1.0000\n",
      "Epoch 177: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1177 - acc: 0.9911 - val_loss: 0.2156 - val_acc: 0.9894\n",
      "Epoch 178/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0720 - acc: 1.0000\n",
      "Epoch 178: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0594 - acc: 0.9920 - val_loss: 0.2740 - val_acc: 0.9858\n",
      "Epoch 179/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1034 - acc: 1.0000\n",
      "Epoch 179: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0618 - acc: 0.9911 - val_loss: 0.1629 - val_acc: 0.9858\n",
      "Epoch 180/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0504 - acc: 0.9688\n",
      "Epoch 180: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1288 - acc: 0.9840 - val_loss: 0.2675 - val_acc: 0.9823\n",
      "Epoch 181/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1145 - acc: 1.0000\n",
      "Epoch 181: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1169 - acc: 0.9938 - val_loss: 0.2223 - val_acc: 0.9752\n",
      "Epoch 182/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4896 - acc: 0.9688\n",
      "Epoch 182: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1044 - acc: 0.9902 - val_loss: 0.1543 - val_acc: 0.9858\n",
      "Epoch 183/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3364 - acc: 0.9688\n",
      "Epoch 183: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0661 - acc: 0.9947 - val_loss: 0.2029 - val_acc: 0.9752\n",
      "Epoch 184/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2729 - acc: 0.9375\n",
      "Epoch 184: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1429 - acc: 0.9858 - val_loss: 0.1830 - val_acc: 0.9681\n",
      "Epoch 185/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.4107e-07 - acc: 1.0000\n",
      "Epoch 185: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0524 - acc: 0.9947 - val_loss: 0.2599 - val_acc: 0.9823\n",
      "Epoch 186/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0799 - acc: 1.0000\n",
      "Epoch 186: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0862 - acc: 0.9920 - val_loss: 0.2755 - val_acc: 0.9787\n",
      "Epoch 187/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1323 - acc: 1.0000\n",
      "Epoch 187: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0716 - acc: 0.9938 - val_loss: 0.2712 - val_acc: 0.9752\n",
      "Epoch 188/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/36 [..............................] - ETA: 0s - loss: 0.1935 - acc: 1.0000\n",
      "Epoch 188: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0844 - acc: 0.9893 - val_loss: 0.1519 - val_acc: 0.9823\n",
      "Epoch 189/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0620 - acc: 1.0000\n",
      "Epoch 189: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1557 - acc: 0.9831 - val_loss: 0.3692 - val_acc: 0.9716\n",
      "Epoch 190/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1475 - acc: 1.0000\n",
      "Epoch 190: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1629 - acc: 0.9831 - val_loss: 0.5442 - val_acc: 0.9504\n",
      "Epoch 191/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3617 - acc: 0.9688\n",
      "Epoch 191: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2994 - acc: 0.9707 - val_loss: 0.4361 - val_acc: 0.9752\n",
      "Epoch 192/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2028 - acc: 1.0000\n",
      "Epoch 192: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2132 - acc: 0.9760 - val_loss: 0.5567 - val_acc: 0.9858\n",
      "Epoch 193/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4804 - acc: 1.0000\n",
      "Epoch 193: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2661 - acc: 0.9778 - val_loss: 0.3719 - val_acc: 0.9574\n",
      "Epoch 194/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 194: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1472 - acc: 0.9813 - val_loss: 0.4295 - val_acc: 0.9716\n",
      "Epoch 195/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1059 - acc: 1.0000\n",
      "Epoch 195: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0882 - acc: 0.9867 - val_loss: 0.3075 - val_acc: 0.9539\n",
      "Epoch 196/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 196: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1114 - acc: 0.9849 - val_loss: 0.1499 - val_acc: 0.9823\n",
      "Epoch 197/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.2833e-04 - acc: 1.0000\n",
      "Epoch 197: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3408 - acc: 0.9645 - val_loss: 0.9062 - val_acc: 0.9149\n",
      "Epoch 198/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.7490 - acc: 0.8438\n",
      "Epoch 198: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1843 - acc: 0.9813 - val_loss: 0.2075 - val_acc: 0.9645\n",
      "Epoch 199/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.9119e-08 - acc: 1.0000\n",
      "Epoch 199: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1353 - acc: 0.9858 - val_loss: 0.2096 - val_acc: 0.9823\n",
      "Epoch 200/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 200: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0705 - acc: 0.9911 - val_loss: 0.1524 - val_acc: 0.9894\n",
      "Epoch 201/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.0521e-07 - acc: 1.0000\n",
      "Epoch 201: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1017 - acc: 0.9893 - val_loss: 0.2709 - val_acc: 0.9752\n",
      "Epoch 202/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2276 - acc: 1.0000\n",
      "Epoch 202: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1005 - acc: 0.9938 - val_loss: 0.2981 - val_acc: 0.9645\n",
      "Epoch 203/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 9.6096e-18 - acc: 1.0000\n",
      "Epoch 203: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0727 - acc: 0.9893 - val_loss: 0.1687 - val_acc: 0.9894\n",
      "Epoch 204/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 5.6969e-08 - acc: 1.0000\n",
      "Epoch 204: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0584 - acc: 0.9938 - val_loss: 0.2637 - val_acc: 0.9858\n",
      "Epoch 205/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0448 - acc: 1.0000\n",
      "Epoch 205: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0955 - acc: 0.9929 - val_loss: 0.2644 - val_acc: 0.9894\n",
      "Epoch 206/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 206: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0747 - acc: 0.9947 - val_loss: 0.3512 - val_acc: 0.9716\n",
      "Epoch 207/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2116 - acc: 1.0000\n",
      "Epoch 207: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0655 - acc: 0.9911 - val_loss: 0.1848 - val_acc: 0.9787\n",
      "Epoch 208/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2041 - acc: 0.9688\n",
      "Epoch 208: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0926 - acc: 0.9920 - val_loss: 0.2249 - val_acc: 0.9716\n",
      "Epoch 209/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0856 - acc: 1.0000\n",
      "Epoch 209: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0656 - acc: 0.9911 - val_loss: 0.2497 - val_acc: 0.9787\n",
      "Epoch 210/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 210: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0493 - acc: 0.9911 - val_loss: 0.1462 - val_acc: 0.9823\n",
      "Epoch 211/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2989 - acc: 0.9688\n",
      "Epoch 211: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0653 - acc: 0.9911 - val_loss: 0.1841 - val_acc: 0.9823\n",
      "Epoch 212/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.8512e-06 - acc: 1.0000\n",
      "Epoch 212: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1545 - acc: 0.9876 - val_loss: 0.2053 - val_acc: 0.9716\n",
      "Epoch 213/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 213: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0489 - acc: 0.9964 - val_loss: 0.5201 - val_acc: 0.9468\n",
      "Epoch 214/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.6014 - acc: 0.9375\n",
      "Epoch 214: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1168 - acc: 0.9893 - val_loss: 0.2734 - val_acc: 0.9823\n",
      "Epoch 215/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 215: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1352 - acc: 0.9840 - val_loss: 0.5167 - val_acc: 0.9397\n",
      "Epoch 216/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4876 - acc: 0.9688\n",
      "Epoch 216: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0658 - acc: 0.9938 - val_loss: 0.2018 - val_acc: 0.9752\n",
      "Epoch 217/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0981 - acc: 1.0000\n",
      "Epoch 217: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3515 - acc: 0.9627 - val_loss: 0.5410 - val_acc: 0.9610\n",
      "Epoch 218/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2881 - acc: 0.9688\n",
      "Epoch 218: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1457 - acc: 0.9805 - val_loss: 0.3525 - val_acc: 0.9681\n",
      "Epoch 219/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3028 - acc: 1.0000\n",
      "Epoch 219: val_loss did not improve from 0.13819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2693 - acc: 0.9725 - val_loss: 0.3386 - val_acc: 0.9574\n",
      "Epoch 220/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1778 - acc: 1.0000\n",
      "Epoch 220: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1596 - acc: 0.9822 - val_loss: 0.3582 - val_acc: 0.9539\n",
      "Epoch 221/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2890 - acc: 0.9375\n",
      "Epoch 221: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2630 - acc: 0.9707 - val_loss: 0.6612 - val_acc: 0.9433\n",
      "Epoch 222/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1572 - acc: 0.9688\n",
      "Epoch 222: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1254 - acc: 0.9796 - val_loss: 0.2063 - val_acc: 0.9787\n",
      "Epoch 223/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1306 - acc: 1.0000\n",
      "Epoch 223: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0482 - acc: 0.9938 - val_loss: 0.2351 - val_acc: 0.9574\n",
      "Epoch 224/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2318 - acc: 0.9062\n",
      "Epoch 224: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0890 - acc: 0.9867 - val_loss: 0.2172 - val_acc: 0.9787\n",
      "Epoch 225/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.7051e-05 - acc: 1.0000\n",
      "Epoch 225: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0476 - acc: 0.9938 - val_loss: 0.3333 - val_acc: 0.9752\n",
      "Epoch 226/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2828 - acc: 0.9688\n",
      "Epoch 226: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1144 - acc: 0.9849 - val_loss: 0.1907 - val_acc: 0.9787\n",
      "Epoch 227/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 8.6040e-06 - acc: 1.0000\n",
      "Epoch 227: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1051 - acc: 0.9911 - val_loss: 0.2572 - val_acc: 0.9681\n",
      "Epoch 228/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0665 - acc: 0.9688\n",
      "Epoch 228: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0958 - acc: 0.9858 - val_loss: 0.1713 - val_acc: 0.9823\n",
      "Epoch 229/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.1374e-06 - acc: 1.0000\n",
      "Epoch 229: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0878 - acc: 0.9885 - val_loss: 0.1672 - val_acc: 0.9823\n",
      "Epoch 230/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.8536e-05 - acc: 1.0000\n",
      "Epoch 230: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0325 - acc: 0.9973 - val_loss: 0.3085 - val_acc: 0.9752\n",
      "Epoch 231/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0695 - acc: 1.0000\n",
      "Epoch 231: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0518 - acc: 0.9938 - val_loss: 0.1953 - val_acc: 0.9787\n",
      "Epoch 232/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0849 - acc: 1.0000\n",
      "Epoch 232: val_loss did not improve from 0.13819\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0492 - acc: 0.9956 - val_loss: 0.1889 - val_acc: 0.9823\n",
      "Epoch 233/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2814 - acc: 0.9688\n",
      "Epoch 233: val_loss improved from 0.13819 to 0.12942, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0287 - acc: 0.9964 - val_loss: 0.1294 - val_acc: 0.9823\n",
      "Epoch 234/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 234: val_loss improved from 0.12942 to 0.12279, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0170 - acc: 0.9982 - val_loss: 0.1228 - val_acc: 0.9787\n",
      "Epoch 235/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2077 - acc: 0.9688\n",
      "Epoch 235: val_loss improved from 0.12279 to 0.10929, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0239 - acc: 0.9956 - val_loss: 0.1093 - val_acc: 0.9929\n",
      "Epoch 236/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.0707e-11 - acc: 1.0000\n",
      "Epoch 236: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0296 - acc: 0.9973 - val_loss: 0.1316 - val_acc: 0.9787\n",
      "Epoch 237/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 237: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0802 - acc: 0.9867 - val_loss: 0.2144 - val_acc: 0.9823\n",
      "Epoch 238/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 238: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0388 - acc: 0.9929 - val_loss: 0.1619 - val_acc: 0.9858\n",
      "Epoch 239/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.5747e-05 - acc: 1.0000\n",
      "Epoch 239: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0440 - acc: 0.9956 - val_loss: 0.3984 - val_acc: 0.9504\n",
      "Epoch 240/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0891 - acc: 1.0000\n",
      "Epoch 240: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1732 - acc: 0.9796 - val_loss: 0.3714 - val_acc: 0.9610\n",
      "Epoch 241/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0452 - acc: 1.0000\n",
      "Epoch 241: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0886 - acc: 0.9876 - val_loss: 0.2004 - val_acc: 0.9574\n",
      "Epoch 242/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.5095e-04 - acc: 1.0000\n",
      "Epoch 242: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0475 - acc: 0.9929 - val_loss: 0.1928 - val_acc: 0.9752\n",
      "Epoch 243/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 243: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0358 - acc: 0.9947 - val_loss: 0.1635 - val_acc: 0.9823\n",
      "Epoch 244/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.2708e-10 - acc: 1.0000\n",
      "Epoch 244: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1271 - acc: 0.9938 - val_loss: 0.1476 - val_acc: 0.9858\n",
      "Epoch 245/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1593 - acc: 1.0000\n",
      "Epoch 245: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1632 - acc: 0.9813 - val_loss: 0.1790 - val_acc: 0.9787\n",
      "Epoch 246/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 246: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0606 - acc: 0.9929 - val_loss: 0.1990 - val_acc: 0.9645\n",
      "Epoch 247/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0961 - acc: 1.0000\n",
      "Epoch 247: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0473 - acc: 0.9929 - val_loss: 0.1417 - val_acc: 0.9787\n",
      "Epoch 248/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.9841e-04 - acc: 1.0000\n",
      "Epoch 248: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0363 - acc: 0.9929 - val_loss: 0.2117 - val_acc: 0.9752\n",
      "Epoch 249/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 249: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1336 - acc: 0.9805 - val_loss: 0.4331 - val_acc: 0.9752\n",
      "Epoch 250/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4646 - acc: 1.0000\n",
      "Epoch 250: val_loss did not improve from 0.10929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1159 - acc: 0.9831 - val_loss: 0.1590 - val_acc: 0.9752\n",
      "Epoch 251/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 251: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1301 - acc: 0.9840 - val_loss: 0.2141 - val_acc: 0.9539\n",
      "Epoch 252/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 9.5969e-06 - acc: 1.0000\n",
      "Epoch 252: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1666 - acc: 0.9760 - val_loss: 0.5875 - val_acc: 0.9149\n",
      "Epoch 253/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.6473 - acc: 0.9688\n",
      "Epoch 253: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0487 - acc: 0.9911 - val_loss: 0.2399 - val_acc: 0.9858\n",
      "Epoch 254/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.4101e-12 - acc: 1.0000\n",
      "Epoch 254: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0530 - acc: 0.9911 - val_loss: 0.1585 - val_acc: 0.9823\n",
      "Epoch 255/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.2976e-10 - acc: 1.0000\n",
      "Epoch 255: val_loss did not improve from 0.10929\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0629 - acc: 0.9893 - val_loss: 0.2059 - val_acc: 0.9716\n",
      "Epoch 256/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0368 - acc: 1.0000\n",
      "Epoch 256: val_loss improved from 0.10929 to 0.10596, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0489 - acc: 0.9929 - val_loss: 0.1060 - val_acc: 0.9894\n",
      "Epoch 257/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.3547e-04 - acc: 1.0000\n",
      "Epoch 257: val_loss improved from 0.10596 to 0.09092, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0315 - acc: 0.9956 - val_loss: 0.0909 - val_acc: 0.9858\n",
      "Epoch 258/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 258: val_loss improved from 0.09092 to 0.07357, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0356 - acc: 0.9920 - val_loss: 0.0736 - val_acc: 0.9929\n",
      "Epoch 259/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 259: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0375 - acc: 0.9938 - val_loss: 0.1629 - val_acc: 0.9752\n",
      "Epoch 260/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0574 - acc: 1.0000\n",
      "Epoch 260: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1138 - acc: 0.9885 - val_loss: 0.2329 - val_acc: 0.9574\n",
      "Epoch 261/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.3050e-06 - acc: 1.0000\n",
      "Epoch 261: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1792 - acc: 0.9760 - val_loss: 0.1980 - val_acc: 0.9645\n",
      "Epoch 262/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2123 - acc: 1.0000\n",
      "Epoch 262: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1192 - acc: 0.9822 - val_loss: 0.4251 - val_acc: 0.9291\n",
      "Epoch 263/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1346 - acc: 0.9688\n",
      "Epoch 263: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0857 - acc: 0.9876 - val_loss: 0.0970 - val_acc: 0.9858\n",
      "Epoch 264/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0277 - acc: 0.9688\n",
      "Epoch 264: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0867 - acc: 0.9831 - val_loss: 0.1555 - val_acc: 0.9823\n",
      "Epoch 265/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0860 - acc: 1.0000\n",
      "Epoch 265: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1458 - acc: 0.9822 - val_loss: 0.1850 - val_acc: 0.9752\n",
      "Epoch 266/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 266: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0532 - acc: 0.9876 - val_loss: 0.1433 - val_acc: 0.9752\n",
      "Epoch 267/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 267: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0349 - acc: 0.9956 - val_loss: 0.0931 - val_acc: 0.9752\n",
      "Epoch 268/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.0534e-04 - acc: 1.0000\n",
      "Epoch 268: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0379 - acc: 0.9920 - val_loss: 0.1146 - val_acc: 0.9823\n",
      "Epoch 269/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 269: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0322 - acc: 0.9929 - val_loss: 0.1093 - val_acc: 0.9929\n",
      "Epoch 270/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.0474e-05 - acc: 1.0000\n",
      "Epoch 270: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0322 - acc: 0.9947 - val_loss: 0.1341 - val_acc: 0.9894\n",
      "Epoch 271/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 271: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0378 - acc: 0.9929 - val_loss: 0.0972 - val_acc: 0.9823\n",
      "Epoch 272/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1630 - acc: 0.9688\n",
      "Epoch 272: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0256 - acc: 0.9947 - val_loss: 0.1508 - val_acc: 0.9787\n",
      "Epoch 273/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 273: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0338 - acc: 0.9938 - val_loss: 0.1414 - val_acc: 0.9929\n",
      "Epoch 274/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 274: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0356 - acc: 0.9947 - val_loss: 0.1038 - val_acc: 0.9929\n",
      "Epoch 275/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 6.7090e-09 - acc: 1.0000\n",
      "Epoch 275: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0506 - acc: 0.9893 - val_loss: 0.1657 - val_acc: 0.9752\n",
      "Epoch 276/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.3144e-05 - acc: 1.0000\n",
      "Epoch 276: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0669 - acc: 0.9893 - val_loss: 0.0799 - val_acc: 0.9823\n",
      "Epoch 277/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.6662e-04 - acc: 1.0000\n",
      "Epoch 277: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0261 - acc: 0.9938 - val_loss: 0.1099 - val_acc: 0.9787\n",
      "Epoch 278/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.1086e-07 - acc: 1.0000\n",
      "Epoch 278: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0720 - acc: 0.9902 - val_loss: 0.8736 - val_acc: 0.9113\n",
      "Epoch 279/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4680 - acc: 0.9688\n",
      "Epoch 279: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3056 - acc: 0.9565 - val_loss: 0.2248 - val_acc: 0.9823\n",
      "Epoch 280/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 280: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0852 - acc: 0.9867 - val_loss: 0.1822 - val_acc: 0.9716\n",
      "Epoch 281/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 7.9975e-05 - acc: 1.0000\n",
      "Epoch 281: val_loss did not improve from 0.07357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0551 - acc: 0.9929 - val_loss: 0.1561 - val_acc: 0.9823\n",
      "Epoch 282/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0935 - acc: 1.0000\n",
      "Epoch 282: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0560 - acc: 0.9920 - val_loss: 0.1889 - val_acc: 0.9823\n",
      "Epoch 283/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1129 - acc: 1.0000\n",
      "Epoch 283: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0367 - acc: 0.9947 - val_loss: 0.1440 - val_acc: 0.9716\n",
      "Epoch 284/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1046 - acc: 1.0000\n",
      "Epoch 284: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0220 - acc: 0.9956 - val_loss: 0.0797 - val_acc: 0.9929\n",
      "Epoch 285/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.1897e-04 - acc: 1.0000\n",
      "Epoch 285: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0223 - acc: 0.9938 - val_loss: 0.0858 - val_acc: 0.9894\n",
      "Epoch 286/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.9265e-09 - acc: 1.0000\n",
      "Epoch 286: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0493 - acc: 0.9920 - val_loss: 0.1135 - val_acc: 0.9858\n",
      "Epoch 287/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.2197e-05 - acc: 1.0000\n",
      "Epoch 287: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0261 - acc: 0.9956 - val_loss: 0.0739 - val_acc: 0.9858\n",
      "Epoch 288/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 288: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0300 - acc: 0.9929 - val_loss: 0.1157 - val_acc: 0.9858\n",
      "Epoch 289/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1084 - acc: 0.9688\n",
      "Epoch 289: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0161 - acc: 0.9973 - val_loss: 0.1343 - val_acc: 0.9752\n",
      "Epoch 290/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 290: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0436 - acc: 0.9929 - val_loss: 0.0945 - val_acc: 0.9858\n",
      "Epoch 291/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 291: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1070 - acc: 0.9876 - val_loss: 0.1849 - val_acc: 0.9823\n",
      "Epoch 292/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1064 - acc: 1.0000\n",
      "Epoch 292: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0721 - acc: 0.9822 - val_loss: 0.0781 - val_acc: 0.9929\n",
      "Epoch 293/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.0035e-07 - acc: 1.0000\n",
      "Epoch 293: val_loss did not improve from 0.07357\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0721 - acc: 0.9893 - val_loss: 0.1306 - val_acc: 0.9787\n",
      "Epoch 294/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.4154e-05 - acc: 1.0000\n",
      "Epoch 294: val_loss improved from 0.07357 to 0.06504, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0474 - acc: 0.9876 - val_loss: 0.0650 - val_acc: 0.9929\n",
      "Epoch 295/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 295: val_loss did not improve from 0.06504\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1151 - acc: 0.9840 - val_loss: 0.0820 - val_acc: 0.9752\n",
      "Epoch 296/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 5.0225e-04 - acc: 1.0000\n",
      "Epoch 296: val_loss did not improve from 0.06504\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0280 - acc: 0.9938 - val_loss: 0.0730 - val_acc: 0.9823\n",
      "Epoch 297/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0394 - acc: 0.9688\n",
      "Epoch 297: val_loss did not improve from 0.06504\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0830 - val_acc: 0.9858\n",
      "Epoch 298/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 9.0711e-04 - acc: 1.0000\n",
      "Epoch 298: val_loss did not improve from 0.06504\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0873 - val_acc: 0.9929\n",
      "Epoch 299/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 299: val_loss improved from 0.06504 to 0.05561, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0556 - val_acc: 0.9894\n",
      "Epoch 300/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 6.9233e-07 - acc: 1.0000\n",
      "Epoch 300: val_loss did not improve from 0.05561\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0141 - acc: 0.9973 - val_loss: 0.1011 - val_acc: 0.9858\n",
      "Epoch 301/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0813 - acc: 1.0000\n",
      "Epoch 301: val_loss did not improve from 0.05561\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0127 - acc: 0.9982 - val_loss: 0.1221 - val_acc: 0.9681\n",
      "Epoch 302/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 302: val_loss did not improve from 0.05561\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0831 - acc: 0.9813 - val_loss: 0.1424 - val_acc: 0.9823\n",
      "Epoch 303/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 303: val_loss did not improve from 0.05561\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0244 - acc: 0.9902 - val_loss: 0.0713 - val_acc: 0.9823\n",
      "Epoch 304/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 304: val_loss did not improve from 0.05561\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0344 - acc: 0.9893 - val_loss: 0.0778 - val_acc: 0.9858\n",
      "Epoch 305/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.0134e-08 - acc: 1.0000\n",
      "Epoch 305: val_loss improved from 0.05561 to 0.04975, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0128 - acc: 0.9973 - val_loss: 0.0498 - val_acc: 0.9894\n",
      "Epoch 306/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 306: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0170 - acc: 0.9938 - val_loss: 0.0592 - val_acc: 0.9894\n",
      "Epoch 307/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.3852e-10 - acc: 1.0000\n",
      "Epoch 307: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - acc: 0.9973 - val_loss: 0.0726 - val_acc: 0.9858\n",
      "Epoch 308/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.0477e-07 - acc: 1.0000\n",
      "Epoch 308: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0277 - acc: 0.9947 - val_loss: 0.0958 - val_acc: 0.9858\n",
      "Epoch 309/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.7360e-10 - acc: 1.0000\n",
      "Epoch 309: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0257 - acc: 0.9929 - val_loss: 0.0982 - val_acc: 0.9823\n",
      "Epoch 310/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.4566e-04 - acc: 1.0000\n",
      "Epoch 310: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0518 - acc: 0.9849 - val_loss: 0.0816 - val_acc: 0.9858\n",
      "Epoch 311/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0086 - acc: 0.9688\n",
      "Epoch 311: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0347 - acc: 0.9920 - val_loss: 0.0822 - val_acc: 0.9858\n",
      "Epoch 312/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 312: val_loss did not improve from 0.04975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0695 - acc: 0.9858 - val_loss: 0.3313 - val_acc: 0.9610\n",
      "Epoch 313/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2432 - acc: 0.9688\n",
      "Epoch 313: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0873 - acc: 0.9885 - val_loss: 0.1695 - val_acc: 0.9823\n",
      "Epoch 314/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1002 - acc: 1.0000\n",
      "Epoch 314: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0999 - acc: 0.9813 - val_loss: 0.2967 - val_acc: 0.9220\n",
      "Epoch 315/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.4002 - acc: 0.9375\n",
      "Epoch 315: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1915 - acc: 0.9707 - val_loss: 0.2252 - val_acc: 0.9504\n",
      "Epoch 316/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0733 - acc: 0.9688\n",
      "Epoch 316: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0885 - acc: 0.9876 - val_loss: 0.1038 - val_acc: 0.9858\n",
      "Epoch 317/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 317: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0528 - acc: 0.9920 - val_loss: 0.1422 - val_acc: 0.9858\n",
      "Epoch 318/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 318: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0456 - acc: 0.9920 - val_loss: 0.0754 - val_acc: 0.9858\n",
      "Epoch 319/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.0518e-06 - acc: 1.0000\n",
      "Epoch 319: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0244 - acc: 0.9947 - val_loss: 0.0837 - val_acc: 0.9823\n",
      "Epoch 320/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 320: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0302 - acc: 0.9902 - val_loss: 0.1024 - val_acc: 0.9858\n",
      "Epoch 321/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.0607e-04 - acc: 1.0000\n",
      "Epoch 321: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0699 - acc: 0.9885 - val_loss: 0.1392 - val_acc: 0.9716\n",
      "Epoch 322/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 322: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1386 - acc: 0.9734 - val_loss: 0.1873 - val_acc: 0.9716\n",
      "Epoch 323/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1126 - acc: 0.9375\n",
      "Epoch 323: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0870 - acc: 0.9778 - val_loss: 0.1171 - val_acc: 0.9894\n",
      "Epoch 324/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 324: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0738 - acc: 0.9867 - val_loss: 0.0530 - val_acc: 0.9823\n",
      "Epoch 325/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 325: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0177 - acc: 0.9964 - val_loss: 0.0688 - val_acc: 0.9894\n",
      "Epoch 326/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 5.5504e-06 - acc: 1.0000\n",
      "Epoch 326: val_loss did not improve from 0.04975\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0160 - acc: 0.9956 - val_loss: 0.1352 - val_acc: 0.9787\n",
      "Epoch 327/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.1385e-05 - acc: 1.0000\n",
      "Epoch 327: val_loss improved from 0.04975 to 0.04798, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0445 - acc: 0.9885 - val_loss: 0.0480 - val_acc: 0.9894\n",
      "Epoch 328/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 328: val_loss improved from 0.04798 to 0.02900, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0198 - acc: 0.9947 - val_loss: 0.0290 - val_acc: 0.9929\n",
      "Epoch 329/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.7934e-04 - acc: 1.0000\n",
      "Epoch 329: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0131 - acc: 0.9964 - val_loss: 0.0426 - val_acc: 0.9929\n",
      "Epoch 330/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 330: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.0587 - val_acc: 0.9858\n",
      "Epoch 331/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 8.6353e-06 - acc: 1.0000\n",
      "Epoch 331: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0694 - acc: 0.9813 - val_loss: 0.1018 - val_acc: 0.9858\n",
      "Epoch 332/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0852 - acc: 1.0000\n",
      "Epoch 332: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0382 - acc: 0.9902 - val_loss: 0.1078 - val_acc: 0.9858\n",
      "Epoch 333/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 6.2974e-04 - acc: 1.0000\n",
      "Epoch 333: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0746 - acc: 0.9796 - val_loss: 0.1231 - val_acc: 0.9787\n",
      "Epoch 334/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 7.2307e-04 - acc: 1.0000\n",
      "Epoch 334: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0724 - acc: 0.9867 - val_loss: 0.1038 - val_acc: 0.9716\n",
      "Epoch 335/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 335: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0362 - acc: 0.9920 - val_loss: 0.1061 - val_acc: 0.9929\n",
      "Epoch 336/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0918 - acc: 1.0000\n",
      "Epoch 336: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0387 - acc: 0.9911 - val_loss: 0.0915 - val_acc: 0.9823\n",
      "Epoch 337/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0541 - acc: 0.9688\n",
      "Epoch 337: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0307 - acc: 0.9902 - val_loss: 0.1097 - val_acc: 0.9716\n",
      "Epoch 338/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0288 - acc: 1.0000\n",
      "Epoch 338: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1045 - acc: 0.9760 - val_loss: 0.0691 - val_acc: 0.9858\n",
      "Epoch 339/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.0026e-04 - acc: 1.0000\n",
      "Epoch 339: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0360 - acc: 0.9902 - val_loss: 0.0726 - val_acc: 0.9787\n",
      "Epoch 340/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 340: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0243 - acc: 0.9920 - val_loss: 0.0764 - val_acc: 0.9752\n",
      "Epoch 341/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 7.5368e-04 - acc: 1.0000\n",
      "Epoch 341: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0142 - acc: 0.9911 - val_loss: 0.0366 - val_acc: 0.9681\n",
      "Epoch 342/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 5.5711e-09 - acc: 1.0000\n",
      "Epoch 342: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0128 - acc: 0.9947 - val_loss: 0.0606 - val_acc: 0.9858\n",
      "Epoch 343/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.6317e-08 - acc: 1.0000\n",
      "Epoch 343: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0355 - acc: 0.9920 - val_loss: 0.0607 - val_acc: 0.9823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.9600e-04 - acc: 1.0000\n",
      "Epoch 344: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0376 - acc: 0.9893 - val_loss: 0.0874 - val_acc: 0.9716\n",
      "Epoch 345/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 345: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0256 - acc: 0.9964 - val_loss: 0.0413 - val_acc: 0.9929\n",
      "Epoch 346/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 346: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0130 - acc: 0.9956 - val_loss: 0.0611 - val_acc: 0.9894\n",
      "Epoch 347/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 7.8499e-05 - acc: 1.0000\n",
      "Epoch 347: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0116 - acc: 0.9956 - val_loss: 0.0472 - val_acc: 0.9929\n",
      "Epoch 348/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 348: val_loss did not improve from 0.02900\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0032 - acc: 0.9982 - val_loss: 0.0306 - val_acc: 0.9929\n",
      "Epoch 349/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.7540e-04 - acc: 1.0000\n",
      "Epoch 349: val_loss improved from 0.02900 to 0.02868, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0045 - acc: 0.9964 - val_loss: 0.0287 - val_acc: 0.9929\n",
      "Epoch 350/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.3870e-07 - acc: 1.0000\n",
      "Epoch 350: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0654 - val_acc: 0.9858\n",
      "Epoch 351/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.6433e-04 - acc: 1.0000\n",
      "Epoch 351: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0054 - acc: 0.9973 - val_loss: 0.0603 - val_acc: 0.9929\n",
      "Epoch 352/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0627 - acc: 0.9688\n",
      "Epoch 352: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0135 - acc: 0.9973 - val_loss: 0.0491 - val_acc: 0.9929\n",
      "Epoch 353/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.2959e-07 - acc: 1.0000\n",
      "Epoch 353: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0298 - acc: 0.9920 - val_loss: 0.1178 - val_acc: 0.9823\n",
      "Epoch 354/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 354: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 0.0684 - val_acc: 0.9894\n",
      "Epoch 355/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.4442e-05 - acc: 1.0000\n",
      "Epoch 355: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0232 - acc: 0.9947 - val_loss: 0.0805 - val_acc: 0.9894\n",
      "Epoch 356/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1718 - acc: 0.9688\n",
      "Epoch 356: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0201 - acc: 0.9973 - val_loss: 0.0706 - val_acc: 0.9894\n",
      "Epoch 357/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 357: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0141 - acc: 0.9956 - val_loss: 0.0412 - val_acc: 0.9894\n",
      "Epoch 358/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 358: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0317 - acc: 0.9902 - val_loss: 0.0551 - val_acc: 0.9752\n",
      "Epoch 359/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1109 - acc: 0.9688\n",
      "Epoch 359: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0678 - acc: 0.9840 - val_loss: 0.3915 - val_acc: 0.9716\n",
      "Epoch 360/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3115 - acc: 0.9688\n",
      "Epoch 360: val_loss did not improve from 0.02868\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0657 - acc: 0.9893 - val_loss: 0.1292 - val_acc: 0.9716\n",
      "Epoch 361/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1046 - acc: 1.0000\n",
      "Epoch 361: val_loss improved from 0.02868 to 0.01722, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0359 - acc: 0.9938 - val_loss: 0.0172 - val_acc: 0.9894\n",
      "Epoch 362/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 362: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0183 - acc: 0.9929 - val_loss: 0.0438 - val_acc: 0.9894\n",
      "Epoch 363/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 363: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0279 - acc: 0.9929 - val_loss: 0.1168 - val_acc: 0.9752\n",
      "Epoch 364/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0775 - acc: 0.9688\n",
      "Epoch 364: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0182 - acc: 0.9956 - val_loss: 0.0793 - val_acc: 0.9681\n",
      "Epoch 365/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0654 - acc: 0.9688\n",
      "Epoch 365: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0355 - acc: 0.9876 - val_loss: 0.0983 - val_acc: 0.9858\n",
      "Epoch 366/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.1953e-04 - acc: 1.0000\n",
      "Epoch 366: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0111 - acc: 0.9956 - val_loss: 0.0644 - val_acc: 0.9894\n",
      "Epoch 367/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 9.5972e-04 - acc: 1.0000\n",
      "Epoch 367: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0969 - val_acc: 0.9716\n",
      "Epoch 368/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0641 - acc: 0.9375\n",
      "Epoch 368: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0210 - acc: 0.9947 - val_loss: 0.1031 - val_acc: 0.9752\n",
      "Epoch 369/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 369: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0261 - acc: 0.9929 - val_loss: 0.0588 - val_acc: 0.9681\n",
      "Epoch 370/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0453 - acc: 0.9375\n",
      "Epoch 370: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0126 - acc: 0.9920 - val_loss: 0.0513 - val_acc: 0.9894\n",
      "Epoch 371/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 371: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9894\n",
      "Epoch 372/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.4132e-07 - acc: 1.0000\n",
      "Epoch 372: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0551 - val_acc: 0.9929\n",
      "Epoch 373/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 5.0034e-09 - acc: 1.0000\n",
      "Epoch 373: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0100 - acc: 0.9991 - val_loss: 0.1093 - val_acc: 0.9894\n",
      "Epoch 374/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.8563e-07 - acc: 1.0000\n",
      "Epoch 374: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0421 - acc: 0.9885 - val_loss: 0.1059 - val_acc: 0.9858\n",
      "Epoch 375/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/36 [..............................] - ETA: 0s - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 375: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0212 - acc: 0.9947 - val_loss: 0.0592 - val_acc: 0.9894\n",
      "Epoch 376/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.8022e-05 - acc: 1.0000\n",
      "Epoch 376: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0239 - acc: 0.9876 - val_loss: 0.0463 - val_acc: 0.9823\n",
      "Epoch 377/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 377: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0321 - acc: 0.9876 - val_loss: 0.1001 - val_acc: 0.9787\n",
      "Epoch 378/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.9617e-06 - acc: 1.0000\n",
      "Epoch 378: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0258 - acc: 0.9956 - val_loss: 0.1270 - val_acc: 0.9787\n",
      "Epoch 379/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0200 - acc: 0.9688\n",
      "Epoch 379: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0229 - acc: 0.9938 - val_loss: 0.0703 - val_acc: 0.9894\n",
      "Epoch 380/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 380: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0304 - acc: 0.9902 - val_loss: 0.0928 - val_acc: 0.9823\n",
      "Epoch 381/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1272 - acc: 0.9688\n",
      "Epoch 381: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0279 - acc: 0.9956 - val_loss: 0.1250 - val_acc: 0.9716\n",
      "Epoch 382/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0365 - acc: 0.9688\n",
      "Epoch 382: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0340 - acc: 0.9867 - val_loss: 0.0774 - val_acc: 0.9858\n",
      "Epoch 383/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 383: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0535 - acc: 0.9902 - val_loss: 0.1158 - val_acc: 0.9645\n",
      "Epoch 384/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0524 - acc: 0.9688\n",
      "Epoch 384: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0505 - acc: 0.9893 - val_loss: 0.1038 - val_acc: 0.9716\n",
      "Epoch 385/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 385: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0280 - acc: 0.9973 - val_loss: 0.1052 - val_acc: 0.9823\n",
      "Epoch 386/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 7.9646e-05 - acc: 1.0000\n",
      "Epoch 386: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0597 - acc: 0.9867 - val_loss: 0.1839 - val_acc: 0.9397\n",
      "Epoch 387/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.2159 - acc: 0.9375\n",
      "Epoch 387: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0646 - acc: 0.9822 - val_loss: 0.0891 - val_acc: 0.9823\n",
      "Epoch 388/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 388: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0368 - acc: 0.9893 - val_loss: 0.1607 - val_acc: 0.9645\n",
      "Epoch 389/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 8.0834e-06 - acc: 1.0000\n",
      "Epoch 389: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2448 - acc: 0.9529 - val_loss: 0.2300 - val_acc: 0.9468\n",
      "Epoch 390/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0720 - acc: 1.0000\n",
      "Epoch 390: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1601 - acc: 0.9671 - val_loss: 0.1073 - val_acc: 0.9574\n",
      "Epoch 391/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1660 - acc: 0.9688\n",
      "Epoch 391: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0680 - acc: 0.9822 - val_loss: 0.1339 - val_acc: 0.9787\n",
      "Epoch 392/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1558 - acc: 0.9688\n",
      "Epoch 392: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0451 - acc: 0.9893 - val_loss: 0.1034 - val_acc: 0.9858\n",
      "Epoch 393/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0330 - acc: 0.9688\n",
      "Epoch 393: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0245 - acc: 0.9911 - val_loss: 0.1010 - val_acc: 0.9645\n",
      "Epoch 394/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0182 - acc: 0.9688\n",
      "Epoch 394: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0206 - acc: 0.9920 - val_loss: 0.0667 - val_acc: 0.9894\n",
      "Epoch 395/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.3511e-04 - acc: 1.0000\n",
      "Epoch 395: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0234 - acc: 0.9911 - val_loss: 0.0772 - val_acc: 0.9858\n",
      "Epoch 396/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0198 - acc: 0.9688\n",
      "Epoch 396: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0106 - acc: 0.9947 - val_loss: 0.0398 - val_acc: 0.9894\n",
      "Epoch 397/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.2861e-04 - acc: 1.0000\n",
      "Epoch 397: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0099 - acc: 0.9929 - val_loss: 0.0672 - val_acc: 0.9929\n",
      "Epoch 398/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 6.7871e-04 - acc: 1.0000\n",
      "Epoch 398: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0157 - acc: 0.9947 - val_loss: 0.0607 - val_acc: 0.9894\n",
      "Epoch 399/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.3086e-04 - acc: 1.0000\n",
      "Epoch 399: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0084 - acc: 0.9956 - val_loss: 0.0400 - val_acc: 0.9787\n",
      "Epoch 400/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.0220e-05 - acc: 1.0000\n",
      "Epoch 400: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.0790 - val_acc: 0.9894\n",
      "Epoch 401/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.7272e-04 - acc: 1.0000\n",
      "Epoch 401: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0192 - acc: 0.9938 - val_loss: 0.0406 - val_acc: 0.9929\n",
      "Epoch 402/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 5.2284e-05 - acc: 1.0000\n",
      "Epoch 402: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0111 - acc: 0.9973 - val_loss: 0.0698 - val_acc: 0.9823\n",
      "Epoch 403/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.6091e-08 - acc: 1.0000\n",
      "Epoch 403: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0076 - acc: 0.9982 - val_loss: 0.0428 - val_acc: 0.9858\n",
      "Epoch 404/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0221 - acc: 0.9688\n",
      "Epoch 404: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0077 - acc: 0.9938 - val_loss: 0.1255 - val_acc: 0.9397\n",
      "Epoch 405/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 405: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0175 - acc: 0.9911 - val_loss: 0.0523 - val_acc: 0.9894\n",
      "Epoch 406/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.7450e-05 - acc: 1.0000\n",
      "Epoch 406: val_loss did not improve from 0.01722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0105 - acc: 0.9956 - val_loss: 0.0513 - val_acc: 0.9858\n",
      "Epoch 407/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.0910e-07 - acc: 1.0000\n",
      "Epoch 407: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0252 - acc: 0.9902 - val_loss: 0.1146 - val_acc: 0.9504\n",
      "Epoch 408/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 408: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0361 - acc: 0.9849 - val_loss: 0.0512 - val_acc: 0.9858\n",
      "Epoch 409/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.1167e-06 - acc: 1.0000\n",
      "Epoch 409: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0111 - acc: 0.9947 - val_loss: 0.0299 - val_acc: 0.9823\n",
      "Epoch 410/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 410: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0111 - acc: 0.9947 - val_loss: 0.0534 - val_acc: 0.9894\n",
      "Epoch 411/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.1890e-05 - acc: 1.0000\n",
      "Epoch 411: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0233 - acc: 0.9929 - val_loss: 0.1000 - val_acc: 0.9823\n",
      "Epoch 412/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 412: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0181 - acc: 0.9947 - val_loss: 0.0590 - val_acc: 0.9858\n",
      "Epoch 413/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.9731e-04 - acc: 1.0000\n",
      "Epoch 413: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0190 - acc: 0.9929 - val_loss: 0.2353 - val_acc: 0.9645\n",
      "Epoch 414/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0597 - acc: 1.0000\n",
      "Epoch 414: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0503 - acc: 0.9876 - val_loss: 0.1043 - val_acc: 0.9858\n",
      "Epoch 415/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0623 - acc: 0.9688\n",
      "Epoch 415: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0233 - acc: 0.9938 - val_loss: 0.0661 - val_acc: 0.9752\n",
      "Epoch 416/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 416: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0236 - acc: 0.9920 - val_loss: 0.0292 - val_acc: 0.9858\n",
      "Epoch 417/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.2553e-06 - acc: 1.0000\n",
      "Epoch 417: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0230 - acc: 0.9929 - val_loss: 0.0264 - val_acc: 0.9894\n",
      "Epoch 418/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 418: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0587 - acc: 0.9876 - val_loss: 0.1339 - val_acc: 0.9752\n",
      "Epoch 419/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0978 - acc: 0.9688\n",
      "Epoch 419: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0600 - acc: 0.9858 - val_loss: 0.1181 - val_acc: 0.9787\n",
      "Epoch 420/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0806 - acc: 1.0000\n",
      "Epoch 420: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0317 - acc: 0.9938 - val_loss: 0.0576 - val_acc: 0.9752\n",
      "Epoch 421/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 421: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0763 - acc: 0.9849 - val_loss: 0.0623 - val_acc: 0.9858\n",
      "Epoch 422/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 9.5409e-06 - acc: 1.0000\n",
      "Epoch 422: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3484 - acc: 0.9263 - val_loss: 0.2329 - val_acc: 0.9433\n",
      "Epoch 423/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 423: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0674 - acc: 0.9858 - val_loss: 0.1894 - val_acc: 0.9610\n",
      "Epoch 424/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1373 - acc: 0.9062\n",
      "Epoch 424: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0482 - acc: 0.9813 - val_loss: 0.0639 - val_acc: 0.9787\n",
      "Epoch 425/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 5.1020e-05 - acc: 1.0000\n",
      "Epoch 425: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0877 - acc: 0.9734 - val_loss: 0.0915 - val_acc: 0.9858\n",
      "Epoch 426/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 426: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0274 - acc: 0.9911 - val_loss: 0.0502 - val_acc: 0.9894\n",
      "Epoch 427/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0229 - acc: 0.9688\n",
      "Epoch 427: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0218 - acc: 0.9956 - val_loss: 0.0547 - val_acc: 0.9823\n",
      "Epoch 428/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.9089e-07 - acc: 1.0000\n",
      "Epoch 428: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0121 - acc: 0.9947 - val_loss: 0.0403 - val_acc: 0.9858\n",
      "Epoch 429/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.2510e-06 - acc: 1.0000\n",
      "Epoch 429: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0139 - acc: 0.9938 - val_loss: 0.0921 - val_acc: 0.9787\n",
      "Epoch 430/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0243 - acc: 0.9688\n",
      "Epoch 430: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0120 - acc: 0.9938 - val_loss: 0.0552 - val_acc: 0.9858\n",
      "Epoch 431/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0177 - acc: 0.9688\n",
      "Epoch 431: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0217 - acc: 0.9947 - val_loss: 0.0501 - val_acc: 0.9858\n",
      "Epoch 432/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.6212e-06 - acc: 1.0000\n",
      "Epoch 432: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0609 - val_acc: 0.9894\n",
      "Epoch 433/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 9.5701e-06 - acc: 1.0000\n",
      "Epoch 433: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0066 - acc: 0.9956 - val_loss: 0.0845 - val_acc: 0.9823\n",
      "Epoch 434/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 434: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0055 - acc: 0.9973 - val_loss: 0.0704 - val_acc: 0.9823\n",
      "Epoch 435/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.0957e-04 - acc: 1.0000\n",
      "Epoch 435: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0145 - acc: 0.9947 - val_loss: 0.0703 - val_acc: 0.9787\n",
      "Epoch 436/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0470 - acc: 0.9688\n",
      "Epoch 436: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0178 - acc: 0.9929 - val_loss: 0.0521 - val_acc: 0.9858\n",
      "Epoch 437/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 437: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0126 - acc: 0.9956 - val_loss: 0.0370 - val_acc: 0.9858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.8923e-06 - acc: 1.0000\n",
      "Epoch 438: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - acc: 0.9964 - val_loss: 0.0436 - val_acc: 0.9858\n",
      "Epoch 439/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.2994e-04 - acc: 1.0000\n",
      "Epoch 439: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9894\n",
      "Epoch 440/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.7881e-04 - acc: 1.0000\n",
      "Epoch 440: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0023 - acc: 0.9982 - val_loss: 0.0299 - val_acc: 0.9858\n",
      "Epoch 441/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.8988e-04 - acc: 1.0000\n",
      "Epoch 441: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0075 - acc: 0.9938 - val_loss: 0.0282 - val_acc: 0.9858\n",
      "Epoch 442/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.3210e-05 - acc: 1.0000\n",
      "Epoch 442: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0525 - val_acc: 0.9752\n",
      "Epoch 443/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 443: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0158 - acc: 0.9938 - val_loss: 0.0605 - val_acc: 0.9858\n",
      "Epoch 444/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.9244e-04 - acc: 1.0000\n",
      "Epoch 444: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0154 - acc: 0.9956 - val_loss: 0.0468 - val_acc: 0.9894\n",
      "Epoch 445/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 9.2126e-06 - acc: 1.0000\n",
      "Epoch 445: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0480 - acc: 0.9858 - val_loss: 0.0945 - val_acc: 0.9574\n",
      "Epoch 446/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0211 - acc: 0.9688\n",
      "Epoch 446: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0157 - acc: 0.9929 - val_loss: 0.0283 - val_acc: 0.9894\n",
      "Epoch 447/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0402 - acc: 0.9688\n",
      "Epoch 447: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0072 - acc: 0.9982 - val_loss: 0.0558 - val_acc: 0.9823\n",
      "Epoch 448/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.2630e-04 - acc: 1.0000\n",
      "Epoch 448: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0137 - acc: 0.9947 - val_loss: 0.0506 - val_acc: 0.9929\n",
      "Epoch 449/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.5349e-04 - acc: 1.0000\n",
      "Epoch 449: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.0317 - val_acc: 0.9787\n",
      "Epoch 450/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.1527e-04 - acc: 1.0000\n",
      "Epoch 450: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0088 - acc: 0.9982 - val_loss: 0.0952 - val_acc: 0.9823\n",
      "Epoch 451/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 451: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0590 - val_acc: 0.9752\n",
      "Epoch 452/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.7723e-04 - acc: 1.0000\n",
      "Epoch 452: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0129 - acc: 0.9964 - val_loss: 0.0765 - val_acc: 0.9752\n",
      "Epoch 453/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 453: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0163 - acc: 0.9902 - val_loss: 0.0769 - val_acc: 0.9858\n",
      "Epoch 454/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.7627e-04 - acc: 1.0000\n",
      "Epoch 454: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0193 - acc: 0.9902 - val_loss: 0.0405 - val_acc: 0.9894\n",
      "Epoch 455/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 9.6550e-05 - acc: 1.0000\n",
      "Epoch 455: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0084 - acc: 0.9956 - val_loss: 0.0526 - val_acc: 0.9823\n",
      "Epoch 456/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 456: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0308 - val_acc: 0.9929\n",
      "Epoch 457/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.2524e-05 - acc: 1.0000\n",
      "Epoch 457: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 0.9929\n",
      "Epoch 458/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.3929e-05 - acc: 1.0000\n",
      "Epoch 458: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 0.0335 - val_acc: 0.9929\n",
      "Epoch 459/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 1.2852e-05 - acc: 1.0000\n",
      "Epoch 459: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.0554 - val_acc: 0.9752\n",
      "Epoch 460/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.2222e-04 - acc: 1.0000\n",
      "Epoch 460: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0066 - acc: 0.9973 - val_loss: 0.0694 - val_acc: 0.9823\n",
      "Epoch 461/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.8776e-06 - acc: 1.0000\n",
      "Epoch 461: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0133 - acc: 0.9938 - val_loss: 0.0345 - val_acc: 0.9894\n",
      "Epoch 462/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.9118e-05 - acc: 1.0000\n",
      "Epoch 462: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0323 - acc: 0.9840 - val_loss: 0.0864 - val_acc: 0.9858\n",
      "Epoch 463/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0487 - acc: 0.9688\n",
      "Epoch 463: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0242 - acc: 0.9947 - val_loss: 0.0631 - val_acc: 0.9858\n",
      "Epoch 464/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.1684e-09 - acc: 1.0000\n",
      "Epoch 464: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0338 - acc: 0.9885 - val_loss: 0.0885 - val_acc: 0.9823\n",
      "Epoch 465/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 465: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0545 - acc: 0.9840 - val_loss: 0.0905 - val_acc: 0.9610\n",
      "Epoch 466/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 466: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0191 - acc: 0.9902 - val_loss: 0.0603 - val_acc: 0.9858\n",
      "Epoch 467/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 467: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0110 - acc: 0.9956 - val_loss: 0.0394 - val_acc: 0.9858\n",
      "Epoch 468/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0171 - acc: 0.9688\n",
      "Epoch 468: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.0511 - val_acc: 0.9858\n",
      "Epoch 469/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/36 [..............................] - ETA: 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 469: val_loss did not improve from 0.01722\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0047 - acc: 0.9982 - val_loss: 0.0341 - val_acc: 0.9929\n",
      "Epoch 470/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 7.4119e-05 - acc: 1.0000\n",
      "Epoch 470: val_loss improved from 0.01722 to 0.01546, saving model to best_pose_model.hdf5\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0066 - acc: 0.9973 - val_loss: 0.0155 - val_acc: 0.9929\n",
      "Epoch 471/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 9.3616e-04 - acc: 1.0000\n",
      "Epoch 471: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0292 - acc: 0.9902 - val_loss: 0.0338 - val_acc: 0.9894\n",
      "Epoch 472/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 472: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1210 - acc: 0.9689 - val_loss: 0.0639 - val_acc: 0.9787\n",
      "Epoch 473/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 473: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0542 - acc: 0.9769 - val_loss: 0.0595 - val_acc: 0.9894\n",
      "Epoch 474/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 474: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0395 - acc: 0.9849 - val_loss: 0.0798 - val_acc: 0.9539\n",
      "Epoch 475/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 475: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0323 - acc: 0.9876 - val_loss: 0.1405 - val_acc: 0.9823\n",
      "Epoch 476/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 476: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0192 - acc: 0.9929 - val_loss: 0.0715 - val_acc: 0.9823\n",
      "Epoch 477/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 477: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.0560 - val_acc: 0.9681\n",
      "Epoch 478/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 478: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0099 - acc: 0.9920 - val_loss: 0.0245 - val_acc: 0.9894\n",
      "Epoch 479/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 479: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0123 - acc: 0.9947 - val_loss: 0.0323 - val_acc: 0.9894\n",
      "Epoch 480/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 480: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0089 - acc: 0.9929 - val_loss: 0.0342 - val_acc: 0.9858\n",
      "Epoch 481/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.0413e-05 - acc: 1.0000\n",
      "Epoch 481: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0130 - acc: 0.9920 - val_loss: 0.0672 - val_acc: 0.9787\n",
      "Epoch 482/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0355 - acc: 0.9688\n",
      "Epoch 482: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0214 - acc: 0.9938 - val_loss: 0.0500 - val_acc: 0.9787\n",
      "Epoch 483/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.0091e-04 - acc: 1.0000\n",
      "Epoch 483: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0651 - val_acc: 0.9787\n",
      "Epoch 484/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0414 - acc: 1.0000\n",
      "Epoch 484: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0445 - acc: 0.9867 - val_loss: 0.1086 - val_acc: 0.9752\n",
      "Epoch 485/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 485: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0325 - acc: 0.9858 - val_loss: 0.1538 - val_acc: 0.9716\n",
      "Epoch 486/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1442 - acc: 0.9688\n",
      "Epoch 486: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0423 - acc: 0.9840 - val_loss: 0.7608 - val_acc: 0.8759\n",
      "Epoch 487/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.3599 - acc: 0.9062\n",
      "Epoch 487: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0598 - acc: 0.9734 - val_loss: 0.0395 - val_acc: 0.9929\n",
      "Epoch 488/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 488: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0298 - acc: 0.9911 - val_loss: 0.0480 - val_acc: 0.9894\n",
      "Epoch 489/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 489: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0185 - acc: 0.9876 - val_loss: 0.0255 - val_acc: 0.9894\n",
      "Epoch 490/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.6293e-04 - acc: 1.0000\n",
      "Epoch 490: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0171 - acc: 0.9911 - val_loss: 0.0241 - val_acc: 0.9752\n",
      "Epoch 491/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.2612e-04 - acc: 1.0000\n",
      "Epoch 491: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - acc: 0.9964 - val_loss: 0.0507 - val_acc: 0.9787\n",
      "Epoch 492/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 2.3329e-04 - acc: 1.0000\n",
      "Epoch 492: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0084 - acc: 0.9947 - val_loss: 0.0582 - val_acc: 0.9894\n",
      "Epoch 493/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.3698e-06 - acc: 1.0000\n",
      "Epoch 493: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0064 - acc: 0.9964 - val_loss: 0.0406 - val_acc: 0.9752\n",
      "Epoch 494/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 494: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0756 - acc: 0.9707 - val_loss: 0.0514 - val_acc: 0.9787\n",
      "Epoch 495/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0724 - acc: 0.9688\n",
      "Epoch 495: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0198 - acc: 0.9920 - val_loss: 0.0458 - val_acc: 0.9894\n",
      "Epoch 496/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0248 - acc: 0.9688\n",
      "Epoch 496: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0358 - acc: 0.9840 - val_loss: 0.0857 - val_acc: 0.9645\n",
      "Epoch 497/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.1928 - acc: 0.9375\n",
      "Epoch 497: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0287 - acc: 0.9849 - val_loss: 0.0294 - val_acc: 0.9823\n",
      "Epoch 498/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0965 - acc: 0.9375\n",
      "Epoch 498: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1274 - acc: 0.9636 - val_loss: 0.4298 - val_acc: 0.9007\n",
      "Epoch 499/500\n",
      " 1/36 [..............................] - ETA: 0s - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 499: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2085 - acc: 0.9414 - val_loss: 0.1009 - val_acc: 0.9716\n",
      "Epoch 500/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/36 [..............................] - ETA: 0s - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 500: val_loss did not improve from 0.01546\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0501 - acc: 0.9885 - val_loss: 0.0584 - val_acc: 0.9823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x558d5b208250) is not the object's thread (0x558d5ad28100).\n",
      "Cannot move to target thread (0x558d5b208250)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def detect_live(version):\n",
    "    # load model\n",
    "    try:\n",
    "        model = keras.models.load_model(\"pose_model_\" + str(version) + \".h5\")\n",
    "    except:\n",
    "        model = train(version)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 3 * 200)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 4 * 200)\n",
    "    ## Setup mediapipe instance\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make detection\n",
    "            result = pose.process(image)\n",
    "            pose_landmarks = result.pose_landmarks\n",
    "\n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, result.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                     )            \n",
    "\n",
    "            # Save landmarks.\n",
    "            if pose_landmarks is not None:\n",
    "                # Check the number of landmarks and take pose landmarks.\n",
    "                assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
    "                pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
    "                frame_height, frame_width = image.shape[:2]\n",
    "                pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
    "                #pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(str).tolist()\n",
    "                pose_landmarks = np.around(pose_landmarks, 5).flatten()\n",
    "\n",
    "                # predicting\n",
    "                features = embedder(version, pose_landmarks)\n",
    "                #print(features)\n",
    "                features = np.expand_dims(features, axis=0).astype(float)\n",
    "                prediction_list = list(model.predict(features, verbose=0)[0])\n",
    "                prediction_id = prediction_list.index(max(prediction_list))\n",
    "\n",
    "                # show on screen\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                text = 'Pose Id: ' + id_to_pose[prediction_id] + \" \" + str(round(max(prediction_list)*100)) + \"%\"\n",
    "                cv2.putText(image, text, (50, 50), font, 1, (255, 0, 0),2, cv2.LINE_4)\n",
    "\n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "detect_live(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
