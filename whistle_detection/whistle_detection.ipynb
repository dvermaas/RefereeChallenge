{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs & Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 11:53:24.647622: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-21 11:53:24.647653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Extracting Features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import IPython\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "# Training neural networks\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Live detection\n",
    "import pyaudio\n",
    "from IPython.display import clear_output\n",
    "import wave\n",
    "\n",
    "# ms per chunk\n",
    "STEP = 50\n",
    "PATH = \"whistle_dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The chunk processor will get a sample with a feature type, and will utilize these to process said chunk into features. The chunk processor is used in both featurizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chunk_processor(sample, sample_rate, feature_type, target, false_window = 1, true_window= 1/50):\n",
    "#def chunk_processor(sample, sample_rate, feature_type, target, false_window = 10, true_window= 1/5):\n",
    "def chunk_processor(sample, sample_rate, feature_type, target, false_window = 25, true_window= 1/2):\n",
    "    \n",
    "    # get correct window variable\n",
    "    if target:\n",
    "        window = true_window\n",
    "    else:\n",
    "        window = false_window\n",
    "        \n",
    "    # calculate chunk size\n",
    "    chunk = int((sample_rate / 1000) * STEP)\n",
    "    \n",
    "    # iterate over sample and fetch features\n",
    "    for i in tqdm(range(0, len(sample) - chunk, int(chunk * window)), leave=False):\n",
    "        if feature_type == \"fft\":\n",
    "            chunk_features = np.mean(np.abs(librosa.stft(sample[i:i+chunk], n_fft=512, hop_length=256, win_length=512)).T, axis=0)\n",
    "        elif feature_type == \"mfcc\":\n",
    "            chunk_features = np.mean(librosa.feature.mfcc(y=sample[i:i+chunk], sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        \n",
    "        try:\n",
    "            features = np.append(features, np.array([chunk_features]), axis=0)\n",
    "        except:\n",
    "            features = np.array([chunk_features])\n",
    "            \n",
    "    return features, np.full(len(features), int(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurizer V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Featurizer 1 only uses the whistle, and the segments before and after (same length). This is how a 2:1 label ratio is managed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_dataframe_v1(feature_type, denoise=False):\n",
    "    \"\"\"Convert all whistles and small fragments before and after said whistles into features\"\"\"\n",
    "    \n",
    "    # See if csv has been calculated before (saving time)\n",
    "    try:\n",
    "        df = pd.read_csv(\"data_v1_\" + feature_type + \"_\" + str(denoise) + \".csv\", index_col=0)\n",
    "        print(\"Dataframe succesfully loaded from csv!\")\n",
    "        return df\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # get the labels\n",
    "    target = []\n",
    "    with open(PATH + \"whistledb.json\") as json_file:\n",
    "        labels = json.load(json_file)[\"audioFiles\"]\n",
    "        labels = {entry[\"path\"] : entry[\"channels\"][1][\"whistleLabels\"] for entry in labels}\n",
    "    \n",
    "    # iterate over all audiofiles\n",
    "    for file_name in tqdm(os.listdir(PATH)):\n",
    "        # skip json file\n",
    "        if file_name.split(\".\")[-1] != \"wav\":\n",
    "            continue\n",
    "\n",
    "        # load file & meta data\n",
    "        sample, sample_rate = librosa.load(PATH + file_name, sr=None)\n",
    "        if denoise == True:\n",
    "            sample = nr.reduce_noise(y=sample,  y_noise=sample[0:5000], sr=sample_rate)\n",
    "\n",
    "        # for all positive intervals get part before and after aswell and featurize\n",
    "        for times in tqdm(labels[file_name], leave=False):\n",
    "            delta_time = times[\"end\"] - times[\"start\"]\n",
    "            \n",
    "            label = False\n",
    "            for i in range(times[\"start\"]-delta_time, times[\"end\"]+delta_time, delta_time):\n",
    "                if i >= 0 and i + delta_time <= len(sample):\n",
    "                    features, targets = chunk_processor(sample[i:i+delta_time], sample_rate, feature_type, label, \n",
    "                                                        false_window = 1/5, true_window= 1/5)\n",
    "                    label = not(label)\n",
    "                    try:\n",
    "                        out = np.append(out, features, axis=0)\n",
    "                        target = np.append(target, targets)\n",
    "                    except:\n",
    "                        out = features\n",
    "                        target = targets\n",
    "                else:\n",
    "                    print(file_name, i, 'no fit ;(')\n",
    "\n",
    "    # save them in dataframe\n",
    "    df = pd.DataFrame(out)\n",
    "    df=(df-df.min())/(df.max()-df.min())\n",
    "    df.insert(0, \"target\", target)\n",
    "    df.to_csv(\"data_v1_\" + feature_type + \"_\" + str(denoise) + \".csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurizer V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Featurizer 2 utilises two different overlap values. True labels have 1/2 overlap, meaning that sequential samples have 50% overlap. False labels have a overlap value of 25, meaning that after each sample taken 24 are skipped. This insures that a 2:1 label ratio is kept while still taking a more fair representation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_dataframe_v2(feature_type, denoise=False):\n",
    "    \n",
    "    # See if csv has been calculated before (saving time)\n",
    "    try:\n",
    "        df = pd.read_csv(\"data_v2_\" + feature_type + \"_\" + str(denoise) + \".csv\", index_col=0)\n",
    "        print(\"Dataframe succesfully loaded from csv!\")\n",
    "        return df\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # get the labels\n",
    "    target = []\n",
    "    with open(PATH + \"whistledb.json\") as json_file:\n",
    "        labels = json.load(json_file)[\"audioFiles\"]\n",
    "        labels = {entry[\"path\"] : entry[\"channels\"][1][\"whistleLabels\"] for entry in labels}\n",
    "    \n",
    "    # iterate over all audiofiles\n",
    "    for file_name in tqdm(os.listdir(PATH)):\n",
    "        # skip json file\n",
    "        if file_name.split(\".\")[-1] != \"wav\":\n",
    "            continue\n",
    "\n",
    "        # load file & meta data\n",
    "        sample, sample_rate = librosa.load(PATH + file_name, sr=None)\n",
    "        if denoise == True:\n",
    "            sample = nr.reduce_noise(y=sample,  y_noise=sample[0:5000], sr=sample_rate)\n",
    "        \n",
    "        # create time intervals\n",
    "        times_list = [0]\n",
    "        for times in labels[file_name]:\n",
    "            times_list += [times[\"start\"], times[\"end\"]]\n",
    "        if times_list[-1] < len(sample):\n",
    "            times_list.append(len(sample))\n",
    "        \n",
    "        label = False\n",
    "        for i in tqdm(range(len(times_list)-1), leave=False):\n",
    "            features, targets = chunk_processor(sample[times_list[i]:times_list[i+1]], sample_rate, feature_type, label)\n",
    "            label = not(label)\n",
    "            try:\n",
    "                out = np.append(out, features, axis=0)\n",
    "                target = np.append(target, targets)\n",
    "            except:\n",
    "                out = features\n",
    "                target = targets\n",
    "\n",
    "    # save them in dataframe\n",
    "    df = pd.DataFrame(out)\n",
    "    df=(df-df.min())/(df.max()-df.min())\n",
    "    df.insert(0, \"target\", target)\n",
    "    df.to_csv(\"data_v2_\" + feature_type + \"_\" + str(denoise) + \".csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(version, feature_type, denoise):\n",
    "    if version == 1:\n",
    "        return build_feature_dataframe_v1(feature_type, denoise)\n",
    "    elif version == 2:\n",
    "        return build_feature_dataframe_v2(feature_type, denoise)\n",
    "    else:\n",
    "        print(\"invalid version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7129bb6d335d45f18bc92cc53bdde341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhistleTest_tuhhnao16.wav 28116000 no fit ;(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label ratio: 33.5 %\n"
     ]
    }
   ],
   "source": [
    "mass_data = build_features(1, \"mfcc\", False)\n",
    "print(\"True label ratio:\", round((len(mass_data[mass_data[\"target\"] == 1]) / len(mass_data[\"target\"])) * 100, 1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following code allows for any whistle sample to be extracted in order to check if they are labeled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestBHuman_03_05_2017_1413.wav\n",
      "[{'start': 445000, 'end': 480000, 'coreStart': 447000, 'coreEnd': 455000}, {'start': 3065000, 'end': 3110000, 'coreStart': 0, 'coreEnd': 0}] 2\n"
     ]
    }
   ],
   "source": [
    "# Choose recording\n",
    "i = -1\n",
    "fname = os.listdir(PATH)[i]\n",
    "print(fname)\n",
    "\n",
    "with open(PATH + \"whistledb.json\") as json_file:\n",
    "    labels = json.load(json_file)[\"audioFiles\"]\n",
    "    labels = {entry[\"path\"] : entry[\"channels\"][1][\"whistleLabels\"] for entry in labels}\n",
    "print(labels[fname], len(labels[fname]))\n",
    "\n",
    "sample_tts, sr = librosa.load(PATH + fname, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lab_Fox40_vs_printed.wav', 'WhistleTest_tuhhnao12.wav', 'HTWK_HULKs_1930_2016_04_29.wav', 'LUnitedvsUPenn20170728Half2.wav', 'HTWK_Dutch_05_04_2017.wav', 'LUnitedvsUPenn20170728.wav', 'WhistleTest_tuhhnao16.wav', 'SRC_Dutch_05-04-2017.wav', 'whistledb.json', 'HTWK_Dutch_05_04_2017-2.wav', 'TestBHuman_03_05_2017_1413.wav']\n",
      "3065000 3110000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose whistle number\n",
    "i = -1\n",
    "print(os.listdir(PATH))\n",
    "print(labels[fname][i][\"start\"],labels[fname][i][\"end\"])\n",
    "\n",
    "IPython.display.Audio(sample_tts[labels[fname][i][\"start\"]:labels[fname][i][\"end\"]], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomise and split dataframe into X and Y\n",
    "def feature_target_split(df, shuffle=True):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac = 1)\n",
    "    \n",
    "    dataset = df.values\n",
    "    X = dataset[:,1:].astype(float)\n",
    "    \n",
    "    Y = dataset[:,0]\n",
    "    encoder = sklearn.preprocessing.LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "    Y = encoder.transform(Y)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_integrated(X):\n",
    "    inputs = Input(shape= (X.shape[1],))\n",
    "    layer = Dense(128, activation=\"relu\")(inputs)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(layer)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(loss = \"binary_crossentropy\",optimizer = \"adam\",metrics = [\"acc\"])\n",
    "    mc = ModelCheckpoint(\"best_model_simple.hdf5\", monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "    return model, mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe succesfully loaded from csv!\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 11:54:16.144996: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-21 11:54:16.145011: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-21 11:54:16.145033: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dan-XPS-15): /proc/driver/nvidia/version does not exist\n",
      "2022-06-21 11:54:16.145353: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/376 [===========================>..] - ETA: 0s - loss: 0.3938 - acc: 0.8284\n",
      "Epoch 1: val_loss improved from inf to 0.22039, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.3873 - acc: 0.8319 - val_loss: 0.2204 - val_acc: 0.9284\n",
      "Epoch 2/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.1922 - acc: 0.9293\n",
      "Epoch 2: val_loss improved from 0.22039 to 0.14920, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1890 - acc: 0.9310 - val_loss: 0.1492 - val_acc: 0.9444\n",
      "Epoch 3/200\n",
      "332/376 [=========================>....] - ETA: 0s - loss: 0.1439 - acc: 0.9469\n",
      "Epoch 3: val_loss improved from 0.14920 to 0.12161, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.1431 - acc: 0.9472 - val_loss: 0.1216 - val_acc: 0.9530\n",
      "Epoch 4/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.1230 - acc: 0.9542\n",
      "Epoch 4: val_loss improved from 0.12161 to 0.10208, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1216 - acc: 0.9546 - val_loss: 0.1021 - val_acc: 0.9617\n",
      "Epoch 5/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.1068 - acc: 0.9609\n",
      "Epoch 5: val_loss improved from 0.10208 to 0.09187, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1065 - acc: 0.9607 - val_loss: 0.0919 - val_acc: 0.9687\n",
      "Epoch 6/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0979 - acc: 0.9635\n",
      "Epoch 6: val_loss improved from 0.09187 to 0.08236, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0970 - acc: 0.9638 - val_loss: 0.0824 - val_acc: 0.9707\n",
      "Epoch 7/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0887 - acc: 0.9676\n",
      "Epoch 7: val_loss improved from 0.08236 to 0.07650, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0879 - acc: 0.9679 - val_loss: 0.0765 - val_acc: 0.9724\n",
      "Epoch 8/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0804 - acc: 0.9695\n",
      "Epoch 8: val_loss improved from 0.07650 to 0.07553, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0809 - acc: 0.9692 - val_loss: 0.0755 - val_acc: 0.9697\n",
      "Epoch 9/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9720\n",
      "Epoch 9: val_loss improved from 0.07553 to 0.06540, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0758 - acc: 0.9716 - val_loss: 0.0654 - val_acc: 0.9744\n",
      "Epoch 10/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9728\n",
      "Epoch 10: val_loss improved from 0.06540 to 0.06199, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0725 - acc: 0.9729 - val_loss: 0.0620 - val_acc: 0.9764\n",
      "Epoch 11/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0664 - acc: 0.9746\n",
      "Epoch 11: val_loss did not improve from 0.06199\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0666 - acc: 0.9747 - val_loss: 0.0629 - val_acc: 0.9767\n",
      "Epoch 12/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0642 - acc: 0.9751\n",
      "Epoch 12: val_loss did not improve from 0.06199\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0639 - acc: 0.9749 - val_loss: 0.0628 - val_acc: 0.9747\n",
      "Epoch 13/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0623 - acc: 0.9767\n",
      "Epoch 13: val_loss improved from 0.06199 to 0.05859, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0622 - acc: 0.9764 - val_loss: 0.0586 - val_acc: 0.9784\n",
      "Epoch 14/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0589 - acc: 0.9775\n",
      "Epoch 14: val_loss improved from 0.05859 to 0.05598, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0589 - acc: 0.9775 - val_loss: 0.0560 - val_acc: 0.9787\n",
      "Epoch 15/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0554 - acc: 0.9797\n",
      "Epoch 15: val_loss improved from 0.05598 to 0.05438, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0558 - acc: 0.9793 - val_loss: 0.0544 - val_acc: 0.9764\n",
      "Epoch 16/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9788\n",
      "Epoch 16: val_loss improved from 0.05438 to 0.05060, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0557 - acc: 0.9788 - val_loss: 0.0506 - val_acc: 0.9810\n",
      "Epoch 17/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9794\n",
      "Epoch 17: val_loss improved from 0.05060 to 0.04730, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0536 - acc: 0.9794 - val_loss: 0.0473 - val_acc: 0.9820\n",
      "Epoch 18/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9807\n",
      "Epoch 18: val_loss improved from 0.04730 to 0.04719, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0508 - acc: 0.9804 - val_loss: 0.0472 - val_acc: 0.9817\n",
      "Epoch 19/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0502 - acc: 0.9811\n",
      "Epoch 19: val_loss did not improve from 0.04719\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0498 - acc: 0.9814 - val_loss: 0.0522 - val_acc: 0.9777\n",
      "Epoch 20/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0482 - acc: 0.9812\n",
      "Epoch 20: val_loss improved from 0.04719 to 0.04636, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0478 - acc: 0.9815 - val_loss: 0.0464 - val_acc: 0.9824\n",
      "Epoch 21/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9817\n",
      "Epoch 21: val_loss improved from 0.04636 to 0.04324, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0485 - acc: 0.9816 - val_loss: 0.0432 - val_acc: 0.9843\n",
      "Epoch 22/200\n",
      "335/376 [=========================>....] - ETA: 0s - loss: 0.0460 - acc: 0.9837\n",
      "Epoch 22: val_loss improved from 0.04324 to 0.04319, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0472 - acc: 0.9829 - val_loss: 0.0432 - val_acc: 0.9830\n",
      "Epoch 23/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0448 - acc: 0.9826\n",
      "Epoch 23: val_loss did not improve from 0.04319\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0455 - acc: 0.9823 - val_loss: 0.0440 - val_acc: 0.9820\n",
      "Epoch 24/200\n",
      "335/376 [=========================>....] - ETA: 0s - loss: 0.0450 - acc: 0.9815\n",
      "Epoch 24: val_loss did not improve from 0.04319\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0451 - acc: 0.9821 - val_loss: 0.0453 - val_acc: 0.9824\n",
      "Epoch 25/200\n",
      "324/376 [========================>.....] - ETA: 0s - loss: 0.0447 - acc: 0.9831\n",
      "Epoch 25: val_loss did not improve from 0.04319\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0444 - acc: 0.9833 - val_loss: 0.0461 - val_acc: 0.9817\n",
      "Epoch 26/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9832\n",
      "Epoch 26: val_loss improved from 0.04319 to 0.04130, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0428 - acc: 0.9829 - val_loss: 0.0413 - val_acc: 0.9820\n",
      "Epoch 27/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0442 - acc: 0.9810\n",
      "Epoch 27: val_loss improved from 0.04130 to 0.03951, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0435 - acc: 0.9819 - val_loss: 0.0395 - val_acc: 0.9847\n",
      "Epoch 28/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0423 - acc: 0.9829\n",
      "Epoch 28: val_loss did not improve from 0.03951\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0419 - acc: 0.9830 - val_loss: 0.0405 - val_acc: 0.9850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0415 - acc: 0.9840\n",
      "Epoch 29: val_loss did not improve from 0.03951\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0413 - acc: 0.9841 - val_loss: 0.0419 - val_acc: 0.9830\n",
      "Epoch 30/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9843\n",
      "Epoch 30: val_loss did not improve from 0.03951\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0399 - acc: 0.9843 - val_loss: 0.0429 - val_acc: 0.9837\n",
      "Epoch 31/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0424 - acc: 0.9840\n",
      "Epoch 31: val_loss improved from 0.03951 to 0.03928, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0424 - acc: 0.9840 - val_loss: 0.0393 - val_acc: 0.9830\n",
      "Epoch 32/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0399 - acc: 0.9842\n",
      "Epoch 32: val_loss improved from 0.03928 to 0.03845, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0399 - acc: 0.9841 - val_loss: 0.0384 - val_acc: 0.9843\n",
      "Epoch 33/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9850\n",
      "Epoch 33: val_loss improved from 0.03845 to 0.03833, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0386 - acc: 0.9850 - val_loss: 0.0383 - val_acc: 0.9840\n",
      "Epoch 34/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9866\n",
      "Epoch 34: val_loss improved from 0.03833 to 0.03827, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0372 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9847\n",
      "Epoch 35/200\n",
      "330/376 [=========================>....] - ETA: 0s - loss: 0.0382 - acc: 0.9863\n",
      "Epoch 35: val_loss improved from 0.03827 to 0.03743, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0371 - acc: 0.9867 - val_loss: 0.0374 - val_acc: 0.9863\n",
      "Epoch 36/200\n",
      "328/376 [=========================>....] - ETA: 0s - loss: 0.0355 - acc: 0.9873\n",
      "Epoch 36: val_loss did not improve from 0.03743\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0362 - acc: 0.9870 - val_loss: 0.0387 - val_acc: 0.9853\n",
      "Epoch 37/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0363 - acc: 0.9862\n",
      "Epoch 37: val_loss did not improve from 0.03743\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0366 - acc: 0.9859 - val_loss: 0.0442 - val_acc: 0.9827\n",
      "Epoch 38/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0377 - acc: 0.9862\n",
      "Epoch 38: val_loss did not improve from 0.03743\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0365 - acc: 0.9870 - val_loss: 0.0377 - val_acc: 0.9843\n",
      "Epoch 39/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9859\n",
      "Epoch 39: val_loss did not improve from 0.03743\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0365 - acc: 0.9858 - val_loss: 0.0386 - val_acc: 0.9853\n",
      "Epoch 40/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0345 - acc: 0.9876\n",
      "Epoch 40: val_loss improved from 0.03743 to 0.03617, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0343 - acc: 0.9878 - val_loss: 0.0362 - val_acc: 0.9853\n",
      "Epoch 41/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9877\n",
      "Epoch 41: val_loss did not improve from 0.03617\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0340 - acc: 0.9878 - val_loss: 0.0407 - val_acc: 0.9833\n",
      "Epoch 42/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0360 - acc: 0.9874\n",
      "Epoch 42: val_loss did not improve from 0.03617\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0361 - acc: 0.9872 - val_loss: 0.0367 - val_acc: 0.9843\n",
      "Epoch 43/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0356 - acc: 0.9856\n",
      "Epoch 43: val_loss did not improve from 0.03617\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0352 - acc: 0.9856 - val_loss: 0.0396 - val_acc: 0.9843\n",
      "Epoch 44/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0339 - acc: 0.9864\n",
      "Epoch 44: val_loss did not improve from 0.03617\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0343 - acc: 0.9863 - val_loss: 0.0378 - val_acc: 0.9840\n",
      "Epoch 45/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9885\n",
      "Epoch 45: val_loss improved from 0.03617 to 0.03427, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0333 - acc: 0.9885 - val_loss: 0.0343 - val_acc: 0.9863\n",
      "Epoch 46/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9886\n",
      "Epoch 46: val_loss did not improve from 0.03427\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0327 - acc: 0.9885 - val_loss: 0.0345 - val_acc: 0.9853\n",
      "Epoch 47/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0322 - acc: 0.9873\n",
      "Epoch 47: val_loss did not improve from 0.03427\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0323 - acc: 0.9875 - val_loss: 0.0382 - val_acc: 0.9843\n",
      "Epoch 48/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0336 - acc: 0.9864\n",
      "Epoch 48: val_loss did not improve from 0.03427\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0335 - acc: 0.9867 - val_loss: 0.0362 - val_acc: 0.9853\n",
      "Epoch 49/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0313 - acc: 0.9883\n",
      "Epoch 49: val_loss improved from 0.03427 to 0.03423, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0308 - acc: 0.9884 - val_loss: 0.0342 - val_acc: 0.9860\n",
      "Epoch 50/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0324 - acc: 0.9885\n",
      "Epoch 50: val_loss improved from 0.03423 to 0.03382, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0327 - acc: 0.9885 - val_loss: 0.0338 - val_acc: 0.9873\n",
      "Epoch 51/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9866\n",
      "Epoch 51: val_loss did not improve from 0.03382\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0335 - acc: 0.9868 - val_loss: 0.0345 - val_acc: 0.9857\n",
      "Epoch 52/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9876\n",
      "Epoch 52: val_loss improved from 0.03382 to 0.03294, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0316 - acc: 0.9878 - val_loss: 0.0329 - val_acc: 0.9867\n",
      "Epoch 53/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9890\n",
      "Epoch 53: val_loss did not improve from 0.03294\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0303 - acc: 0.9890 - val_loss: 0.0353 - val_acc: 0.9860\n",
      "Epoch 54/200\n",
      "324/376 [========================>.....] - ETA: 0s - loss: 0.0295 - acc: 0.9883\n",
      "Epoch 54: val_loss did not improve from 0.03294\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0297 - acc: 0.9886 - val_loss: 0.0341 - val_acc: 0.9850\n",
      "Epoch 55/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9882\n",
      "Epoch 55: val_loss did not improve from 0.03294\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0307 - acc: 0.9882 - val_loss: 0.0359 - val_acc: 0.9870\n",
      "Epoch 56/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0297 - acc: 0.9888\n",
      "Epoch 56: val_loss did not improve from 0.03294\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0297 - acc: 0.9888 - val_loss: 0.0332 - val_acc: 0.9867\n",
      "Epoch 57/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9892\n",
      "Epoch 57: val_loss did not improve from 0.03294\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0290 - acc: 0.9892 - val_loss: 0.0364 - val_acc: 0.9860\n",
      "Epoch 58/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0311 - acc: 0.9881\n",
      "Epoch 58: val_loss did not improve from 0.03294\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0308 - acc: 0.9883 - val_loss: 0.0337 - val_acc: 0.9860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0285 - acc: 0.9886\n",
      "Epoch 59: val_loss improved from 0.03294 to 0.03117, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0287 - acc: 0.9883 - val_loss: 0.0312 - val_acc: 0.9877\n",
      "Epoch 60/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0283 - acc: 0.9900\n",
      "Epoch 60: val_loss did not improve from 0.03117\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0283 - acc: 0.9899 - val_loss: 0.0379 - val_acc: 0.9833\n",
      "Epoch 61/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9899\n",
      "Epoch 61: val_loss improved from 0.03117 to 0.03000, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0284 - acc: 0.9901 - val_loss: 0.0300 - val_acc: 0.9877\n",
      "Epoch 62/200\n",
      "330/376 [=========================>....] - ETA: 0s - loss: 0.0286 - acc: 0.9898\n",
      "Epoch 62: val_loss did not improve from 0.03000\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0280 - acc: 0.9900 - val_loss: 0.0314 - val_acc: 0.9867\n",
      "Epoch 63/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0290 - acc: 0.9882\n",
      "Epoch 63: val_loss improved from 0.03000 to 0.02971, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0290 - acc: 0.9882 - val_loss: 0.0297 - val_acc: 0.9887\n",
      "Epoch 64/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0276 - acc: 0.9895\n",
      "Epoch 64: val_loss did not improve from 0.02971\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0279 - acc: 0.9893 - val_loss: 0.0343 - val_acc: 0.9860\n",
      "Epoch 65/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9888\n",
      "Epoch 65: val_loss did not improve from 0.02971\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0293 - acc: 0.9888 - val_loss: 0.0307 - val_acc: 0.9877\n",
      "Epoch 66/200\n",
      "327/376 [=========================>....] - ETA: 0s - loss: 0.0272 - acc: 0.9900\n",
      "Epoch 66: val_loss did not improve from 0.02971\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0276 - acc: 0.9895 - val_loss: 0.0315 - val_acc: 0.9860\n",
      "Epoch 67/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0273 - acc: 0.9892\n",
      "Epoch 67: val_loss did not improve from 0.02971\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0271 - acc: 0.9893 - val_loss: 0.0321 - val_acc: 0.9877\n",
      "Epoch 68/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0267 - acc: 0.9908\n",
      "Epoch 68: val_loss improved from 0.02971 to 0.02953, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0267 - acc: 0.9908 - val_loss: 0.0295 - val_acc: 0.9877\n",
      "Epoch 69/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0273 - acc: 0.9900\n",
      "Epoch 69: val_loss did not improve from 0.02953\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0276 - acc: 0.9898 - val_loss: 0.0309 - val_acc: 0.9873\n",
      "Epoch 70/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0265 - acc: 0.9904\n",
      "Epoch 70: val_loss did not improve from 0.02953\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0267 - acc: 0.9903 - val_loss: 0.0303 - val_acc: 0.9880\n",
      "Epoch 71/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0269 - acc: 0.9900\n",
      "Epoch 71: val_loss did not improve from 0.02953\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0265 - acc: 0.9902 - val_loss: 0.0319 - val_acc: 0.9850\n",
      "Epoch 72/200\n",
      "324/376 [========================>.....] - ETA: 0s - loss: 0.0268 - acc: 0.9887\n",
      "Epoch 72: val_loss did not improve from 0.02953\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0265 - acc: 0.9893 - val_loss: 0.0466 - val_acc: 0.9840\n",
      "Epoch 73/200\n",
      "328/376 [=========================>....] - ETA: 0s - loss: 0.0251 - acc: 0.9914\n",
      "Epoch 73: val_loss did not improve from 0.02953\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0257 - acc: 0.9909 - val_loss: 0.0307 - val_acc: 0.9873\n",
      "Epoch 74/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9894\n",
      "Epoch 74: val_loss did not improve from 0.02953\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0258 - acc: 0.9895 - val_loss: 0.0445 - val_acc: 0.9833\n",
      "Epoch 75/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0244 - acc: 0.9916\n",
      "Epoch 75: val_loss improved from 0.02953 to 0.02921, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0242 - acc: 0.9918 - val_loss: 0.0292 - val_acc: 0.9883\n",
      "Epoch 76/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0275 - acc: 0.9895\n",
      "Epoch 76: val_loss did not improve from 0.02921\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0341 - val_acc: 0.9883\n",
      "Epoch 77/200\n",
      "326/376 [=========================>....] - ETA: 0s - loss: 0.0271 - acc: 0.9899\n",
      "Epoch 77: val_loss did not improve from 0.02921\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0255 - acc: 0.9908 - val_loss: 0.0327 - val_acc: 0.9870\n",
      "Epoch 78/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0242 - acc: 0.9912\n",
      "Epoch 78: val_loss did not improve from 0.02921\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0247 - acc: 0.9911 - val_loss: 0.0349 - val_acc: 0.9857\n",
      "Epoch 79/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0245 - acc: 0.9905\n",
      "Epoch 79: val_loss improved from 0.02921 to 0.02876, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0253 - acc: 0.9900 - val_loss: 0.0288 - val_acc: 0.9880\n",
      "Epoch 80/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0234 - acc: 0.9909\n",
      "Epoch 80: val_loss improved from 0.02876 to 0.02662, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0247 - acc: 0.9906 - val_loss: 0.0266 - val_acc: 0.9897\n",
      "Epoch 81/200\n",
      "327/376 [=========================>....] - ETA: 0s - loss: 0.0241 - acc: 0.9905\n",
      "Epoch 81: val_loss did not improve from 0.02662\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0248 - acc: 0.9902 - val_loss: 0.0325 - val_acc: 0.9873\n",
      "Epoch 82/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0236 - acc: 0.9915\n",
      "Epoch 82: val_loss did not improve from 0.02662\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0238 - acc: 0.9913 - val_loss: 0.0275 - val_acc: 0.9890\n",
      "Epoch 83/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9916\n",
      "Epoch 83: val_loss did not improve from 0.02662\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0240 - acc: 0.9916 - val_loss: 0.0277 - val_acc: 0.9880\n",
      "Epoch 84/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0232 - acc: 0.9918\n",
      "Epoch 84: val_loss improved from 0.02662 to 0.02647, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0235 - acc: 0.9916 - val_loss: 0.0265 - val_acc: 0.9883\n",
      "Epoch 85/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9905\n",
      "Epoch 85: val_loss did not improve from 0.02647\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0251 - acc: 0.9905 - val_loss: 0.0489 - val_acc: 0.9820\n",
      "Epoch 86/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9902\n",
      "Epoch 86: val_loss did not improve from 0.02647\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0255 - acc: 0.9902 - val_loss: 0.0281 - val_acc: 0.9890\n",
      "Epoch 87/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9906\n",
      "Epoch 87: val_loss did not improve from 0.02647\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0241 - acc: 0.9908 - val_loss: 0.0286 - val_acc: 0.9893\n",
      "Epoch 88/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9924\n",
      "Epoch 88: val_loss did not improve from 0.02647\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0221 - acc: 0.9923 - val_loss: 0.0306 - val_acc: 0.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9911\n",
      "Epoch 89: val_loss did not improve from 0.02647\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0225 - acc: 0.9912 - val_loss: 0.0313 - val_acc: 0.9887\n",
      "Epoch 90/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0229 - acc: 0.9916\n",
      "Epoch 90: val_loss did not improve from 0.02647\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0225 - acc: 0.9917 - val_loss: 0.0381 - val_acc: 0.9850\n",
      "Epoch 91/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0242 - acc: 0.9910\n",
      "Epoch 91: val_loss improved from 0.02647 to 0.02474, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0236 - acc: 0.9914 - val_loss: 0.0247 - val_acc: 0.9903\n",
      "Epoch 92/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0240 - acc: 0.9903\n",
      "Epoch 92: val_loss did not improve from 0.02474\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0236 - acc: 0.9904 - val_loss: 0.0289 - val_acc: 0.9880\n",
      "Epoch 93/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0220 - acc: 0.9919\n",
      "Epoch 93: val_loss did not improve from 0.02474\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0219 - acc: 0.9918 - val_loss: 0.0334 - val_acc: 0.9867\n",
      "Epoch 94/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0223 - acc: 0.9915\n",
      "Epoch 94: val_loss did not improve from 0.02474\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0223 - acc: 0.9915 - val_loss: 0.0262 - val_acc: 0.9913\n",
      "Epoch 95/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9922\n",
      "Epoch 95: val_loss did not improve from 0.02474\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0208 - acc: 0.9923 - val_loss: 0.0259 - val_acc: 0.9893\n",
      "Epoch 96/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0220 - acc: 0.9924\n",
      "Epoch 96: val_loss did not improve from 0.02474\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0222 - acc: 0.9923 - val_loss: 0.0252 - val_acc: 0.9907\n",
      "Epoch 97/200\n",
      "335/376 [=========================>....] - ETA: 0s - loss: 0.0236 - acc: 0.9912\n",
      "Epoch 97: val_loss did not improve from 0.02474\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0232 - acc: 0.9916 - val_loss: 0.0269 - val_acc: 0.9890\n",
      "Epoch 98/200\n",
      "327/376 [=========================>....] - ETA: 0s - loss: 0.0222 - acc: 0.9917\n",
      "Epoch 98: val_loss did not improve from 0.02474\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0221 - acc: 0.9919 - val_loss: 0.0290 - val_acc: 0.9887\n",
      "Epoch 99/200\n",
      "334/376 [=========================>....] - ETA: 0s - loss: 0.0207 - acc: 0.9925\n",
      "Epoch 99: val_loss did not improve from 0.02474\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0216 - acc: 0.9918 - val_loss: 0.0495 - val_acc: 0.9827\n",
      "Epoch 100/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0198 - acc: 0.9926\n",
      "Epoch 100: val_loss did not improve from 0.02474\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0207 - acc: 0.9921 - val_loss: 0.0261 - val_acc: 0.9887\n",
      "Epoch 101/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9925\n",
      "Epoch 101: val_loss improved from 0.02474 to 0.02401, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0208 - acc: 0.9926 - val_loss: 0.0240 - val_acc: 0.9910\n",
      "Epoch 102/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0213 - acc: 0.9920\n",
      "Epoch 102: val_loss did not improve from 0.02401\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0214 - acc: 0.9920 - val_loss: 0.0294 - val_acc: 0.9880\n",
      "Epoch 103/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9925\n",
      "Epoch 103: val_loss did not improve from 0.02401\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0207 - acc: 0.9924 - val_loss: 0.0321 - val_acc: 0.9880\n",
      "Epoch 104/200\n",
      "330/376 [=========================>....] - ETA: 0s - loss: 0.0186 - acc: 0.9937\n",
      "Epoch 104: val_loss did not improve from 0.02401\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0197 - acc: 0.9929 - val_loss: 0.0243 - val_acc: 0.9897\n",
      "Epoch 105/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0204 - acc: 0.9928\n",
      "Epoch 105: val_loss did not improve from 0.02401\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0206 - acc: 0.9927 - val_loss: 0.0289 - val_acc: 0.9887\n",
      "Epoch 106/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9917\n",
      "Epoch 106: val_loss did not improve from 0.02401\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0218 - acc: 0.9917 - val_loss: 0.0295 - val_acc: 0.9887\n",
      "Epoch 107/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0197 - acc: 0.9931\n",
      "Epoch 107: val_loss did not improve from 0.02401\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0188 - acc: 0.9933 - val_loss: 0.0248 - val_acc: 0.9917\n",
      "Epoch 108/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9932\n",
      "Epoch 108: val_loss did not improve from 0.02401\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0202 - acc: 0.9931 - val_loss: 0.0280 - val_acc: 0.9890\n",
      "Epoch 109/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0192 - acc: 0.9930\n",
      "Epoch 109: val_loss did not improve from 0.02401\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0196 - acc: 0.9929 - val_loss: 0.0266 - val_acc: 0.9900\n",
      "Epoch 110/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9938\n",
      "Epoch 110: val_loss improved from 0.02401 to 0.02347, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0183 - acc: 0.9937 - val_loss: 0.0235 - val_acc: 0.9903\n",
      "Epoch 111/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0202 - acc: 0.9922\n",
      "Epoch 111: val_loss did not improve from 0.02347\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0198 - acc: 0.9924 - val_loss: 0.0239 - val_acc: 0.9900\n",
      "Epoch 112/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9922\n",
      "Epoch 112: val_loss did not improve from 0.02347\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0223 - acc: 0.9923 - val_loss: 0.0373 - val_acc: 0.9857\n",
      "Epoch 113/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0204 - acc: 0.9922\n",
      "Epoch 113: val_loss improved from 0.02347 to 0.02294, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0202 - acc: 0.9923 - val_loss: 0.0229 - val_acc: 0.9913\n",
      "Epoch 114/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0178 - acc: 0.9936\n",
      "Epoch 114: val_loss did not improve from 0.02294\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0185 - acc: 0.9932 - val_loss: 0.0264 - val_acc: 0.9887\n",
      "Epoch 115/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9934\n",
      "Epoch 115: val_loss improved from 0.02294 to 0.02279, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0184 - acc: 0.9931 - val_loss: 0.0228 - val_acc: 0.9903\n",
      "Epoch 116/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0181 - acc: 0.9933\n",
      "Epoch 116: val_loss did not improve from 0.02279\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0181 - acc: 0.9933 - val_loss: 0.0263 - val_acc: 0.9893\n",
      "Epoch 117/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0189 - acc: 0.9933\n",
      "Epoch 117: val_loss did not improve from 0.02279\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0195 - acc: 0.9931 - val_loss: 0.0238 - val_acc: 0.9913\n",
      "Epoch 118/200\n",
      "324/376 [========================>.....] - ETA: 0s - loss: 0.0190 - acc: 0.9931\n",
      "Epoch 118: val_loss did not improve from 0.02279\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0190 - acc: 0.9929 - val_loss: 0.0276 - val_acc: 0.9880\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/376 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9932\n",
      "Epoch 119: val_loss did not improve from 0.02279\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0185 - acc: 0.9933 - val_loss: 0.0233 - val_acc: 0.9910\n",
      "Epoch 120/200\n",
      "330/376 [=========================>....] - ETA: 0s - loss: 0.0172 - acc: 0.9937\n",
      "Epoch 120: val_loss improved from 0.02279 to 0.02201, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0188 - acc: 0.9928 - val_loss: 0.0220 - val_acc: 0.9920\n",
      "Epoch 121/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9941\n",
      "Epoch 121: val_loss did not improve from 0.02201\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0175 - acc: 0.9941 - val_loss: 0.0223 - val_acc: 0.9910\n",
      "Epoch 122/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9934\n",
      "Epoch 122: val_loss did not improve from 0.02201\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0173 - acc: 0.9935 - val_loss: 0.0233 - val_acc: 0.9903\n",
      "Epoch 123/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9937\n",
      "Epoch 123: val_loss did not improve from 0.02201\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0176 - acc: 0.9938 - val_loss: 0.0263 - val_acc: 0.9897\n",
      "Epoch 124/200\n",
      "328/376 [=========================>....] - ETA: 0s - loss: 0.0174 - acc: 0.9941\n",
      "Epoch 124: val_loss improved from 0.02201 to 0.02133, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0173 - acc: 0.9942 - val_loss: 0.0213 - val_acc: 0.9917\n",
      "Epoch 125/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0201 - acc: 0.9921\n",
      "Epoch 125: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0198 - acc: 0.9922 - val_loss: 0.0292 - val_acc: 0.9893\n",
      "Epoch 126/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9924\n",
      "Epoch 126: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0190 - acc: 0.9924 - val_loss: 0.0255 - val_acc: 0.9900\n",
      "Epoch 127/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0173 - acc: 0.9931\n",
      "Epoch 127: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0172 - acc: 0.9935 - val_loss: 0.0249 - val_acc: 0.9903\n",
      "Epoch 128/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0172 - acc: 0.9939\n",
      "Epoch 128: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0170 - acc: 0.9939 - val_loss: 0.0219 - val_acc: 0.9923\n",
      "Epoch 129/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9933\n",
      "Epoch 129: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0166 - acc: 0.9933 - val_loss: 0.0262 - val_acc: 0.9887\n",
      "Epoch 130/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0201 - acc: 0.9929\n",
      "Epoch 130: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0197 - acc: 0.9932 - val_loss: 0.0250 - val_acc: 0.9890\n",
      "Epoch 131/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9942\n",
      "Epoch 131: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0170 - acc: 0.9941 - val_loss: 0.0217 - val_acc: 0.9927\n",
      "Epoch 132/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0174 - acc: 0.9935\n",
      "Epoch 132: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0179 - acc: 0.9931 - val_loss: 0.0733 - val_acc: 0.9757\n",
      "Epoch 133/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9931\n",
      "Epoch 133: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0172 - acc: 0.9931 - val_loss: 0.0221 - val_acc: 0.9920\n",
      "Epoch 134/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9928\n",
      "Epoch 134: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0177 - acc: 0.9928 - val_loss: 0.0216 - val_acc: 0.9923\n",
      "Epoch 135/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0173 - acc: 0.9944\n",
      "Epoch 135: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0168 - acc: 0.9944 - val_loss: 0.0220 - val_acc: 0.9903\n",
      "Epoch 136/200\n",
      "332/376 [=========================>....] - ETA: 0s - loss: 0.0154 - acc: 0.9947\n",
      "Epoch 136: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0153 - acc: 0.9947 - val_loss: 0.0246 - val_acc: 0.9910\n",
      "Epoch 137/200\n",
      "330/376 [=========================>....] - ETA: 0s - loss: 0.0155 - acc: 0.9945\n",
      "Epoch 137: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0157 - acc: 0.9943 - val_loss: 0.0214 - val_acc: 0.9917\n",
      "Epoch 138/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0184 - acc: 0.9929\n",
      "Epoch 138: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0181 - acc: 0.9929 - val_loss: 0.0222 - val_acc: 0.9907\n",
      "Epoch 139/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.9944\n",
      "Epoch 139: val_loss did not improve from 0.02133\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0150 - acc: 0.9944 - val_loss: 0.0238 - val_acc: 0.9900\n",
      "Epoch 140/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0187 - acc: 0.9932\n",
      "Epoch 140: val_loss improved from 0.02133 to 0.01945, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0182 - acc: 0.9935 - val_loss: 0.0195 - val_acc: 0.9927\n",
      "Epoch 141/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9942\n",
      "Epoch 141: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0155 - acc: 0.9941 - val_loss: 0.0221 - val_acc: 0.9920\n",
      "Epoch 142/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9941\n",
      "Epoch 142: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0164 - acc: 0.9939 - val_loss: 0.0237 - val_acc: 0.9907\n",
      "Epoch 143/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0157 - acc: 0.9946\n",
      "Epoch 143: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0156 - acc: 0.9948 - val_loss: 0.0219 - val_acc: 0.9913\n",
      "Epoch 144/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0170 - acc: 0.9940\n",
      "Epoch 144: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0164 - acc: 0.9943 - val_loss: 0.0203 - val_acc: 0.9917\n",
      "Epoch 145/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0162 - acc: 0.9942\n",
      "Epoch 145: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0164 - acc: 0.9941 - val_loss: 0.0244 - val_acc: 0.9903\n",
      "Epoch 146/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0168 - acc: 0.9937\n",
      "Epoch 146: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0167 - acc: 0.9938 - val_loss: 0.0204 - val_acc: 0.9923\n",
      "Epoch 147/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0166 - acc: 0.9934\n",
      "Epoch 147: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0164 - acc: 0.9935 - val_loss: 0.0209 - val_acc: 0.9917\n",
      "Epoch 148/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0148 - acc: 0.9946\n",
      "Epoch 148: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0156 - acc: 0.9941 - val_loss: 0.0195 - val_acc: 0.9927\n",
      "Epoch 149/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9942\n",
      "Epoch 149: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0156 - acc: 0.9943 - val_loss: 0.0429 - val_acc: 0.9827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0175 - acc: 0.9939\n",
      "Epoch 150: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0173 - acc: 0.9940 - val_loss: 0.0203 - val_acc: 0.9930\n",
      "Epoch 151/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0139 - acc: 0.9949\n",
      "Epoch 151: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 0.9948 - val_loss: 0.0206 - val_acc: 0.9917\n",
      "Epoch 152/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0150 - acc: 0.9942\n",
      "Epoch 152: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0147 - acc: 0.9943 - val_loss: 0.0201 - val_acc: 0.9927\n",
      "Epoch 153/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0146 - acc: 0.9944\n",
      "Epoch 153: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 0.9944 - val_loss: 0.0242 - val_acc: 0.9890\n",
      "Epoch 154/200\n",
      "334/376 [=========================>....] - ETA: 0s - loss: 0.0149 - acc: 0.9948\n",
      "Epoch 154: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0148 - acc: 0.9945 - val_loss: 0.0208 - val_acc: 0.9930\n",
      "Epoch 155/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0140 - acc: 0.9952\n",
      "Epoch 155: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0136 - acc: 0.9952 - val_loss: 0.0213 - val_acc: 0.9917\n",
      "Epoch 156/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0133 - acc: 0.9953\n",
      "Epoch 156: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0132 - acc: 0.9953 - val_loss: 0.0234 - val_acc: 0.9903\n",
      "Epoch 157/200\n",
      "330/376 [=========================>....] - ETA: 0s - loss: 0.0164 - acc: 0.9944\n",
      "Epoch 157: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0159 - acc: 0.9945 - val_loss: 0.0223 - val_acc: 0.9893\n",
      "Epoch 158/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9946\n",
      "Epoch 158: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0149 - acc: 0.9948 - val_loss: 0.0277 - val_acc: 0.9887\n",
      "Epoch 159/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0124 - acc: 0.9961\n",
      "Epoch 159: val_loss did not improve from 0.01945\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0263 - val_acc: 0.9883\n",
      "Epoch 160/200\n",
      "325/376 [========================>.....] - ETA: 0s - loss: 0.0146 - acc: 0.9955\n",
      "Epoch 160: val_loss improved from 0.01945 to 0.01801, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0143 - acc: 0.9955 - val_loss: 0.0180 - val_acc: 0.9930\n",
      "Epoch 161/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0135 - acc: 0.9948\n",
      "Epoch 161: val_loss did not improve from 0.01801\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0136 - acc: 0.9947 - val_loss: 0.0192 - val_acc: 0.9927\n",
      "Epoch 162/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0143 - acc: 0.9941\n",
      "Epoch 162: val_loss improved from 0.01801 to 0.01733, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0141 - acc: 0.9943 - val_loss: 0.0173 - val_acc: 0.9940\n",
      "Epoch 163/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0148 - acc: 0.9950\n",
      "Epoch 163: val_loss did not improve from 0.01733\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0147 - acc: 0.9948 - val_loss: 0.0232 - val_acc: 0.9920\n",
      "Epoch 164/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9957\n",
      "Epoch 164: val_loss did not improve from 0.01733\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0131 - acc: 0.9957 - val_loss: 0.0240 - val_acc: 0.9910\n",
      "Epoch 165/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0134 - acc: 0.9954\n",
      "Epoch 165: val_loss did not improve from 0.01733\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0131 - acc: 0.9956 - val_loss: 0.0202 - val_acc: 0.9933\n",
      "Epoch 166/200\n",
      "326/376 [=========================>....] - ETA: 0s - loss: 0.0122 - acc: 0.9954\n",
      "Epoch 166: val_loss did not improve from 0.01733\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0122 - acc: 0.9956 - val_loss: 0.0256 - val_acc: 0.9887\n",
      "Epoch 167/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0144 - acc: 0.9942\n",
      "Epoch 167: val_loss did not improve from 0.01733\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0148 - acc: 0.9941 - val_loss: 0.0249 - val_acc: 0.9903\n",
      "Epoch 168/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0143 - acc: 0.9949\n",
      "Epoch 168: val_loss did not improve from 0.01733\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0146 - acc: 0.9948 - val_loss: 0.0205 - val_acc: 0.9920\n",
      "Epoch 169/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9951\n",
      "Epoch 169: val_loss did not improve from 0.01733\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.9952 - val_loss: 0.0195 - val_acc: 0.9927\n",
      "Epoch 170/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9954\n",
      "Epoch 170: val_loss did not improve from 0.01733\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0136 - acc: 0.9953 - val_loss: 0.0208 - val_acc: 0.9923\n",
      "Epoch 171/200\n",
      "332/376 [=========================>....] - ETA: 0s - loss: 0.0128 - acc: 0.9956\n",
      "Epoch 171: val_loss improved from 0.01733 to 0.01731, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0129 - acc: 0.9955 - val_loss: 0.0173 - val_acc: 0.9930\n",
      "Epoch 172/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9951\n",
      "Epoch 172: val_loss did not improve from 0.01731\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0126 - acc: 0.9952 - val_loss: 0.0183 - val_acc: 0.9943\n",
      "Epoch 173/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0124 - acc: 0.9958\n",
      "Epoch 173: val_loss did not improve from 0.01731\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0125 - acc: 0.9958 - val_loss: 0.0193 - val_acc: 0.9927\n",
      "Epoch 174/200\n",
      "330/376 [=========================>....] - ETA: 0s - loss: 0.0131 - acc: 0.9956\n",
      "Epoch 174: val_loss did not improve from 0.01731\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0128 - acc: 0.9955 - val_loss: 0.0230 - val_acc: 0.9923\n",
      "Epoch 175/200\n",
      "324/376 [========================>.....] - ETA: 0s - loss: 0.0131 - acc: 0.9957\n",
      "Epoch 175: val_loss did not improve from 0.01731\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0132 - acc: 0.9955 - val_loss: 0.0222 - val_acc: 0.9933\n",
      "Epoch 176/200\n",
      "321/376 [========================>.....] - ETA: 0s - loss: 0.0131 - acc: 0.9954\n",
      "Epoch 176: val_loss did not improve from 0.01731\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0125 - acc: 0.9957 - val_loss: 0.0176 - val_acc: 0.9943\n",
      "Epoch 177/200\n",
      "330/376 [=========================>....] - ETA: 0s - loss: 0.0125 - acc: 0.9952\n",
      "Epoch 177: val_loss did not improve from 0.01731\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0124 - acc: 0.9953 - val_loss: 0.0184 - val_acc: 0.9930\n",
      "Epoch 178/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0124 - acc: 0.9953\n",
      "Epoch 178: val_loss did not improve from 0.01731\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.9952 - val_loss: 0.0202 - val_acc: 0.9913\n",
      "Epoch 179/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0127 - acc: 0.9952\n",
      "Epoch 179: val_loss did not improve from 0.01731\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.9949 - val_loss: 0.0315 - val_acc: 0.9877\n",
      "Epoch 180/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0115 - acc: 0.9956\n",
      "Epoch 180: val_loss did not improve from 0.01731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.9954 - val_loss: 0.0214 - val_acc: 0.9917\n",
      "Epoch 181/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0126 - acc: 0.9954\n",
      "Epoch 181: val_loss improved from 0.01731 to 0.01715, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0126 - acc: 0.9955 - val_loss: 0.0172 - val_acc: 0.9947\n",
      "Epoch 182/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9952\n",
      "Epoch 182: val_loss improved from 0.01715 to 0.01687, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0125 - acc: 0.9952 - val_loss: 0.0169 - val_acc: 0.9930\n",
      "Epoch 183/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0115 - acc: 0.9960\n",
      "Epoch 183: val_loss did not improve from 0.01687\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0190 - val_acc: 0.9920\n",
      "Epoch 184/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0113 - acc: 0.9961\n",
      "Epoch 184: val_loss did not improve from 0.01687\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9963 - val_loss: 0.0169 - val_acc: 0.9940\n",
      "Epoch 185/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0122 - acc: 0.9955\n",
      "Epoch 185: val_loss improved from 0.01687 to 0.01661, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.9954 - val_loss: 0.0166 - val_acc: 0.9947\n",
      "Epoch 186/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0105 - acc: 0.9965\n",
      "Epoch 186: val_loss did not improve from 0.01661\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0228 - val_acc: 0.9907\n",
      "Epoch 187/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0119 - acc: 0.9958\n",
      "Epoch 187: val_loss did not improve from 0.01661\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0190 - val_acc: 0.9923\n",
      "Epoch 188/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0114 - acc: 0.9965\n",
      "Epoch 188: val_loss improved from 0.01661 to 0.01651, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.0165 - val_acc: 0.9940\n",
      "Epoch 189/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 189: val_loss did not improve from 0.01651\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.9963 - val_loss: 0.0175 - val_acc: 0.9940\n",
      "Epoch 190/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0125 - acc: 0.9952\n",
      "Epoch 190: val_loss did not improve from 0.01651\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0125 - acc: 0.9952 - val_loss: 0.0220 - val_acc: 0.9913\n",
      "Epoch 191/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0107 - acc: 0.9961\n",
      "Epoch 191: val_loss did not improve from 0.01651\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0107 - acc: 0.9961 - val_loss: 0.0242 - val_acc: 0.9903\n",
      "Epoch 192/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9961\n",
      "Epoch 192: val_loss did not improve from 0.01651\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0182 - val_acc: 0.9923\n",
      "Epoch 193/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0101 - acc: 0.9968\n",
      "Epoch 193: val_loss improved from 0.01651 to 0.01567, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0157 - val_acc: 0.9947\n",
      "Epoch 194/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9962\n",
      "Epoch 194: val_loss improved from 0.01567 to 0.01538, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0154 - val_acc: 0.9937\n",
      "Epoch 195/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9970\n",
      "Epoch 195: val_loss improved from 0.01538 to 0.01536, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0154 - val_acc: 0.9947\n",
      "Epoch 196/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9959\n",
      "Epoch 196: val_loss did not improve from 0.01536\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.9957 - val_loss: 0.0190 - val_acc: 0.9927\n",
      "Epoch 197/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9962\n",
      "Epoch 197: val_loss did not improve from 0.01536\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0106 - acc: 0.9963 - val_loss: 0.0162 - val_acc: 0.9943\n",
      "Epoch 198/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0109 - acc: 0.9963\n",
      "Epoch 198: val_loss did not improve from 0.01536\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0112 - acc: 0.9962 - val_loss: 0.0221 - val_acc: 0.9913\n",
      "Epoch 199/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0095 - acc: 0.9965\n",
      "Epoch 199: val_loss did not improve from 0.01536\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0096 - acc: 0.9965 - val_loss: 0.0178 - val_acc: 0.9930\n",
      "Epoch 200/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9958\n",
      "Epoch 200: val_loss did not improve from 0.01536\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.9958 - val_loss: 0.0158 - val_acc: 0.9940\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train(X_train, X_test, Y_train, Y_test, version, feature_type, denoise, plot=False):\n",
    "    \n",
    "    # model training\n",
    "    model, model_checkpoint = two_layer_integrated(X_train)\n",
    "    history = model.fit(X_train, Y_train ,epochs=200, callbacks=[model_checkpoint], batch_size=32, \n",
    "                        validation_data=(X_test, Y_test))\n",
    "\n",
    "    # load the best model weights\n",
    "    model.load_weights('best_model_simple.hdf5')\n",
    "    \n",
    "    # save model\n",
    "    model.save(\"model_v\" + str(version) + \"_\" + feature_type + \"_\" + str(denoise) + \".h5\")\n",
    "\n",
    "    # summarize history for loss\n",
    "    if plot:\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "    return model\n",
    "        \n",
    "def train_model(version, feature_type, denoise):\n",
    "    # load data\n",
    "    mass_data = build_features(version, feature_type, denoise)\n",
    "    \n",
    "    # train test split\n",
    "    X, Y = feature_target_split(mass_data)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, \n",
    "                                                        random_state=12, shuffle=True)\n",
    "    \n",
    "    return X_test, Y_test, train(X_train, X_test, Y_train, Y_test, version, feature_type, denoise, plot=True)\n",
    "        \n",
    "\n",
    "X_test, Y_test, model = train_model(1, \"mfcc\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 767us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2d19447e80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, [1 if prediction > .5 else 0 for prediction in model.predict(X_test)[:,0]])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])\n",
    "disp.plot(cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e998984119e4c8997cd0d0dcc8f2a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhistleTest_tuhhnao16.wav 28116000 no fit ;(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.3104 - acc: 0.8944\n",
      "Epoch 1: val_loss improved from inf to 0.20099, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.3070 - acc: 0.8950 - val_loss: 0.2010 - val_acc: 0.9184\n",
      "Epoch 2/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9412\n",
      "Epoch 2: val_loss improved from 0.20099 to 0.15080, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1626 - acc: 0.9407 - val_loss: 0.1508 - val_acc: 0.9447\n",
      "Epoch 3/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.1335 - acc: 0.9529\n",
      "Epoch 3: val_loss improved from 0.15080 to 0.13103, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1356 - acc: 0.9516 - val_loss: 0.1310 - val_acc: 0.9514\n",
      "Epoch 4/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9561\n",
      "Epoch 4: val_loss improved from 0.13103 to 0.12271, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1203 - acc: 0.9562 - val_loss: 0.1227 - val_acc: 0.9534\n",
      "Epoch 5/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.1114 - acc: 0.9596\n",
      "Epoch 5: val_loss improved from 0.12271 to 0.11167, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1106 - acc: 0.9601 - val_loss: 0.1117 - val_acc: 0.9577\n",
      "Epoch 6/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.1041 - acc: 0.9623\n",
      "Epoch 6: val_loss improved from 0.11167 to 0.10856, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1040 - acc: 0.9625 - val_loss: 0.1086 - val_acc: 0.9584\n",
      "Epoch 7/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9648\n",
      "Epoch 7: val_loss improved from 0.10856 to 0.10178, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0980 - acc: 0.9646 - val_loss: 0.1018 - val_acc: 0.9617\n",
      "Epoch 8/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0918 - acc: 0.9660\n",
      "Epoch 8: val_loss did not improve from 0.10178\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0933 - acc: 0.9658 - val_loss: 0.1023 - val_acc: 0.9617\n",
      "Epoch 9/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9675\n",
      "Epoch 9: val_loss improved from 0.10178 to 0.09671, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0895 - acc: 0.9674 - val_loss: 0.0967 - val_acc: 0.9660\n",
      "Epoch 10/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9684\n",
      "Epoch 10: val_loss did not improve from 0.09671\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0862 - acc: 0.9685 - val_loss: 0.0991 - val_acc: 0.9647\n",
      "Epoch 11/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0832 - acc: 0.9682\n",
      "Epoch 11: val_loss improved from 0.09671 to 0.08977, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0820 - acc: 0.9689 - val_loss: 0.0898 - val_acc: 0.9647\n",
      "Epoch 12/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9717\n",
      "Epoch 12: val_loss improved from 0.08977 to 0.08455, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0794 - acc: 0.9713 - val_loss: 0.0845 - val_acc: 0.9664\n",
      "Epoch 13/200\n",
      "334/376 [=========================>....] - ETA: 0s - loss: 0.0766 - acc: 0.9708\n",
      "Epoch 13: val_loss improved from 0.08455 to 0.08306, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0763 - acc: 0.9709 - val_loss: 0.0831 - val_acc: 0.9694\n",
      "Epoch 14/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0739 - acc: 0.9723\n",
      "Epoch 14: val_loss did not improve from 0.08306\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0724 - acc: 0.9732 - val_loss: 0.0838 - val_acc: 0.9677\n",
      "Epoch 15/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0695 - acc: 0.9733\n",
      "Epoch 15: val_loss improved from 0.08306 to 0.07507, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0704 - acc: 0.9732 - val_loss: 0.0751 - val_acc: 0.9700\n",
      "Epoch 16/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9744\n",
      "Epoch 16: val_loss improved from 0.07507 to 0.07291, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0678 - acc: 0.9741 - val_loss: 0.0729 - val_acc: 0.9717\n",
      "Epoch 17/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0650 - acc: 0.9759\n",
      "Epoch 17: val_loss did not improve from 0.07291\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0650 - acc: 0.9758 - val_loss: 0.0750 - val_acc: 0.9714\n",
      "Epoch 18/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9753\n",
      "Epoch 18: val_loss did not improve from 0.07291\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0645 - acc: 0.9754 - val_loss: 0.0753 - val_acc: 0.9704\n",
      "Epoch 19/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0599 - acc: 0.9778\n",
      "Epoch 19: val_loss improved from 0.07291 to 0.07086, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0608 - acc: 0.9774 - val_loss: 0.0709 - val_acc: 0.9740\n",
      "Epoch 20/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9770\n",
      "Epoch 20: val_loss improved from 0.07086 to 0.06675, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0591 - acc: 0.9772 - val_loss: 0.0668 - val_acc: 0.9750\n",
      "Epoch 21/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0569 - acc: 0.9784\n",
      "Epoch 21: val_loss improved from 0.06675 to 0.06506, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0572 - acc: 0.9780 - val_loss: 0.0651 - val_acc: 0.9740\n",
      "Epoch 22/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0543 - acc: 0.9796\n",
      "Epoch 22: val_loss improved from 0.06506 to 0.06141, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0551 - acc: 0.9794 - val_loss: 0.0614 - val_acc: 0.9754\n",
      "Epoch 23/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0532 - acc: 0.9803\n",
      "Epoch 23: val_loss did not improve from 0.06141\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0528 - acc: 0.9804 - val_loss: 0.0616 - val_acc: 0.9777\n",
      "Epoch 24/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0517 - acc: 0.9804\n",
      "Epoch 24: val_loss improved from 0.06141 to 0.05746, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0522 - acc: 0.9801 - val_loss: 0.0575 - val_acc: 0.9794\n",
      "Epoch 25/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0519 - acc: 0.9823\n",
      "Epoch 25: val_loss improved from 0.05746 to 0.05620, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0520 - acc: 0.9820 - val_loss: 0.0562 - val_acc: 0.9787\n",
      "Epoch 26/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0501 - acc: 0.9812\n",
      "Epoch 26: val_loss did not improve from 0.05620\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0496 - acc: 0.9814 - val_loss: 0.0567 - val_acc: 0.9770\n",
      "Epoch 27/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9820\n",
      "Epoch 27: val_loss improved from 0.05620 to 0.05413, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0490 - acc: 0.9821 - val_loss: 0.0541 - val_acc: 0.9807\n",
      "Epoch 28/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9830\n",
      "Epoch 28: val_loss improved from 0.05413 to 0.05369, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0474 - acc: 0.9829 - val_loss: 0.0537 - val_acc: 0.9817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0448 - acc: 0.9835\n",
      "Epoch 29: val_loss improved from 0.05369 to 0.05273, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0460 - acc: 0.9830 - val_loss: 0.0527 - val_acc: 0.9814\n",
      "Epoch 30/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9843\n",
      "Epoch 30: val_loss improved from 0.05273 to 0.05225, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0445 - acc: 0.9843 - val_loss: 0.0522 - val_acc: 0.9810\n",
      "Epoch 31/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0447 - acc: 0.9838\n",
      "Epoch 31: val_loss improved from 0.05225 to 0.05068, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0447 - acc: 0.9838 - val_loss: 0.0507 - val_acc: 0.9814\n",
      "Epoch 32/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0442 - acc: 0.9836\n",
      "Epoch 32: val_loss improved from 0.05068 to 0.04956, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0432 - acc: 0.9841 - val_loss: 0.0496 - val_acc: 0.9820\n",
      "Epoch 33/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0429 - acc: 0.9841\n",
      "Epoch 33: val_loss did not improve from 0.04956\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0429 - acc: 0.9841 - val_loss: 0.0501 - val_acc: 0.9820\n",
      "Epoch 34/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0427 - acc: 0.9845\n",
      "Epoch 34: val_loss improved from 0.04956 to 0.04806, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0430 - acc: 0.9844 - val_loss: 0.0481 - val_acc: 0.9827\n",
      "Epoch 35/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0408 - acc: 0.9854\n",
      "Epoch 35: val_loss did not improve from 0.04806\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0413 - acc: 0.9851 - val_loss: 0.0517 - val_acc: 0.9804\n",
      "Epoch 36/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0404 - acc: 0.9852\n",
      "Epoch 36: val_loss improved from 0.04806 to 0.04782, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0402 - acc: 0.9852 - val_loss: 0.0478 - val_acc: 0.9824\n",
      "Epoch 37/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0394 - acc: 0.9850\n",
      "Epoch 37: val_loss improved from 0.04782 to 0.04729, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0392 - acc: 0.9853 - val_loss: 0.0473 - val_acc: 0.9824\n",
      "Epoch 38/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0391 - acc: 0.9853\n",
      "Epoch 38: val_loss improved from 0.04729 to 0.04727, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0390 - acc: 0.9856 - val_loss: 0.0473 - val_acc: 0.9814\n",
      "Epoch 39/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0380 - acc: 0.9862\n",
      "Epoch 39: val_loss improved from 0.04727 to 0.04515, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0379 - acc: 0.9863 - val_loss: 0.0452 - val_acc: 0.9820\n",
      "Epoch 40/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0408 - acc: 0.9842\n",
      "Epoch 40: val_loss improved from 0.04515 to 0.04508, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0396 - acc: 0.9849 - val_loss: 0.0451 - val_acc: 0.9824\n",
      "Epoch 41/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0378 - acc: 0.9862\n",
      "Epoch 41: val_loss improved from 0.04508 to 0.04500, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0371 - acc: 0.9862 - val_loss: 0.0450 - val_acc: 0.9840\n",
      "Epoch 42/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0355 - acc: 0.9863\n",
      "Epoch 42: val_loss did not improve from 0.04500\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0361 - acc: 0.9861 - val_loss: 0.0484 - val_acc: 0.9800\n",
      "Epoch 43/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9863\n",
      "Epoch 43: val_loss did not improve from 0.04500\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0357 - acc: 0.9863 - val_loss: 0.0501 - val_acc: 0.9800\n",
      "Epoch 44/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9862\n",
      "Epoch 44: val_loss improved from 0.04500 to 0.04473, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0356 - acc: 0.9863 - val_loss: 0.0447 - val_acc: 0.9827\n",
      "Epoch 45/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0340 - acc: 0.9874\n",
      "Epoch 45: val_loss did not improve from 0.04473\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0352 - acc: 0.9868 - val_loss: 0.0448 - val_acc: 0.9830\n",
      "Epoch 46/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9873\n",
      "Epoch 46: val_loss did not improve from 0.04473\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0348 - acc: 0.9873 - val_loss: 0.0456 - val_acc: 0.9817\n",
      "Epoch 47/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9871\n",
      "Epoch 47: val_loss improved from 0.04473 to 0.04420, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0345 - acc: 0.9872 - val_loss: 0.0442 - val_acc: 0.9827\n",
      "Epoch 48/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9877\n",
      "Epoch 48: val_loss improved from 0.04420 to 0.04397, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0335 - acc: 0.9876 - val_loss: 0.0440 - val_acc: 0.9827\n",
      "Epoch 49/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9874\n",
      "Epoch 49: val_loss improved from 0.04397 to 0.04253, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0333 - acc: 0.9873 - val_loss: 0.0425 - val_acc: 0.9824\n",
      "Epoch 50/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0325 - acc: 0.9875\n",
      "Epoch 50: val_loss did not improve from 0.04253\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0328 - acc: 0.9873 - val_loss: 0.0457 - val_acc: 0.9820\n",
      "Epoch 51/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0323 - acc: 0.9885\n",
      "Epoch 51: val_loss did not improve from 0.04253\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0320 - acc: 0.9887 - val_loss: 0.0457 - val_acc: 0.9814\n",
      "Epoch 52/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9887\n",
      "Epoch 52: val_loss did not improve from 0.04253\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0315 - acc: 0.9888 - val_loss: 0.0467 - val_acc: 0.9804\n",
      "Epoch 53/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9878\n",
      "Epoch 53: val_loss improved from 0.04253 to 0.04118, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0316 - acc: 0.9880 - val_loss: 0.0412 - val_acc: 0.9833\n",
      "Epoch 54/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0309 - acc: 0.9879\n",
      "Epoch 54: val_loss did not improve from 0.04118\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0316 - acc: 0.9874 - val_loss: 0.0512 - val_acc: 0.9824\n",
      "Epoch 55/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9885\n",
      "Epoch 55: val_loss did not improve from 0.04118\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0305 - acc: 0.9884 - val_loss: 0.0412 - val_acc: 0.9830\n",
      "Epoch 56/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0292 - acc: 0.9892\n",
      "Epoch 56: val_loss did not improve from 0.04118\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0297 - acc: 0.9891 - val_loss: 0.0476 - val_acc: 0.9804\n",
      "Epoch 57/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0308 - acc: 0.9882\n",
      "Epoch 57: val_loss improved from 0.04118 to 0.04091, saving model to best_model_simple.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0305 - acc: 0.9883 - val_loss: 0.0409 - val_acc: 0.9827\n",
      "Epoch 58/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0282 - acc: 0.9889\n",
      "Epoch 58: val_loss did not improve from 0.04091\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0294 - acc: 0.9883 - val_loss: 0.0530 - val_acc: 0.9814\n",
      "Epoch 59/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9895\n",
      "Epoch 59: val_loss improved from 0.04091 to 0.03950, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0291 - acc: 0.9896 - val_loss: 0.0395 - val_acc: 0.9840\n",
      "Epoch 60/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9883\n",
      "Epoch 60: val_loss improved from 0.03950 to 0.03926, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0312 - acc: 0.9884 - val_loss: 0.0393 - val_acc: 0.9853\n",
      "Epoch 61/200\n",
      "335/376 [=========================>....] - ETA: 0s - loss: 0.0256 - acc: 0.9904\n",
      "Epoch 61: val_loss improved from 0.03926 to 0.03766, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0278 - acc: 0.9894 - val_loss: 0.0377 - val_acc: 0.9843\n",
      "Epoch 62/200\n",
      "332/376 [=========================>....] - ETA: 0s - loss: 0.0274 - acc: 0.9901\n",
      "Epoch 62: val_loss did not improve from 0.03766\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0273 - acc: 0.9902 - val_loss: 0.0415 - val_acc: 0.9833\n",
      "Epoch 63/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0287 - acc: 0.9889\n",
      "Epoch 63: val_loss improved from 0.03766 to 0.03724, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0285 - acc: 0.9889 - val_loss: 0.0372 - val_acc: 0.9843\n",
      "Epoch 64/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0276 - acc: 0.9896\n",
      "Epoch 64: val_loss did not improve from 0.03724\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0269 - acc: 0.9899 - val_loss: 0.0377 - val_acc: 0.9833\n",
      "Epoch 65/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9896\n",
      "Epoch 65: val_loss improved from 0.03724 to 0.03663, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0272 - acc: 0.9896 - val_loss: 0.0366 - val_acc: 0.9833\n",
      "Epoch 66/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0262 - acc: 0.9899\n",
      "Epoch 66: val_loss did not improve from 0.03663\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0385 - val_acc: 0.9840\n",
      "Epoch 67/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0255 - acc: 0.9909\n",
      "Epoch 67: val_loss improved from 0.03663 to 0.03650, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0259 - acc: 0.9906 - val_loss: 0.0365 - val_acc: 0.9847\n",
      "Epoch 68/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9892\n",
      "Epoch 68: val_loss improved from 0.03650 to 0.03621, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0272 - acc: 0.9892 - val_loss: 0.0362 - val_acc: 0.9850\n",
      "Epoch 69/200\n",
      "332/376 [=========================>....] - ETA: 0s - loss: 0.0259 - acc: 0.9899\n",
      "Epoch 69: val_loss improved from 0.03621 to 0.03610, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0253 - acc: 0.9900 - val_loss: 0.0361 - val_acc: 0.9843\n",
      "Epoch 70/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0256 - acc: 0.9899\n",
      "Epoch 70: val_loss improved from 0.03610 to 0.03546, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0256 - acc: 0.9899 - val_loss: 0.0355 - val_acc: 0.9847\n",
      "Epoch 71/200\n",
      "332/376 [=========================>....] - ETA: 0s - loss: 0.0247 - acc: 0.9908\n",
      "Epoch 71: val_loss did not improve from 0.03546\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0252 - acc: 0.9907 - val_loss: 0.0357 - val_acc: 0.9847\n",
      "Epoch 72/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0251 - acc: 0.9915\n",
      "Epoch 72: val_loss did not improve from 0.03546\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0243 - acc: 0.9916 - val_loss: 0.0393 - val_acc: 0.9840\n",
      "Epoch 73/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9898\n",
      "Epoch 73: val_loss did not improve from 0.03546\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0262 - acc: 0.9897 - val_loss: 0.0472 - val_acc: 0.9830\n",
      "Epoch 74/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 74: val_loss improved from 0.03546 to 0.03493, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0238 - acc: 0.9917 - val_loss: 0.0349 - val_acc: 0.9853\n",
      "Epoch 75/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9908\n",
      "Epoch 75: val_loss did not improve from 0.03493\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0239 - acc: 0.9906 - val_loss: 0.0371 - val_acc: 0.9843\n",
      "Epoch 76/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0232 - acc: 0.9914\n",
      "Epoch 76: val_loss did not improve from 0.03493\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0232 - acc: 0.9914 - val_loss: 0.0382 - val_acc: 0.9833\n",
      "Epoch 77/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9905\n",
      "Epoch 77: val_loss did not improve from 0.03493\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0243 - acc: 0.9903 - val_loss: 0.0363 - val_acc: 0.9837\n",
      "Epoch 78/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9913\n",
      "Epoch 78: val_loss improved from 0.03493 to 0.03446, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0231 - acc: 0.9913 - val_loss: 0.0345 - val_acc: 0.9857\n",
      "Epoch 79/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9911\n",
      "Epoch 79: val_loss improved from 0.03446 to 0.03390, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0241 - acc: 0.9912 - val_loss: 0.0339 - val_acc: 0.9847\n",
      "Epoch 80/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0222 - acc: 0.9917\n",
      "Epoch 80: val_loss did not improve from 0.03390\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0222 - acc: 0.9917 - val_loss: 0.0344 - val_acc: 0.9847\n",
      "Epoch 81/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9917\n",
      "Epoch 81: val_loss did not improve from 0.03390\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0220 - acc: 0.9918 - val_loss: 0.0343 - val_acc: 0.9860\n",
      "Epoch 82/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0211 - acc: 0.9922\n",
      "Epoch 82: val_loss did not improve from 0.03390\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0215 - acc: 0.9922 - val_loss: 0.0365 - val_acc: 0.9837\n",
      "Epoch 83/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0222 - acc: 0.9921\n",
      "Epoch 83: val_loss did not improve from 0.03390\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0220 - acc: 0.9922 - val_loss: 0.0344 - val_acc: 0.9857\n",
      "Epoch 84/200\n",
      "335/376 [=========================>....] - ETA: 0s - loss: 0.0223 - acc: 0.9917\n",
      "Epoch 84: val_loss did not improve from 0.03390\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0215 - acc: 0.9922 - val_loss: 0.0354 - val_acc: 0.9840\n",
      "Epoch 85/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0212 - acc: 0.9915\n",
      "Epoch 85: val_loss improved from 0.03390 to 0.03246, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0212 - acc: 0.9915 - val_loss: 0.0325 - val_acc: 0.9860\n",
      "Epoch 86/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0221 - acc: 0.9917\n",
      "Epoch 86: val_loss did not improve from 0.03246\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0220 - acc: 0.9919 - val_loss: 0.0332 - val_acc: 0.9847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0212 - acc: 0.9926\n",
      "Epoch 87: val_loss improved from 0.03246 to 0.03205, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0213 - acc: 0.9927 - val_loss: 0.0320 - val_acc: 0.9853\n",
      "Epoch 88/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9923\n",
      "Epoch 88: val_loss improved from 0.03205 to 0.03199, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0214 - acc: 0.9923 - val_loss: 0.0320 - val_acc: 0.9860\n",
      "Epoch 89/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0209 - acc: 0.9918\n",
      "Epoch 89: val_loss improved from 0.03199 to 0.03143, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0207 - acc: 0.9918 - val_loss: 0.0314 - val_acc: 0.9877\n",
      "Epoch 90/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0206 - acc: 0.9920\n",
      "Epoch 90: val_loss did not improve from 0.03143\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0199 - acc: 0.9924 - val_loss: 0.0343 - val_acc: 0.9840\n",
      "Epoch 91/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0206 - acc: 0.9929\n",
      "Epoch 91: val_loss did not improve from 0.03143\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0201 - acc: 0.9931 - val_loss: 0.0315 - val_acc: 0.9863\n",
      "Epoch 92/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0206 - acc: 0.9929\n",
      "Epoch 92: val_loss improved from 0.03143 to 0.03127, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0206 - acc: 0.9929 - val_loss: 0.0313 - val_acc: 0.9857\n",
      "Epoch 93/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0196 - acc: 0.9935\n",
      "Epoch 93: val_loss did not improve from 0.03127\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0196 - acc: 0.9935 - val_loss: 0.0313 - val_acc: 0.9877\n",
      "Epoch 94/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0192 - acc: 0.9935\n",
      "Epoch 94: val_loss did not improve from 0.03127\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0192 - acc: 0.9934 - val_loss: 0.0357 - val_acc: 0.9867\n",
      "Epoch 95/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0185 - acc: 0.9936\n",
      "Epoch 95: val_loss improved from 0.03127 to 0.03067, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0185 - acc: 0.9936 - val_loss: 0.0307 - val_acc: 0.9863\n",
      "Epoch 96/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9930\n",
      "Epoch 96: val_loss did not improve from 0.03067\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0196 - acc: 0.9929 - val_loss: 0.0345 - val_acc: 0.9860\n",
      "Epoch 97/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9934\n",
      "Epoch 97: val_loss improved from 0.03067 to 0.02973, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0185 - acc: 0.9936 - val_loss: 0.0297 - val_acc: 0.9887\n",
      "Epoch 98/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9934\n",
      "Epoch 98: val_loss did not improve from 0.02973\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0180 - acc: 0.9934 - val_loss: 0.0304 - val_acc: 0.9863\n",
      "Epoch 99/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0208 - acc: 0.9922\n",
      "Epoch 99: val_loss did not improve from 0.02973\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0200 - acc: 0.9925 - val_loss: 0.0302 - val_acc: 0.9860\n",
      "Epoch 100/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0187 - acc: 0.9932\n",
      "Epoch 100: val_loss did not improve from 0.02973\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0187 - acc: 0.9930 - val_loss: 0.0299 - val_acc: 0.9880\n",
      "Epoch 101/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0179 - acc: 0.9940\n",
      "Epoch 101: val_loss did not improve from 0.02973\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0175 - acc: 0.9941 - val_loss: 0.0299 - val_acc: 0.9867\n",
      "Epoch 102/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9939\n",
      "Epoch 102: val_loss did not improve from 0.02973\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0179 - acc: 0.9938 - val_loss: 0.0308 - val_acc: 0.9880\n",
      "Epoch 103/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0183 - acc: 0.9934\n",
      "Epoch 103: val_loss did not improve from 0.02973\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0178 - acc: 0.9937 - val_loss: 0.0325 - val_acc: 0.9857\n",
      "Epoch 104/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9943\n",
      "Epoch 104: val_loss did not improve from 0.02973\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0359 - val_acc: 0.9847\n",
      "Epoch 105/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0171 - acc: 0.9947\n",
      "Epoch 105: val_loss did not improve from 0.02973\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0302 - val_acc: 0.9857\n",
      "Epoch 106/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0182 - acc: 0.9935\n",
      "Epoch 106: val_loss did not improve from 0.02973\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0178 - acc: 0.9938 - val_loss: 0.0331 - val_acc: 0.9853\n",
      "Epoch 107/200\n",
      "331/376 [=========================>....] - ETA: 0s - loss: 0.0180 - acc: 0.9941\n",
      "Epoch 107: val_loss did not improve from 0.02973\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0180 - acc: 0.9940 - val_loss: 0.0298 - val_acc: 0.9863\n",
      "Epoch 108/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0168 - acc: 0.9937\n",
      "Epoch 108: val_loss improved from 0.02973 to 0.02856, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0164 - acc: 0.9939 - val_loss: 0.0286 - val_acc: 0.9863\n",
      "Epoch 109/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0160 - acc: 0.9949\n",
      "Epoch 109: val_loss did not improve from 0.02856\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0311 - val_acc: 0.9860\n",
      "Epoch 110/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0174 - acc: 0.9943\n",
      "Epoch 110: val_loss improved from 0.02856 to 0.02851, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0171 - acc: 0.9943 - val_loss: 0.0285 - val_acc: 0.9867\n",
      "Epoch 111/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0164 - acc: 0.9945\n",
      "Epoch 111: val_loss did not improve from 0.02851\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0166 - acc: 0.9943 - val_loss: 0.0291 - val_acc: 0.9870\n",
      "Epoch 112/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0161 - acc: 0.9943\n",
      "Epoch 112: val_loss did not improve from 0.02851\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0162 - acc: 0.9941 - val_loss: 0.0297 - val_acc: 0.9887\n",
      "Epoch 113/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0154 - acc: 0.9945\n",
      "Epoch 113: val_loss did not improve from 0.02851\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0156 - acc: 0.9943 - val_loss: 0.0335 - val_acc: 0.9873\n",
      "Epoch 114/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0163 - acc: 0.9942\n",
      "Epoch 114: val_loss did not improve from 0.02851\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0159 - acc: 0.9945 - val_loss: 0.0317 - val_acc: 0.9877\n",
      "Epoch 115/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9948\n",
      "Epoch 115: val_loss did not improve from 0.02851\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0157 - acc: 0.9947 - val_loss: 0.0303 - val_acc: 0.9890\n",
      "Epoch 116/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0151 - acc: 0.9945\n",
      "Epoch 116: val_loss improved from 0.02851 to 0.02764, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0153 - acc: 0.9946 - val_loss: 0.0276 - val_acc: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9950\n",
      "Epoch 117: val_loss did not improve from 0.02764\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0156 - acc: 0.9950 - val_loss: 0.0291 - val_acc: 0.9860\n",
      "Epoch 118/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9957\n",
      "Epoch 118: val_loss did not improve from 0.02764\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0144 - acc: 0.9957 - val_loss: 0.0374 - val_acc: 0.9853\n",
      "Epoch 119/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0154 - acc: 0.9944\n",
      "Epoch 119: val_loss did not improve from 0.02764\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0153 - acc: 0.9944 - val_loss: 0.0297 - val_acc: 0.9880\n",
      "Epoch 120/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0147 - acc: 0.9949\n",
      "Epoch 120: val_loss did not improve from 0.02764\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0147 - acc: 0.9950 - val_loss: 0.0346 - val_acc: 0.9867\n",
      "Epoch 121/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0144 - acc: 0.9947\n",
      "Epoch 121: val_loss improved from 0.02764 to 0.02694, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0140 - acc: 0.9948 - val_loss: 0.0269 - val_acc: 0.9897\n",
      "Epoch 122/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9949\n",
      "Epoch 122: val_loss improved from 0.02694 to 0.02653, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0146 - acc: 0.9951 - val_loss: 0.0265 - val_acc: 0.9893\n",
      "Epoch 123/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9956\n",
      "Epoch 123: val_loss did not improve from 0.02653\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 0.9954 - val_loss: 0.0265 - val_acc: 0.9897\n",
      "Epoch 124/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9962\n",
      "Epoch 124: val_loss improved from 0.02653 to 0.02593, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0135 - acc: 0.9960 - val_loss: 0.0259 - val_acc: 0.9893\n",
      "Epoch 125/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0140 - acc: 0.9953\n",
      "Epoch 125: val_loss did not improve from 0.02593\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0288 - val_acc: 0.9893\n",
      "Epoch 126/200\n",
      "335/376 [=========================>....] - ETA: 0s - loss: 0.0138 - acc: 0.9950\n",
      "Epoch 126: val_loss did not improve from 0.02593\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0136 - acc: 0.9953 - val_loss: 0.0264 - val_acc: 0.9900\n",
      "Epoch 127/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0139 - acc: 0.9958\n",
      "Epoch 127: val_loss did not improve from 0.02593\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0272 - val_acc: 0.9870\n",
      "Epoch 128/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9956\n",
      "Epoch 128: val_loss did not improve from 0.02593\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0129 - acc: 0.9957 - val_loss: 0.0294 - val_acc: 0.9890\n",
      "Epoch 129/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0128 - acc: 0.9956\n",
      "Epoch 129: val_loss did not improve from 0.02593\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.9954 - val_loss: 0.0261 - val_acc: 0.9883\n",
      "Epoch 130/200\n",
      "331/376 [=========================>....] - ETA: 0s - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 130: val_loss did not improve from 0.02593\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0131 - acc: 0.9958 - val_loss: 0.0268 - val_acc: 0.9890\n",
      "Epoch 131/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0125 - acc: 0.9958\n",
      "Epoch 131: val_loss did not improve from 0.02593\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0128 - acc: 0.9958 - val_loss: 0.0276 - val_acc: 0.9887\n",
      "Epoch 132/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0136 - acc: 0.9957\n",
      "Epoch 132: val_loss improved from 0.02593 to 0.02568, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.9958 - val_loss: 0.0257 - val_acc: 0.9890\n",
      "Epoch 133/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9958\n",
      "Epoch 133: val_loss did not improve from 0.02568\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0126 - acc: 0.9958 - val_loss: 0.0258 - val_acc: 0.9893\n",
      "Epoch 134/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9950\n",
      "Epoch 134: val_loss improved from 0.02568 to 0.02510, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0125 - acc: 0.9949 - val_loss: 0.0251 - val_acc: 0.9897\n",
      "Epoch 135/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0125 - acc: 0.9958\n",
      "Epoch 135: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.9958 - val_loss: 0.0252 - val_acc: 0.9907\n",
      "Epoch 136/200\n",
      "335/376 [=========================>....] - ETA: 0s - loss: 0.0120 - acc: 0.9965\n",
      "Epoch 136: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0125 - acc: 0.9963 - val_loss: 0.0288 - val_acc: 0.9877\n",
      "Epoch 137/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0122 - acc: 0.9960\n",
      "Epoch 137: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0258 - val_acc: 0.9887\n",
      "Epoch 138/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0148 - acc: 0.9948\n",
      "Epoch 138: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0145 - acc: 0.9950 - val_loss: 0.0258 - val_acc: 0.9887\n",
      "Epoch 139/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0118 - acc: 0.9955\n",
      "Epoch 139: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.9956 - val_loss: 0.0254 - val_acc: 0.9887\n",
      "Epoch 140/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9964\n",
      "Epoch 140: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.0255 - val_acc: 0.9897\n",
      "Epoch 141/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0116 - acc: 0.9962\n",
      "Epoch 141: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0122 - acc: 0.9958 - val_loss: 0.0315 - val_acc: 0.9870\n",
      "Epoch 142/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0115 - acc: 0.9961\n",
      "Epoch 142: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.9961 - val_loss: 0.0314 - val_acc: 0.9860\n",
      "Epoch 143/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0122 - acc: 0.9957\n",
      "Epoch 143: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0120 - acc: 0.9957 - val_loss: 0.0256 - val_acc: 0.9903\n",
      "Epoch 144/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 144: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0252 - val_acc: 0.9887\n",
      "Epoch 145/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9964\n",
      "Epoch 145: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0259 - val_acc: 0.9887\n",
      "Epoch 146/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0124 - acc: 0.9959\n",
      "Epoch 146: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0254 - val_acc: 0.9887\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332/376 [=========================>....] - ETA: 0s - loss: 0.0121 - acc: 0.9957\n",
      "Epoch 147: val_loss did not improve from 0.02510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0123 - acc: 0.9958 - val_loss: 0.0266 - val_acc: 0.9893\n",
      "Epoch 148/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0110 - acc: 0.9964\n",
      "Epoch 148: val_loss improved from 0.02510 to 0.02457, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0246 - val_acc: 0.9897\n",
      "Epoch 149/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0110 - acc: 0.9961\n",
      "Epoch 149: val_loss improved from 0.02457 to 0.02424, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0111 - acc: 0.9960 - val_loss: 0.0242 - val_acc: 0.9900\n",
      "Epoch 150/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0103 - acc: 0.9967\n",
      "Epoch 150: val_loss did not improve from 0.02424\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0270 - val_acc: 0.9877\n",
      "Epoch 151/200\n",
      "332/376 [=========================>....] - ETA: 0s - loss: 0.0111 - acc: 0.9965\n",
      "Epoch 151: val_loss did not improve from 0.02424\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0111 - acc: 0.9963 - val_loss: 0.0257 - val_acc: 0.9890\n",
      "Epoch 152/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9963\n",
      "Epoch 152: val_loss did not improve from 0.02424\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0312 - val_acc: 0.9870\n",
      "Epoch 153/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0110 - acc: 0.9961\n",
      "Epoch 153: val_loss improved from 0.02424 to 0.02352, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0110 - acc: 0.9960 - val_loss: 0.0235 - val_acc: 0.9900\n",
      "Epoch 154/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0106 - acc: 0.9959\n",
      "Epoch 154: val_loss improved from 0.02352 to 0.02306, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9960 - val_loss: 0.0231 - val_acc: 0.9893\n",
      "Epoch 155/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 155: val_loss did not improve from 0.02306\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0274 - val_acc: 0.9877\n",
      "Epoch 156/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9971\n",
      "Epoch 156: val_loss did not improve from 0.02306\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0102 - acc: 0.9972 - val_loss: 0.0281 - val_acc: 0.9873\n",
      "Epoch 157/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0095 - acc: 0.9977\n",
      "Epoch 157: val_loss did not improve from 0.02306\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0263 - val_acc: 0.9880\n",
      "Epoch 158/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9965\n",
      "Epoch 158: val_loss did not improve from 0.02306\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0103 - acc: 0.9965 - val_loss: 0.0253 - val_acc: 0.9903\n",
      "Epoch 159/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9974\n",
      "Epoch 159: val_loss did not improve from 0.02306\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0252 - val_acc: 0.9890\n",
      "Epoch 160/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0096 - acc: 0.9972\n",
      "Epoch 160: val_loss did not improve from 0.02306\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.0233 - val_acc: 0.9897\n",
      "Epoch 161/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0090 - acc: 0.9978\n",
      "Epoch 161: val_loss did not improve from 0.02306\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9976 - val_loss: 0.0246 - val_acc: 0.9893\n",
      "Epoch 162/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0098 - acc: 0.9968\n",
      "Epoch 162: val_loss improved from 0.02306 to 0.02230, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0223 - val_acc: 0.9903\n",
      "Epoch 163/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0107 - acc: 0.9966\n",
      "Epoch 163: val_loss did not improve from 0.02230\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0269 - val_acc: 0.9893\n",
      "Epoch 164/200\n",
      "334/376 [=========================>....] - ETA: 0s - loss: 0.0097 - acc: 0.9970\n",
      "Epoch 164: val_loss did not improve from 0.02230\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.0248 - val_acc: 0.9887\n",
      "Epoch 165/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0093 - acc: 0.9973\n",
      "Epoch 165: val_loss did not improve from 0.02230\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.9972 - val_loss: 0.0270 - val_acc: 0.9883\n",
      "Epoch 166/200\n",
      "331/376 [=========================>....] - ETA: 0s - loss: 0.0092 - acc: 0.9973\n",
      "Epoch 166: val_loss did not improve from 0.02230\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9972 - val_loss: 0.0287 - val_acc: 0.9890\n",
      "Epoch 167/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 167: val_loss did not improve from 0.02230\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.0464 - val_acc: 0.9817\n",
      "Epoch 168/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9972\n",
      "Epoch 168: val_loss did not improve from 0.02230\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 0.9972 - val_loss: 0.0243 - val_acc: 0.9907\n",
      "Epoch 169/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0092 - acc: 0.9967\n",
      "Epoch 169: val_loss improved from 0.02230 to 0.02227, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0223 - val_acc: 0.9897\n",
      "Epoch 170/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9979\n",
      "Epoch 170: val_loss did not improve from 0.02227\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.0245 - val_acc: 0.9893\n",
      "Epoch 171/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9972\n",
      "Epoch 171: val_loss did not improve from 0.02227\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0253 - val_acc: 0.9907\n",
      "Epoch 172/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0087 - acc: 0.9978\n",
      "Epoch 172: val_loss improved from 0.02227 to 0.02220, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0086 - acc: 0.9978 - val_loss: 0.0222 - val_acc: 0.9903\n",
      "Epoch 173/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9978\n",
      "Epoch 173: val_loss improved from 0.02220 to 0.02172, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0084 - acc: 0.9978 - val_loss: 0.0217 - val_acc: 0.9903\n",
      "Epoch 174/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0081 - acc: 0.9982\n",
      "Epoch 174: val_loss did not improve from 0.02172\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0242 - val_acc: 0.9893\n",
      "Epoch 175/200\n",
      "331/376 [=========================>....] - ETA: 0s - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 175: val_loss improved from 0.02172 to 0.02160, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0216 - val_acc: 0.9903\n",
      "Epoch 176/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9977\n",
      "Epoch 176: val_loss improved from 0.02160 to 0.02153, saving model to best_model_simple.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0081 - acc: 0.9976 - val_loss: 0.0215 - val_acc: 0.9907\n",
      "Epoch 177/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9980\n",
      "Epoch 177: val_loss improved from 0.02153 to 0.02119, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0212 - val_acc: 0.9910\n",
      "Epoch 178/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9977\n",
      "Epoch 178: val_loss did not improve from 0.02119\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0218 - val_acc: 0.9910\n",
      "Epoch 179/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0080 - acc: 0.9977\n",
      "Epoch 179: val_loss did not improve from 0.02119\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0079 - acc: 0.9977 - val_loss: 0.0240 - val_acc: 0.9903\n",
      "Epoch 180/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9980\n",
      "Epoch 180: val_loss did not improve from 0.02119\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0213 - val_acc: 0.9910\n",
      "Epoch 181/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9980\n",
      "Epoch 181: val_loss did not improve from 0.02119\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0228 - val_acc: 0.9913\n",
      "Epoch 182/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9978\n",
      "Epoch 182: val_loss did not improve from 0.02119\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0262 - val_acc: 0.9890\n",
      "Epoch 183/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0106 - acc: 0.9966\n",
      "Epoch 183: val_loss did not improve from 0.02119\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0219 - val_acc: 0.9917\n",
      "Epoch 184/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9979\n",
      "Epoch 184: val_loss improved from 0.02119 to 0.02017, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.0202 - val_acc: 0.9917\n",
      "Epoch 185/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9982\n",
      "Epoch 185: val_loss did not improve from 0.02017\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0206 - val_acc: 0.9907\n",
      "Epoch 186/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 186: val_loss did not improve from 0.02017\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 0.9977 - val_loss: 0.0226 - val_acc: 0.9913\n",
      "Epoch 187/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9978\n",
      "Epoch 187: val_loss did not improve from 0.02017\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.0208 - val_acc: 0.9907\n",
      "Epoch 188/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0090 - acc: 0.9976\n",
      "Epoch 188: val_loss did not improve from 0.02017\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.0216 - val_acc: 0.9910\n",
      "Epoch 189/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9977\n",
      "Epoch 189: val_loss did not improve from 0.02017\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.0211 - val_acc: 0.9910\n",
      "Epoch 190/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9982\n",
      "Epoch 190: val_loss did not improve from 0.02017\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0072 - acc: 0.9983 - val_loss: 0.0220 - val_acc: 0.9913\n",
      "Epoch 191/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9974\n",
      "Epoch 191: val_loss did not improve from 0.02017\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0224 - val_acc: 0.9920\n",
      "Epoch 192/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0073 - acc: 0.9983\n",
      "Epoch 192: val_loss improved from 0.02017 to 0.02006, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0072 - acc: 0.9984 - val_loss: 0.0201 - val_acc: 0.9903\n",
      "Epoch 193/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9983\n",
      "Epoch 193: val_loss did not improve from 0.02006\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0069 - acc: 0.9983 - val_loss: 0.0202 - val_acc: 0.9917\n",
      "Epoch 194/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9983\n",
      "Epoch 194: val_loss did not improve from 0.02006\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0070 - acc: 0.9983 - val_loss: 0.0203 - val_acc: 0.9917\n",
      "Epoch 195/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9979\n",
      "Epoch 195: val_loss did not improve from 0.02006\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 0.9979 - val_loss: 0.0228 - val_acc: 0.9903\n",
      "Epoch 196/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0074 - acc: 0.9977\n",
      "Epoch 196: val_loss improved from 0.02006 to 0.01912, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 0.9977 - val_loss: 0.0191 - val_acc: 0.9913\n",
      "Epoch 197/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0068 - acc: 0.9982\n",
      "Epoch 197: val_loss did not improve from 0.01912\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0193 - val_acc: 0.9917\n",
      "Epoch 198/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0067 - acc: 0.9981\n",
      "Epoch 198: val_loss did not improve from 0.01912\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0215 - val_acc: 0.9923\n",
      "Epoch 199/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0065 - acc: 0.9988\n",
      "Epoch 199: val_loss did not improve from 0.01912\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0065 - acc: 0.9988 - val_loss: 0.0198 - val_acc: 0.9920\n",
      "Epoch 200/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9981\n",
      "Epoch 200: val_loss did not improve from 0.01912\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0201 - val_acc: 0.9917\n",
      "94/94 [==============================] - 0s 597us/step\n",
      "Epoch 1/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.2997 - acc: 0.8929\n",
      "Epoch 1: val_loss improved from inf to 0.19151, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.2997 - acc: 0.8929 - val_loss: 0.1915 - val_acc: 0.9291\n",
      "Epoch 2/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.1597 - acc: 0.9428\n",
      "Epoch 2: val_loss improved from 0.19151 to 0.15250, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1588 - acc: 0.9428 - val_loss: 0.1525 - val_acc: 0.9431\n",
      "Epoch 3/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9542\n",
      "Epoch 3: val_loss improved from 0.15250 to 0.13656, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1301 - acc: 0.9543 - val_loss: 0.1366 - val_acc: 0.9484\n",
      "Epoch 4/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9582\n",
      "Epoch 4: val_loss improved from 0.13656 to 0.12835, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1162 - acc: 0.9579 - val_loss: 0.1283 - val_acc: 0.9540\n",
      "Epoch 5/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.1081 - acc: 0.9616\n",
      "Epoch 5: val_loss improved from 0.12835 to 0.12771, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1081 - acc: 0.9615 - val_loss: 0.1277 - val_acc: 0.9584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.1033 - acc: 0.9628\n",
      "Epoch 6: val_loss improved from 0.12771 to 0.11763, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1024 - acc: 0.9634 - val_loss: 0.1176 - val_acc: 0.9590\n",
      "Epoch 7/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0968 - acc: 0.9657\n",
      "Epoch 7: val_loss improved from 0.11763 to 0.11237, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0963 - acc: 0.9655 - val_loss: 0.1124 - val_acc: 0.9600\n",
      "Epoch 8/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0936 - acc: 0.9657\n",
      "Epoch 8: val_loss improved from 0.11237 to 0.10813, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0936 - acc: 0.9656 - val_loss: 0.1081 - val_acc: 0.9627\n",
      "Epoch 9/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0909 - acc: 0.9671\n",
      "Epoch 9: val_loss did not improve from 0.10813\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0891 - acc: 0.9675 - val_loss: 0.1116 - val_acc: 0.9577\n",
      "Epoch 10/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0864 - acc: 0.9689\n",
      "Epoch 10: val_loss improved from 0.10813 to 0.10242, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0859 - acc: 0.9689 - val_loss: 0.1024 - val_acc: 0.9617\n",
      "Epoch 11/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0824 - acc: 0.9705\n",
      "Epoch 11: val_loss improved from 0.10242 to 0.10013, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0832 - acc: 0.9699 - val_loss: 0.1001 - val_acc: 0.9634\n",
      "Epoch 12/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0790 - acc: 0.9717\n",
      "Epoch 12: val_loss improved from 0.10013 to 0.09470, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0801 - acc: 0.9708 - val_loss: 0.0947 - val_acc: 0.9657\n",
      "Epoch 13/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0791 - acc: 0.9711\n",
      "Epoch 13: val_loss improved from 0.09470 to 0.09144, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0778 - acc: 0.9714 - val_loss: 0.0914 - val_acc: 0.9657\n",
      "Epoch 14/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0747 - acc: 0.9724\n",
      "Epoch 14: val_loss improved from 0.09144 to 0.08706, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0745 - acc: 0.9725 - val_loss: 0.0871 - val_acc: 0.9680\n",
      "Epoch 15/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9729\n",
      "Epoch 15: val_loss improved from 0.08706 to 0.08419, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0726 - acc: 0.9728 - val_loss: 0.0842 - val_acc: 0.9710\n",
      "Epoch 16/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0710 - acc: 0.9730\n",
      "Epoch 16: val_loss improved from 0.08419 to 0.08279, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0696 - acc: 0.9736 - val_loss: 0.0828 - val_acc: 0.9677\n",
      "Epoch 17/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9751\n",
      "Epoch 17: val_loss did not improve from 0.08279\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0673 - acc: 0.9751 - val_loss: 0.0835 - val_acc: 0.9667\n",
      "Epoch 18/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0679 - acc: 0.9750\n",
      "Epoch 18: val_loss improved from 0.08279 to 0.07717, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0671 - acc: 0.9756 - val_loss: 0.0772 - val_acc: 0.9704\n",
      "Epoch 19/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0627 - acc: 0.9774\n",
      "Epoch 19: val_loss did not improve from 0.07717\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0632 - acc: 0.9772 - val_loss: 0.0813 - val_acc: 0.9710\n",
      "Epoch 20/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9778\n",
      "Epoch 20: val_loss improved from 0.07717 to 0.07624, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0623 - acc: 0.9780 - val_loss: 0.0762 - val_acc: 0.9704\n",
      "Epoch 21/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0602 - acc: 0.9783\n",
      "Epoch 21: val_loss improved from 0.07624 to 0.07039, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0599 - acc: 0.9785 - val_loss: 0.0704 - val_acc: 0.9737\n",
      "Epoch 22/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9785\n",
      "Epoch 22: val_loss improved from 0.07039 to 0.06853, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0591 - acc: 0.9785 - val_loss: 0.0685 - val_acc: 0.9734\n",
      "Epoch 23/200\n",
      "334/376 [=========================>....] - ETA: 0s - loss: 0.0586 - acc: 0.9774\n",
      "Epoch 23: val_loss improved from 0.06853 to 0.06712, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0582 - acc: 0.9780 - val_loss: 0.0671 - val_acc: 0.9767\n",
      "Epoch 24/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0557 - acc: 0.9795\n",
      "Epoch 24: val_loss improved from 0.06712 to 0.06489, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0556 - acc: 0.9796 - val_loss: 0.0649 - val_acc: 0.9784\n",
      "Epoch 25/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0545 - acc: 0.9795\n",
      "Epoch 25: val_loss improved from 0.06489 to 0.06278, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0540 - acc: 0.9798 - val_loss: 0.0628 - val_acc: 0.9777\n",
      "Epoch 26/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0532 - acc: 0.9805\n",
      "Epoch 26: val_loss improved from 0.06278 to 0.06262, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0528 - acc: 0.9804 - val_loss: 0.0626 - val_acc: 0.9750\n",
      "Epoch 27/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0507 - acc: 0.9809\n",
      "Epoch 27: val_loss improved from 0.06262 to 0.05931, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0515 - acc: 0.9807 - val_loss: 0.0593 - val_acc: 0.9780\n",
      "Epoch 28/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0498 - acc: 0.9813\n",
      "Epoch 28: val_loss improved from 0.05931 to 0.05891, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0494 - acc: 0.9815 - val_loss: 0.0589 - val_acc: 0.9790\n",
      "Epoch 29/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0482 - acc: 0.9816\n",
      "Epoch 29: val_loss improved from 0.05891 to 0.05727, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0480 - acc: 0.9816 - val_loss: 0.0573 - val_acc: 0.9797\n",
      "Epoch 30/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0476 - acc: 0.9827\n",
      "Epoch 30: val_loss did not improve from 0.05727\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0471 - acc: 0.9829 - val_loss: 0.0580 - val_acc: 0.9794\n",
      "Epoch 31/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9833\n",
      "Epoch 31: val_loss improved from 0.05727 to 0.05666, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0461 - acc: 0.9833 - val_loss: 0.0567 - val_acc: 0.9797\n",
      "Epoch 32/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0459 - acc: 0.9824\n",
      "Epoch 32: val_loss improved from 0.05666 to 0.05357, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0454 - acc: 0.9827 - val_loss: 0.0536 - val_acc: 0.9800\n",
      "Epoch 33/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0439 - acc: 0.9839\n",
      "Epoch 33: val_loss improved from 0.05357 to 0.05117, saving model to best_model_simple.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0443 - acc: 0.9840 - val_loss: 0.0512 - val_acc: 0.9817\n",
      "Epoch 34/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0429 - acc: 0.9841\n",
      "Epoch 34: val_loss did not improve from 0.05117\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0425 - acc: 0.9843 - val_loss: 0.0528 - val_acc: 0.9797\n",
      "Epoch 35/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0434 - acc: 0.9832\n",
      "Epoch 35: val_loss improved from 0.05117 to 0.04909, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0428 - acc: 0.9836 - val_loss: 0.0491 - val_acc: 0.9824\n",
      "Epoch 36/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0400 - acc: 0.9848\n",
      "Epoch 36: val_loss improved from 0.04909 to 0.04879, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0407 - acc: 0.9845 - val_loss: 0.0488 - val_acc: 0.9820\n",
      "Epoch 37/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0395 - acc: 0.9850\n",
      "Epoch 37: val_loss did not improve from 0.04879\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0397 - acc: 0.9850 - val_loss: 0.0496 - val_acc: 0.9810\n",
      "Epoch 38/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0378 - acc: 0.9856\n",
      "Epoch 38: val_loss improved from 0.04879 to 0.04671, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0383 - acc: 0.9855 - val_loss: 0.0467 - val_acc: 0.9830\n",
      "Epoch 39/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9857\n",
      "Epoch 39: val_loss did not improve from 0.04671\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0376 - acc: 0.9858 - val_loss: 0.0475 - val_acc: 0.9817\n",
      "Epoch 40/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9859\n",
      "Epoch 40: val_loss improved from 0.04671 to 0.04522, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0375 - acc: 0.9858 - val_loss: 0.0452 - val_acc: 0.9840\n",
      "Epoch 41/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0361 - acc: 0.9870\n",
      "Epoch 41: val_loss did not improve from 0.04522\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0358 - acc: 0.9873 - val_loss: 0.0461 - val_acc: 0.9830\n",
      "Epoch 42/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0355 - acc: 0.9862\n",
      "Epoch 42: val_loss did not improve from 0.04522\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0356 - acc: 0.9860 - val_loss: 0.0501 - val_acc: 0.9810\n",
      "Epoch 43/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0358 - acc: 0.9864\n",
      "Epoch 43: val_loss improved from 0.04522 to 0.04411, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0354 - acc: 0.9863 - val_loss: 0.0441 - val_acc: 0.9840\n",
      "Epoch 44/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0348 - acc: 0.9863\n",
      "Epoch 44: val_loss did not improve from 0.04411\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0348 - acc: 0.9863 - val_loss: 0.0540 - val_acc: 0.9780\n",
      "Epoch 45/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0328 - acc: 0.9871\n",
      "Epoch 45: val_loss improved from 0.04411 to 0.04167, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0332 - acc: 0.9868 - val_loss: 0.0417 - val_acc: 0.9850\n",
      "Epoch 46/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0321 - acc: 0.9876\n",
      "Epoch 46: val_loss did not improve from 0.04167\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0327 - acc: 0.9873 - val_loss: 0.0419 - val_acc: 0.9843\n",
      "Epoch 47/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0308 - acc: 0.9877\n",
      "Epoch 47: val_loss improved from 0.04167 to 0.03953, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0319 - acc: 0.9876 - val_loss: 0.0395 - val_acc: 0.9850\n",
      "Epoch 48/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0312 - acc: 0.9883\n",
      "Epoch 48: val_loss did not improve from 0.03953\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0312 - acc: 0.9883 - val_loss: 0.0400 - val_acc: 0.9847\n",
      "Epoch 49/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0311 - acc: 0.9881\n",
      "Epoch 49: val_loss did not improve from 0.03953\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0305 - acc: 0.9883 - val_loss: 0.0500 - val_acc: 0.9784\n",
      "Epoch 50/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9880\n",
      "Epoch 50: val_loss did not improve from 0.03953\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0323 - acc: 0.9879 - val_loss: 0.0401 - val_acc: 0.9843\n",
      "Epoch 51/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9887\n",
      "Epoch 51: val_loss improved from 0.03953 to 0.03846, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0298 - acc: 0.9887 - val_loss: 0.0385 - val_acc: 0.9847\n",
      "Epoch 52/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9883\n",
      "Epoch 52: val_loss improved from 0.03846 to 0.03748, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0294 - acc: 0.9883 - val_loss: 0.0375 - val_acc: 0.9860\n",
      "Epoch 53/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9889\n",
      "Epoch 53: val_loss improved from 0.03748 to 0.03647, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0286 - acc: 0.9892 - val_loss: 0.0365 - val_acc: 0.9857\n",
      "Epoch 54/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0277 - acc: 0.9902\n",
      "Epoch 54: val_loss did not improve from 0.03647\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0282 - acc: 0.9898 - val_loss: 0.0370 - val_acc: 0.9860\n",
      "Epoch 55/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0275 - acc: 0.9900\n",
      "Epoch 55: val_loss improved from 0.03647 to 0.03625, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0286 - acc: 0.9894 - val_loss: 0.0363 - val_acc: 0.9850\n",
      "Epoch 56/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0273 - acc: 0.9898\n",
      "Epoch 56: val_loss improved from 0.03625 to 0.03518, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0269 - acc: 0.9902 - val_loss: 0.0352 - val_acc: 0.9867\n",
      "Epoch 57/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9894\n",
      "Epoch 57: val_loss did not improve from 0.03518\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0270 - acc: 0.9896 - val_loss: 0.0368 - val_acc: 0.9843\n",
      "Epoch 58/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0260 - acc: 0.9904\n",
      "Epoch 58: val_loss improved from 0.03518 to 0.03418, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0261 - acc: 0.9904 - val_loss: 0.0342 - val_acc: 0.9870\n",
      "Epoch 59/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9900\n",
      "Epoch 59: val_loss did not improve from 0.03418\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0259 - acc: 0.9900 - val_loss: 0.0384 - val_acc: 0.9843\n",
      "Epoch 60/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0257 - acc: 0.9899\n",
      "Epoch 60: val_loss did not improve from 0.03418\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0256 - acc: 0.9901 - val_loss: 0.0377 - val_acc: 0.9843\n",
      "Epoch 61/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9910\n",
      "Epoch 61: val_loss improved from 0.03418 to 0.03236, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0255 - acc: 0.9908 - val_loss: 0.0324 - val_acc: 0.9873\n",
      "Epoch 62/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0250 - acc: 0.9905\n",
      "Epoch 62: val_loss did not improve from 0.03236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0248 - acc: 0.9903 - val_loss: 0.0344 - val_acc: 0.9880\n",
      "Epoch 63/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0254 - acc: 0.9898\n",
      "Epoch 63: val_loss did not improve from 0.03236\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0252 - acc: 0.9901 - val_loss: 0.0358 - val_acc: 0.9847\n",
      "Epoch 64/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0237 - acc: 0.9907\n",
      "Epoch 64: val_loss did not improve from 0.03236\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0240 - acc: 0.9905 - val_loss: 0.0331 - val_acc: 0.9867\n",
      "Epoch 65/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9908\n",
      "Epoch 65: val_loss improved from 0.03236 to 0.03149, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0235 - acc: 0.9908 - val_loss: 0.0315 - val_acc: 0.9880\n",
      "Epoch 66/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0233 - acc: 0.9911\n",
      "Epoch 66: val_loss did not improve from 0.03149\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0229 - acc: 0.9913 - val_loss: 0.0316 - val_acc: 0.9863\n",
      "Epoch 67/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9918\n",
      "Epoch 67: val_loss improved from 0.03149 to 0.03096, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0225 - acc: 0.9918 - val_loss: 0.0310 - val_acc: 0.9870\n",
      "Epoch 68/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9921\n",
      "Epoch 68: val_loss did not improve from 0.03096\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0228 - acc: 0.9921 - val_loss: 0.0418 - val_acc: 0.9847\n",
      "Epoch 69/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0237 - acc: 0.9911\n",
      "Epoch 69: val_loss improved from 0.03096 to 0.03059, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0233 - acc: 0.9913 - val_loss: 0.0306 - val_acc: 0.9880\n",
      "Epoch 70/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9916\n",
      "Epoch 70: val_loss did not improve from 0.03059\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0213 - acc: 0.9916 - val_loss: 0.0339 - val_acc: 0.9867\n",
      "Epoch 71/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0215 - acc: 0.9921\n",
      "Epoch 71: val_loss did not improve from 0.03059\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0210 - acc: 0.9923 - val_loss: 0.0332 - val_acc: 0.9870\n",
      "Epoch 72/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9920\n",
      "Epoch 72: val_loss did not improve from 0.03059\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0212 - acc: 0.9919 - val_loss: 0.0340 - val_acc: 0.9870\n",
      "Epoch 73/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0206 - acc: 0.9925\n",
      "Epoch 73: val_loss improved from 0.03059 to 0.03023, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0206 - acc: 0.9925 - val_loss: 0.0302 - val_acc: 0.9880\n",
      "Epoch 74/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9924\n",
      "Epoch 74: val_loss improved from 0.03023 to 0.02924, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0206 - acc: 0.9925 - val_loss: 0.0292 - val_acc: 0.9883\n",
      "Epoch 75/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0205 - acc: 0.9923\n",
      "Epoch 75: val_loss did not improve from 0.02924\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0202 - acc: 0.9925 - val_loss: 0.0304 - val_acc: 0.9873\n",
      "Epoch 76/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0193 - acc: 0.9931\n",
      "Epoch 76: val_loss improved from 0.02924 to 0.02804, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0197 - acc: 0.9928 - val_loss: 0.0280 - val_acc: 0.9897\n",
      "Epoch 77/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9933\n",
      "Epoch 77: val_loss improved from 0.02804 to 0.02776, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0192 - acc: 0.9933 - val_loss: 0.0278 - val_acc: 0.9893\n",
      "Epoch 78/200\n",
      "334/376 [=========================>....] - ETA: 0s - loss: 0.0189 - acc: 0.9929\n",
      "Epoch 78: val_loss did not improve from 0.02776\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0188 - acc: 0.9927 - val_loss: 0.0291 - val_acc: 0.9900\n",
      "Epoch 79/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9935\n",
      "Epoch 79: val_loss did not improve from 0.02776\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0186 - acc: 0.9935 - val_loss: 0.0297 - val_acc: 0.9897\n",
      "Epoch 80/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9932\n",
      "Epoch 80: val_loss did not improve from 0.02776\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0189 - acc: 0.9932 - val_loss: 0.0305 - val_acc: 0.9873\n",
      "Epoch 81/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0182 - acc: 0.9934\n",
      "Epoch 81: val_loss improved from 0.02776 to 0.02705, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0178 - acc: 0.9937 - val_loss: 0.0271 - val_acc: 0.9897\n",
      "Epoch 82/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0181 - acc: 0.9932\n",
      "Epoch 82: val_loss improved from 0.02705 to 0.02662, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0179 - acc: 0.9934 - val_loss: 0.0266 - val_acc: 0.9893\n",
      "Epoch 83/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9943\n",
      "Epoch 83: val_loss did not improve from 0.02662\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0170 - acc: 0.9943 - val_loss: 0.0279 - val_acc: 0.9887\n",
      "Epoch 84/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0172 - acc: 0.9942\n",
      "Epoch 84: val_loss did not improve from 0.02662\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0170 - acc: 0.9943 - val_loss: 0.0310 - val_acc: 0.9867\n",
      "Epoch 85/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0166 - acc: 0.9940\n",
      "Epoch 85: val_loss did not improve from 0.02662\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0168 - acc: 0.9939 - val_loss: 0.0363 - val_acc: 0.9857\n",
      "Epoch 86/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9940\n",
      "Epoch 86: val_loss improved from 0.02662 to 0.02510, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0169 - acc: 0.9940 - val_loss: 0.0251 - val_acc: 0.9887\n",
      "Epoch 87/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0165 - acc: 0.9942\n",
      "Epoch 87: val_loss improved from 0.02510 to 0.02503, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0165 - acc: 0.9942 - val_loss: 0.0250 - val_acc: 0.9917\n",
      "Epoch 88/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0155 - acc: 0.9946\n",
      "Epoch 88: val_loss did not improve from 0.02503\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0156 - acc: 0.9946 - val_loss: 0.0257 - val_acc: 0.9893\n",
      "Epoch 89/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0156 - acc: 0.9950\n",
      "Epoch 89: val_loss improved from 0.02503 to 0.02414, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0241 - val_acc: 0.9907\n",
      "Epoch 90/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0157 - acc: 0.9954\n",
      "Epoch 90: val_loss did not improve from 0.02414\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0157 - acc: 0.9955 - val_loss: 0.0242 - val_acc: 0.9903\n",
      "Epoch 91/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0149 - acc: 0.9955\n",
      "Epoch 91: val_loss did not improve from 0.02414\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0148 - acc: 0.9958 - val_loss: 0.0255 - val_acc: 0.9913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0152 - acc: 0.9952\n",
      "Epoch 92: val_loss did not improve from 0.02414\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0153 - acc: 0.9952 - val_loss: 0.0246 - val_acc: 0.9920\n",
      "Epoch 93/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9953\n",
      "Epoch 93: val_loss did not improve from 0.02414\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.0245 - val_acc: 0.9907\n",
      "Epoch 94/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0144 - acc: 0.9947\n",
      "Epoch 94: val_loss improved from 0.02414 to 0.02294, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0143 - acc: 0.9948 - val_loss: 0.0229 - val_acc: 0.9913\n",
      "Epoch 95/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9951\n",
      "Epoch 95: val_loss did not improve from 0.02294\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0139 - acc: 0.9951 - val_loss: 0.0275 - val_acc: 0.9883\n",
      "Epoch 96/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0139 - acc: 0.9954\n",
      "Epoch 96: val_loss did not improve from 0.02294\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0252 - val_acc: 0.9893\n",
      "Epoch 97/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0139 - acc: 0.9954\n",
      "Epoch 97: val_loss did not improve from 0.02294\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0302 - val_acc: 0.9880\n",
      "Epoch 98/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0132 - acc: 0.9961\n",
      "Epoch 98: val_loss did not improve from 0.02294\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0136 - acc: 0.9961 - val_loss: 0.0242 - val_acc: 0.9897\n",
      "Epoch 99/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9952\n",
      "Epoch 99: val_loss did not improve from 0.02294\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0133 - acc: 0.9951 - val_loss: 0.0237 - val_acc: 0.9893\n",
      "Epoch 100/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0134 - acc: 0.9957\n",
      "Epoch 100: val_loss improved from 0.02294 to 0.02267, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0133 - acc: 0.9958 - val_loss: 0.0227 - val_acc: 0.9900\n",
      "Epoch 101/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0133 - acc: 0.9958\n",
      "Epoch 101: val_loss improved from 0.02267 to 0.02209, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0221 - val_acc: 0.9907\n",
      "Epoch 102/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0128 - acc: 0.9959\n",
      "Epoch 102: val_loss did not improve from 0.02209\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0131 - acc: 0.9958 - val_loss: 0.0238 - val_acc: 0.9923\n",
      "Epoch 103/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0126 - acc: 0.9963\n",
      "Epoch 103: val_loss improved from 0.02209 to 0.02113, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0211 - val_acc: 0.9913\n",
      "Epoch 104/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0130 - acc: 0.9962\n",
      "Epoch 104: val_loss did not improve from 0.02113\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0128 - acc: 0.9964 - val_loss: 0.0216 - val_acc: 0.9910\n",
      "Epoch 105/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0125 - acc: 0.9963\n",
      "Epoch 105: val_loss did not improve from 0.02113\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.0234 - val_acc: 0.9893\n",
      "Epoch 106/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0113 - acc: 0.9964\n",
      "Epoch 106: val_loss did not improve from 0.02113\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.9963 - val_loss: 0.0226 - val_acc: 0.9893\n",
      "Epoch 107/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0118 - acc: 0.9967\n",
      "Epoch 107: val_loss did not improve from 0.02113\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.9968 - val_loss: 0.0221 - val_acc: 0.9907\n",
      "Epoch 108/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9966\n",
      "Epoch 108: val_loss did not improve from 0.02113\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9966 - val_loss: 0.0259 - val_acc: 0.9883\n",
      "Epoch 109/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9962\n",
      "Epoch 109: val_loss did not improve from 0.02113\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.9962 - val_loss: 0.0216 - val_acc: 0.9930\n",
      "Epoch 110/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9966\n",
      "Epoch 110: val_loss did not improve from 0.02113\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.9966 - val_loss: 0.0255 - val_acc: 0.9920\n",
      "Epoch 111/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0113 - acc: 0.9971\n",
      "Epoch 111: val_loss improved from 0.02113 to 0.01991, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0111 - acc: 0.9972 - val_loss: 0.0199 - val_acc: 0.9923\n",
      "Epoch 112/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0105 - acc: 0.9971\n",
      "Epoch 112: val_loss did not improve from 0.01991\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0110 - acc: 0.9969 - val_loss: 0.0213 - val_acc: 0.9940\n",
      "Epoch 113/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0112 - acc: 0.9964\n",
      "Epoch 113: val_loss did not improve from 0.01991\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0203 - val_acc: 0.9907\n",
      "Epoch 114/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 114: val_loss did not improve from 0.01991\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9968 - val_loss: 0.0214 - val_acc: 0.9933\n",
      "Epoch 115/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0101 - acc: 0.9972\n",
      "Epoch 115: val_loss did not improve from 0.01991\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 0.9973 - val_loss: 0.0279 - val_acc: 0.9870\n",
      "Epoch 116/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0102 - acc: 0.9972\n",
      "Epoch 116: val_loss improved from 0.01991 to 0.01978, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0102 - acc: 0.9972 - val_loss: 0.0198 - val_acc: 0.9933\n",
      "Epoch 117/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9973\n",
      "Epoch 117: val_loss did not improve from 0.01978\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.9973 - val_loss: 0.0266 - val_acc: 0.9887\n",
      "Epoch 118/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0101 - acc: 0.9969\n",
      "Epoch 118: val_loss did not improve from 0.01978\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0216 - val_acc: 0.9900\n",
      "Epoch 119/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0107 - acc: 0.9970\n",
      "Epoch 119: val_loss improved from 0.01978 to 0.01894, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9972 - val_loss: 0.0189 - val_acc: 0.9917\n",
      "Epoch 120/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9977\n",
      "Epoch 120: val_loss did not improve from 0.01894\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0088 - acc: 0.9978 - val_loss: 0.0243 - val_acc: 0.9900\n",
      "Epoch 121/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0093 - acc: 0.9975\n",
      "Epoch 121: val_loss did not improve from 0.01894\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0236 - val_acc: 0.9887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0095 - acc: 0.9977\n",
      "Epoch 122: val_loss improved from 0.01894 to 0.01874, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0095 - acc: 0.9977 - val_loss: 0.0187 - val_acc: 0.9927\n",
      "Epoch 123/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0094 - acc: 0.9977\n",
      "Epoch 123: val_loss did not improve from 0.01874\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0205 - val_acc: 0.9913\n",
      "Epoch 124/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0092 - acc: 0.9976\n",
      "Epoch 124: val_loss did not improve from 0.01874\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0197 - val_acc: 0.9913\n",
      "Epoch 125/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 125: val_loss did not improve from 0.01874\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 0.0250 - val_acc: 0.9890\n",
      "Epoch 126/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0094 - acc: 0.9971\n",
      "Epoch 126: val_loss improved from 0.01874 to 0.01822, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0182 - val_acc: 0.9943\n",
      "Epoch 127/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9975\n",
      "Epoch 127: val_loss did not improve from 0.01822\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0087 - acc: 0.9975 - val_loss: 0.0189 - val_acc: 0.9923\n",
      "Epoch 128/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0083 - acc: 0.9978\n",
      "Epoch 128: val_loss did not improve from 0.01822\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 0.9978 - val_loss: 0.0195 - val_acc: 0.9943\n",
      "Epoch 129/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9980\n",
      "Epoch 129: val_loss did not improve from 0.01822\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0194 - val_acc: 0.9923\n",
      "Epoch 130/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0084 - acc: 0.9976\n",
      "Epoch 130: val_loss did not improve from 0.01822\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0087 - acc: 0.9975 - val_loss: 0.0257 - val_acc: 0.9903\n",
      "Epoch 131/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0081 - acc: 0.9981\n",
      "Epoch 131: val_loss improved from 0.01822 to 0.01793, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0081 - acc: 0.9983 - val_loss: 0.0179 - val_acc: 0.9950\n",
      "Epoch 132/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9978\n",
      "Epoch 132: val_loss did not improve from 0.01793\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0080 - acc: 0.9978 - val_loss: 0.0180 - val_acc: 0.9920\n",
      "Epoch 133/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0076 - acc: 0.9982\n",
      "Epoch 133: val_loss did not improve from 0.01793\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.0247 - val_acc: 0.9897\n",
      "Epoch 134/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0081 - acc: 0.9978\n",
      "Epoch 134: val_loss did not improve from 0.01793\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0080 - acc: 0.9978 - val_loss: 0.0209 - val_acc: 0.9907\n",
      "Epoch 135/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0085 - acc: 0.9978\n",
      "Epoch 135: val_loss did not improve from 0.01793\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0188 - val_acc: 0.9940\n",
      "Epoch 136/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0077 - acc: 0.9982\n",
      "Epoch 136: val_loss did not improve from 0.01793\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0189 - val_acc: 0.9920\n",
      "Epoch 137/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0076 - acc: 0.9982\n",
      "Epoch 137: val_loss did not improve from 0.01793\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0183 - val_acc: 0.9907\n",
      "Epoch 138/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0074 - acc: 0.9984\n",
      "Epoch 138: val_loss did not improve from 0.01793\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0074 - acc: 0.9985 - val_loss: 0.0193 - val_acc: 0.9917\n",
      "Epoch 139/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0070 - acc: 0.9985\n",
      "Epoch 139: val_loss improved from 0.01793 to 0.01682, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0069 - acc: 0.9986 - val_loss: 0.0168 - val_acc: 0.9937\n",
      "Epoch 140/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0067 - acc: 0.9986\n",
      "Epoch 140: val_loss did not improve from 0.01682\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 0.0189 - val_acc: 0.9923\n",
      "Epoch 141/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9983\n",
      "Epoch 141: val_loss improved from 0.01682 to 0.01679, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0168 - val_acc: 0.9933\n",
      "Epoch 142/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0067 - acc: 0.9989\n",
      "Epoch 142: val_loss did not improve from 0.01679\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0065 - acc: 0.9989 - val_loss: 0.0170 - val_acc: 0.9927\n",
      "Epoch 143/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0069 - acc: 0.9984\n",
      "Epoch 143: val_loss did not improve from 0.01679\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 0.0180 - val_acc: 0.9953\n",
      "Epoch 144/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9986\n",
      "Epoch 144: val_loss did not improve from 0.01679\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0068 - acc: 0.9987 - val_loss: 0.0176 - val_acc: 0.9930\n",
      "Epoch 145/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0065 - acc: 0.9986\n",
      "Epoch 145: val_loss improved from 0.01679 to 0.01616, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 0.9986 - val_loss: 0.0162 - val_acc: 0.9950\n",
      "Epoch 146/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9987\n",
      "Epoch 146: val_loss did not improve from 0.01616\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0221 - val_acc: 0.9893\n",
      "Epoch 147/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9982\n",
      "Epoch 147: val_loss did not improve from 0.01616\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0189 - val_acc: 0.9910\n",
      "Epoch 148/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0067 - acc: 0.9985\n",
      "Epoch 148: val_loss did not improve from 0.01616\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 0.0169 - val_acc: 0.9957\n",
      "Epoch 149/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0065 - acc: 0.9983\n",
      "Epoch 149: val_loss did not improve from 0.01616\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.0190 - val_acc: 0.9920\n",
      "Epoch 150/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9986\n",
      "Epoch 150: val_loss improved from 0.01616 to 0.01565, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.0157 - val_acc: 0.9953\n",
      "Epoch 151/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9991\n",
      "Epoch 151: val_loss did not improve from 0.01565\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0210 - val_acc: 0.9910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0065 - acc: 0.9987\n",
      "Epoch 152: val_loss did not improve from 0.01565\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0065 - acc: 0.9988 - val_loss: 0.0188 - val_acc: 0.9947\n",
      "Epoch 153/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0066 - acc: 0.9986\n",
      "Epoch 153: val_loss did not improve from 0.01565\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0064 - acc: 0.9987 - val_loss: 0.0159 - val_acc: 0.9930\n",
      "Epoch 154/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9988\n",
      "Epoch 154: val_loss did not improve from 0.01565\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0246 - val_acc: 0.9893\n",
      "Epoch 155/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9990\n",
      "Epoch 155: val_loss improved from 0.01565 to 0.01556, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0057 - acc: 0.9989 - val_loss: 0.0156 - val_acc: 0.9947\n",
      "Epoch 156/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9991\n",
      "Epoch 156: val_loss did not improve from 0.01556\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 0.9991 - val_loss: 0.0178 - val_acc: 0.9917\n",
      "Epoch 157/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9993\n",
      "Epoch 157: val_loss improved from 0.01556 to 0.01502, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0150 - val_acc: 0.9950\n",
      "Epoch 158/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0055 - acc: 0.9991\n",
      "Epoch 158: val_loss did not improve from 0.01502\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0171 - val_acc: 0.9927\n",
      "Epoch 159/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 159: val_loss did not improve from 0.01502\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0152 - val_acc: 0.9953\n",
      "Epoch 160/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9988\n",
      "Epoch 160: val_loss did not improve from 0.01502\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.0234 - val_acc: 0.9887\n",
      "Epoch 161/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9994\n",
      "Epoch 161: val_loss did not improve from 0.01502\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0183 - val_acc: 0.9920\n",
      "Epoch 162/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0052 - acc: 0.9990\n",
      "Epoch 162: val_loss did not improve from 0.01502\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.9991 - val_loss: 0.0166 - val_acc: 0.9930\n",
      "Epoch 163/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0051 - acc: 0.9991\n",
      "Epoch 163: val_loss did not improve from 0.01502\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 0.9991 - val_loss: 0.0162 - val_acc: 0.9957\n",
      "Epoch 164/200\n",
      "335/376 [=========================>....] - ETA: 0s - loss: 0.0050 - acc: 0.9992\n",
      "Epoch 164: val_loss did not improve from 0.01502\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0064 - acc: 0.9989 - val_loss: 0.0284 - val_acc: 0.9910\n",
      "Epoch 165/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0059 - acc: 0.9991\n",
      "Epoch 165: val_loss did not improve from 0.01502\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0158 - val_acc: 0.9933\n",
      "Epoch 166/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0045 - acc: 0.9994\n",
      "Epoch 166: val_loss did not improve from 0.01502\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0154 - val_acc: 0.9937\n",
      "Epoch 167/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0048 - acc: 0.9996\n",
      "Epoch 167: val_loss did not improve from 0.01502\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.9996 - val_loss: 0.0153 - val_acc: 0.9950\n",
      "Epoch 168/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9993\n",
      "Epoch 168: val_loss improved from 0.01502 to 0.01498, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.9993 - val_loss: 0.0150 - val_acc: 0.9943\n",
      "Epoch 169/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0044 - acc: 0.9996\n",
      "Epoch 169: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 0.9996 - val_loss: 0.0164 - val_acc: 0.9937\n",
      "Epoch 170/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9992\n",
      "Epoch 170: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 0.9992 - val_loss: 0.0233 - val_acc: 0.9900\n",
      "Epoch 171/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0045 - acc: 0.9992\n",
      "Epoch 171: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.9993 - val_loss: 0.0207 - val_acc: 0.9913\n",
      "Epoch 172/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0045 - acc: 0.9993\n",
      "Epoch 172: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0044 - acc: 0.9993 - val_loss: 0.0162 - val_acc: 0.9943\n",
      "Epoch 173/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0044 - acc: 0.9993\n",
      "Epoch 173: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.9993 - val_loss: 0.0160 - val_acc: 0.9947\n",
      "Epoch 174/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0041 - acc: 0.9993\n",
      "Epoch 174: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0042 - acc: 0.9993 - val_loss: 0.0213 - val_acc: 0.9937\n",
      "Epoch 175/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0040 - acc: 0.9997\n",
      "Epoch 175: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.9997 - val_loss: 0.0195 - val_acc: 0.9927\n",
      "Epoch 176/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9990\n",
      "Epoch 176: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0174 - val_acc: 0.9930\n",
      "Epoch 177/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9992\n",
      "Epoch 177: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0040 - acc: 0.9993 - val_loss: 0.0173 - val_acc: 0.9933\n",
      "Epoch 178/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0041 - acc: 0.9993\n",
      "Epoch 178: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.9994 - val_loss: 0.0157 - val_acc: 0.9933\n",
      "Epoch 179/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 179: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0038 - acc: 0.9995 - val_loss: 0.0171 - val_acc: 0.9930\n",
      "Epoch 180/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0035 - acc: 0.9995\n",
      "Epoch 180: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0038 - acc: 0.9994 - val_loss: 0.0204 - val_acc: 0.9937\n",
      "Epoch 181/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0045 - acc: 0.9992\n",
      "Epoch 181: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.9992 - val_loss: 0.0238 - val_acc: 0.9927\n",
      "Epoch 182/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9996\n",
      "Epoch 182: val_loss did not improve from 0.01498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0226 - val_acc: 0.9923\n",
      "Epoch 183/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 183: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 0.9995 - val_loss: 0.0191 - val_acc: 0.9930\n",
      "Epoch 184/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 184: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.9993 - val_loss: 0.0326 - val_acc: 0.9903\n",
      "Epoch 185/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9997\n",
      "Epoch 185: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.9998 - val_loss: 0.0230 - val_acc: 0.9927\n",
      "Epoch 186/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 186: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0369 - val_acc: 0.9880\n",
      "Epoch 187/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9996\n",
      "Epoch 187: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 0.9995 - val_loss: 0.0251 - val_acc: 0.9930\n",
      "Epoch 188/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0046 - acc: 0.9988\n",
      "Epoch 188: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0217 - val_acc: 0.9937\n",
      "Epoch 189/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 189: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 0.9933\n",
      "Epoch 190/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 190: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9933\n",
      "Epoch 191/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 191: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0033 - acc: 0.9998 - val_loss: 0.0246 - val_acc: 0.9933\n",
      "Epoch 192/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 192: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0230 - val_acc: 0.9930\n",
      "Epoch 193/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 193: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0030 - acc: 0.9998 - val_loss: 0.0233 - val_acc: 0.9940\n",
      "Epoch 194/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 194: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0513 - val_acc: 0.9880\n",
      "Epoch 195/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0036 - acc: 0.9995\n",
      "Epoch 195: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.9993 - val_loss: 0.0456 - val_acc: 0.9897\n",
      "Epoch 196/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 196: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.9998 - val_loss: 0.0275 - val_acc: 0.9943\n",
      "Epoch 197/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 197: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.9998 - val_loss: 0.0294 - val_acc: 0.9937\n",
      "Epoch 198/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 198: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0358 - val_acc: 0.9910\n",
      "Epoch 199/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 0.9999\n",
      "Epoch 199: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 0.9999 - val_loss: 0.0329 - val_acc: 0.9933\n",
      "Epoch 200/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 200: val_loss did not improve from 0.01498\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0319 - val_acc: 0.9923\n",
      "94/94 [==============================] - 0s 638us/step\n",
      "Epoch 1/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.3130 - acc: 0.8894\n",
      "Epoch 1: val_loss improved from inf to 0.19600, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.3039 - acc: 0.8926 - val_loss: 0.1960 - val_acc: 0.9221\n",
      "Epoch 2/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.1636 - acc: 0.9406\n",
      "Epoch 2: val_loss improved from 0.19600 to 0.14524, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1614 - acc: 0.9417 - val_loss: 0.1452 - val_acc: 0.9494\n",
      "Epoch 3/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9524\n",
      "Epoch 3: val_loss improved from 0.14524 to 0.12851, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1327 - acc: 0.9525 - val_loss: 0.1285 - val_acc: 0.9564\n",
      "Epoch 4/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.1199 - acc: 0.9564\n",
      "Epoch 4: val_loss improved from 0.12851 to 0.11696, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1186 - acc: 0.9573 - val_loss: 0.1170 - val_acc: 0.9594\n",
      "Epoch 5/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.1096 - acc: 0.9613\n",
      "Epoch 5: val_loss improved from 0.11696 to 0.11182, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1094 - acc: 0.9610 - val_loss: 0.1118 - val_acc: 0.9594\n",
      "Epoch 6/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.1024 - acc: 0.9626\n",
      "Epoch 6: val_loss improved from 0.11182 to 0.10767, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1038 - acc: 0.9622 - val_loss: 0.1077 - val_acc: 0.9604\n",
      "Epoch 7/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9645\n",
      "Epoch 7: val_loss improved from 0.10767 to 0.10242, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0970 - acc: 0.9645 - val_loss: 0.1024 - val_acc: 0.9627\n",
      "Epoch 8/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0912 - acc: 0.9670\n",
      "Epoch 8: val_loss improved from 0.10242 to 0.10200, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0925 - acc: 0.9670 - val_loss: 0.1020 - val_acc: 0.9617\n",
      "Epoch 9/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0872 - acc: 0.9680\n",
      "Epoch 9: val_loss improved from 0.10200 to 0.09127, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0877 - acc: 0.9678 - val_loss: 0.0913 - val_acc: 0.9677\n",
      "Epoch 10/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9695\n",
      "Epoch 10: val_loss improved from 0.09127 to 0.08625, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0839 - acc: 0.9696 - val_loss: 0.0863 - val_acc: 0.9694\n",
      "Epoch 11/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0805 - acc: 0.9707\n",
      "Epoch 11: val_loss improved from 0.08625 to 0.08267, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0793 - acc: 0.9709 - val_loss: 0.0827 - val_acc: 0.9704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0757 - acc: 0.9727\n",
      "Epoch 12: val_loss improved from 0.08267 to 0.08024, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0763 - acc: 0.9727 - val_loss: 0.0802 - val_acc: 0.9710\n",
      "Epoch 13/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0745 - acc: 0.9735\n",
      "Epoch 13: val_loss improved from 0.08024 to 0.07636, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0741 - acc: 0.9736 - val_loss: 0.0764 - val_acc: 0.9730\n",
      "Epoch 14/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0698 - acc: 0.9739\n",
      "Epoch 14: val_loss did not improve from 0.07636\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0705 - acc: 0.9733 - val_loss: 0.0808 - val_acc: 0.9737\n",
      "Epoch 15/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9748\n",
      "Epoch 15: val_loss improved from 0.07636 to 0.07354, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0680 - acc: 0.9745 - val_loss: 0.0735 - val_acc: 0.9737\n",
      "Epoch 16/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0658 - acc: 0.9748\n",
      "Epoch 16: val_loss improved from 0.07354 to 0.07209, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0653 - acc: 0.9751 - val_loss: 0.0721 - val_acc: 0.9717\n",
      "Epoch 17/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9767\n",
      "Epoch 17: val_loss improved from 0.07209 to 0.07113, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0634 - acc: 0.9762 - val_loss: 0.0711 - val_acc: 0.9727\n",
      "Epoch 18/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0601 - acc: 0.9774\n",
      "Epoch 18: val_loss improved from 0.07113 to 0.06502, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0608 - acc: 0.9769 - val_loss: 0.0650 - val_acc: 0.9757\n",
      "Epoch 19/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9779\n",
      "Epoch 19: val_loss did not improve from 0.06502\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0590 - acc: 0.9779 - val_loss: 0.0658 - val_acc: 0.9744\n",
      "Epoch 20/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0580 - acc: 0.9781\n",
      "Epoch 20: val_loss improved from 0.06502 to 0.06147, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0573 - acc: 0.9784 - val_loss: 0.0615 - val_acc: 0.9784\n",
      "Epoch 21/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0551 - acc: 0.9800\n",
      "Epoch 21: val_loss did not improve from 0.06147\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0551 - acc: 0.9800 - val_loss: 0.0624 - val_acc: 0.9760\n",
      "Epoch 22/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0534 - acc: 0.9808\n",
      "Epoch 22: val_loss improved from 0.06147 to 0.05870, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0534 - acc: 0.9805 - val_loss: 0.0587 - val_acc: 0.9787\n",
      "Epoch 23/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9800\n",
      "Epoch 23: val_loss did not improve from 0.05870\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0524 - acc: 0.9803 - val_loss: 0.0703 - val_acc: 0.9704\n",
      "Epoch 24/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0524 - acc: 0.9793\n",
      "Epoch 24: val_loss improved from 0.05870 to 0.05564, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0518 - acc: 0.9797 - val_loss: 0.0556 - val_acc: 0.9794\n",
      "Epoch 25/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9818\n",
      "Epoch 25: val_loss improved from 0.05564 to 0.05482, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0501 - acc: 0.9819 - val_loss: 0.0548 - val_acc: 0.9784\n",
      "Epoch 26/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9819\n",
      "Epoch 26: val_loss improved from 0.05482 to 0.05323, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0476 - acc: 0.9821 - val_loss: 0.0532 - val_acc: 0.9800\n",
      "Epoch 27/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0469 - acc: 0.9827\n",
      "Epoch 27: val_loss did not improve from 0.05323\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0477 - acc: 0.9823 - val_loss: 0.0534 - val_acc: 0.9784\n",
      "Epoch 28/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9834\n",
      "Epoch 28: val_loss did not improve from 0.05323\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0457 - acc: 0.9834 - val_loss: 0.0571 - val_acc: 0.9810\n",
      "Epoch 29/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0459 - acc: 0.9837\n",
      "Epoch 29: val_loss improved from 0.05323 to 0.05055, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0457 - acc: 0.9833 - val_loss: 0.0505 - val_acc: 0.9794\n",
      "Epoch 30/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9847\n",
      "Epoch 30: val_loss improved from 0.05055 to 0.04996, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0434 - acc: 0.9846 - val_loss: 0.0500 - val_acc: 0.9807\n",
      "Epoch 31/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0420 - acc: 0.9851\n",
      "Epoch 31: val_loss did not improve from 0.04996\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0421 - acc: 0.9850 - val_loss: 0.0507 - val_acc: 0.9804\n",
      "Epoch 32/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9852\n",
      "Epoch 32: val_loss improved from 0.04996 to 0.04792, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0417 - acc: 0.9853 - val_loss: 0.0479 - val_acc: 0.9817\n",
      "Epoch 33/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9853\n",
      "Epoch 33: val_loss improved from 0.04792 to 0.04677, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0405 - acc: 0.9853 - val_loss: 0.0468 - val_acc: 0.9794\n",
      "Epoch 34/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9860\n",
      "Epoch 34: val_loss improved from 0.04677 to 0.04590, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0400 - acc: 0.9860 - val_loss: 0.0459 - val_acc: 0.9794\n",
      "Epoch 35/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0397 - acc: 0.9859\n",
      "Epoch 35: val_loss improved from 0.04590 to 0.04473, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0393 - acc: 0.9862 - val_loss: 0.0447 - val_acc: 0.9800\n",
      "Epoch 36/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9865\n",
      "Epoch 36: val_loss improved from 0.04473 to 0.04451, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0377 - acc: 0.9865 - val_loss: 0.0445 - val_acc: 0.9800\n",
      "Epoch 37/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0371 - acc: 0.9868\n",
      "Epoch 37: val_loss improved from 0.04451 to 0.04411, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0378 - acc: 0.9863 - val_loss: 0.0441 - val_acc: 0.9804\n",
      "Epoch 38/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9862\n",
      "Epoch 38: val_loss did not improve from 0.04411\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0376 - acc: 0.9863 - val_loss: 0.0450 - val_acc: 0.9833\n",
      "Epoch 39/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0347 - acc: 0.9875\n",
      "Epoch 39: val_loss improved from 0.04411 to 0.04155, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0359 - acc: 0.9873 - val_loss: 0.0416 - val_acc: 0.9830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0348 - acc: 0.9874\n",
      "Epoch 40: val_loss did not improve from 0.04155\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0348 - acc: 0.9876 - val_loss: 0.0433 - val_acc: 0.9837\n",
      "Epoch 41/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0343 - acc: 0.9876\n",
      "Epoch 41: val_loss improved from 0.04155 to 0.04072, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0343 - acc: 0.9873 - val_loss: 0.0407 - val_acc: 0.9827\n",
      "Epoch 42/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0353 - acc: 0.9869\n",
      "Epoch 42: val_loss did not improve from 0.04072\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0349 - acc: 0.9873 - val_loss: 0.0408 - val_acc: 0.9850\n",
      "Epoch 43/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0329 - acc: 0.9877\n",
      "Epoch 43: val_loss improved from 0.04072 to 0.03992, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0328 - acc: 0.9877 - val_loss: 0.0399 - val_acc: 0.9837\n",
      "Epoch 44/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0320 - acc: 0.9883\n",
      "Epoch 44: val_loss improved from 0.03992 to 0.03867, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0322 - acc: 0.9883 - val_loss: 0.0387 - val_acc: 0.9843\n",
      "Epoch 45/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9891\n",
      "Epoch 45: val_loss did not improve from 0.03867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0320 - acc: 0.9891 - val_loss: 0.0480 - val_acc: 0.9794\n",
      "Epoch 46/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0306 - acc: 0.9892\n",
      "Epoch 46: val_loss improved from 0.03867 to 0.03742, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0307 - acc: 0.9891 - val_loss: 0.0374 - val_acc: 0.9850\n",
      "Epoch 47/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0283 - acc: 0.9895\n",
      "Epoch 47: val_loss improved from 0.03742 to 0.03635, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0293 - acc: 0.9892 - val_loss: 0.0363 - val_acc: 0.9860\n",
      "Epoch 48/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0289 - acc: 0.9899\n",
      "Epoch 48: val_loss improved from 0.03635 to 0.03610, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0293 - acc: 0.9898 - val_loss: 0.0361 - val_acc: 0.9847\n",
      "Epoch 49/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9894\n",
      "Epoch 49: val_loss improved from 0.03610 to 0.03559, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0289 - acc: 0.9893 - val_loss: 0.0356 - val_acc: 0.9867\n",
      "Epoch 50/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0290 - acc: 0.9895\n",
      "Epoch 50: val_loss did not improve from 0.03559\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0289 - acc: 0.9893 - val_loss: 0.0365 - val_acc: 0.9847\n",
      "Epoch 51/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9901\n",
      "Epoch 51: val_loss did not improve from 0.03559\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0280 - acc: 0.9900 - val_loss: 0.0383 - val_acc: 0.9840\n",
      "Epoch 52/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0270 - acc: 0.9899\n",
      "Epoch 52: val_loss improved from 0.03559 to 0.03411, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0341 - val_acc: 0.9863\n",
      "Epoch 53/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0269 - acc: 0.9908\n",
      "Epoch 53: val_loss did not improve from 0.03411\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0272 - acc: 0.9904 - val_loss: 0.0585 - val_acc: 0.9794\n",
      "Epoch 54/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9907\n",
      "Epoch 54: val_loss did not improve from 0.03411\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0262 - acc: 0.9908 - val_loss: 0.0343 - val_acc: 0.9853\n",
      "Epoch 55/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0253 - acc: 0.9909\n",
      "Epoch 55: val_loss improved from 0.03411 to 0.03181, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0261 - acc: 0.9904 - val_loss: 0.0318 - val_acc: 0.9883\n",
      "Epoch 56/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0250 - acc: 0.9911\n",
      "Epoch 56: val_loss did not improve from 0.03181\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0256 - acc: 0.9909 - val_loss: 0.0349 - val_acc: 0.9847\n",
      "Epoch 57/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0246 - acc: 0.9908\n",
      "Epoch 57: val_loss improved from 0.03181 to 0.03050, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0248 - acc: 0.9907 - val_loss: 0.0305 - val_acc: 0.9903\n",
      "Epoch 58/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0241 - acc: 0.9911\n",
      "Epoch 58: val_loss did not improve from 0.03050\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0245 - acc: 0.9910 - val_loss: 0.0365 - val_acc: 0.9853\n",
      "Epoch 59/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9912\n",
      "Epoch 59: val_loss did not improve from 0.03050\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0243 - acc: 0.9913 - val_loss: 0.0326 - val_acc: 0.9857\n",
      "Epoch 60/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0247 - acc: 0.9907\n",
      "Epoch 60: val_loss improved from 0.03050 to 0.03036, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0242 - acc: 0.9909 - val_loss: 0.0304 - val_acc: 0.9873\n",
      "Epoch 61/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0227 - acc: 0.9924\n",
      "Epoch 61: val_loss did not improve from 0.03036\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0227 - acc: 0.9923 - val_loss: 0.0313 - val_acc: 0.9893\n",
      "Epoch 62/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0225 - acc: 0.9920\n",
      "Epoch 62: val_loss improved from 0.03036 to 0.02864, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0225 - acc: 0.9920 - val_loss: 0.0286 - val_acc: 0.9897\n",
      "Epoch 63/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0209 - acc: 0.9926\n",
      "Epoch 63: val_loss did not improve from 0.02864\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0217 - acc: 0.9922 - val_loss: 0.0343 - val_acc: 0.9863\n",
      "Epoch 64/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0217 - acc: 0.9925\n",
      "Epoch 64: val_loss improved from 0.02864 to 0.02813, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0222 - acc: 0.9922 - val_loss: 0.0281 - val_acc: 0.9890\n",
      "Epoch 65/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0222 - acc: 0.9923\n",
      "Epoch 65: val_loss did not improve from 0.02813\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0219 - acc: 0.9923 - val_loss: 0.0334 - val_acc: 0.9857\n",
      "Epoch 66/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0209 - acc: 0.9929\n",
      "Epoch 66: val_loss improved from 0.02813 to 0.02758, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0218 - acc: 0.9927 - val_loss: 0.0276 - val_acc: 0.9890\n",
      "Epoch 67/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0206 - acc: 0.9932\n",
      "Epoch 67: val_loss did not improve from 0.02758\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0204 - acc: 0.9931 - val_loss: 0.0307 - val_acc: 0.9860\n",
      "Epoch 68/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0202 - acc: 0.9930\n",
      "Epoch 68: val_loss improved from 0.02758 to 0.02680, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0197 - acc: 0.9932 - val_loss: 0.0268 - val_acc: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0206 - acc: 0.9934\n",
      "Epoch 69: val_loss did not improve from 0.02680\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0203 - acc: 0.9935 - val_loss: 0.0282 - val_acc: 0.9877\n",
      "Epoch 70/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9939\n",
      "Epoch 70: val_loss did not improve from 0.02680\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0276 - val_acc: 0.9890\n",
      "Epoch 71/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0197 - acc: 0.9930\n",
      "Epoch 71: val_loss did not improve from 0.02680\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0194 - acc: 0.9932 - val_loss: 0.0305 - val_acc: 0.9893\n",
      "Epoch 72/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0198 - acc: 0.9925\n",
      "Epoch 72: val_loss improved from 0.02680 to 0.02622, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0194 - acc: 0.9928 - val_loss: 0.0262 - val_acc: 0.9890\n",
      "Epoch 73/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9941\n",
      "Epoch 73: val_loss did not improve from 0.02622\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0188 - acc: 0.9941 - val_loss: 0.0265 - val_acc: 0.9893\n",
      "Epoch 74/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0178 - acc: 0.9939\n",
      "Epoch 74: val_loss improved from 0.02622 to 0.02576, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0181 - acc: 0.9938 - val_loss: 0.0258 - val_acc: 0.9897\n",
      "Epoch 75/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0179 - acc: 0.9945\n",
      "Epoch 75: val_loss did not improve from 0.02576\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0178 - acc: 0.9948 - val_loss: 0.0265 - val_acc: 0.9900\n",
      "Epoch 76/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0192 - acc: 0.9931\n",
      "Epoch 76: val_loss improved from 0.02576 to 0.02534, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0186 - acc: 0.9934 - val_loss: 0.0253 - val_acc: 0.9887\n",
      "Epoch 77/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0171 - acc: 0.9941\n",
      "Epoch 77: val_loss did not improve from 0.02534\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0172 - acc: 0.9939 - val_loss: 0.0269 - val_acc: 0.9890\n",
      "Epoch 78/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0176 - acc: 0.9939\n",
      "Epoch 78: val_loss improved from 0.02534 to 0.02471, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0174 - acc: 0.9941 - val_loss: 0.0247 - val_acc: 0.9880\n",
      "Epoch 79/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0168 - acc: 0.9939\n",
      "Epoch 79: val_loss improved from 0.02471 to 0.02451, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0168 - acc: 0.9939 - val_loss: 0.0245 - val_acc: 0.9897\n",
      "Epoch 80/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9950\n",
      "Epoch 80: val_loss did not improve from 0.02451\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0167 - acc: 0.9949 - val_loss: 0.0247 - val_acc: 0.9903\n",
      "Epoch 81/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9950\n",
      "Epoch 81: val_loss improved from 0.02451 to 0.02433, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0162 - acc: 0.9950 - val_loss: 0.0243 - val_acc: 0.9887\n",
      "Epoch 82/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9947\n",
      "Epoch 82: val_loss improved from 0.02433 to 0.02273, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0162 - acc: 0.9947 - val_loss: 0.0227 - val_acc: 0.9907\n",
      "Epoch 83/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0154 - acc: 0.9954\n",
      "Epoch 83: val_loss did not improve from 0.02273\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0289 - val_acc: 0.9897\n",
      "Epoch 84/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0157 - acc: 0.9949\n",
      "Epoch 84: val_loss did not improve from 0.02273\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0241 - val_acc: 0.9910\n",
      "Epoch 85/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0156 - acc: 0.9951\n",
      "Epoch 85: val_loss did not improve from 0.02273\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0153 - acc: 0.9953 - val_loss: 0.0272 - val_acc: 0.9893\n",
      "Epoch 86/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0163 - acc: 0.9947\n",
      "Epoch 86: val_loss did not improve from 0.02273\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0246 - val_acc: 0.9893\n",
      "Epoch 87/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0149 - acc: 0.9950\n",
      "Epoch 87: val_loss did not improve from 0.02273\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0230 - val_acc: 0.9897\n",
      "Epoch 88/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0147 - acc: 0.9946\n",
      "Epoch 88: val_loss did not improve from 0.02273\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 0.9948 - val_loss: 0.0257 - val_acc: 0.9903\n",
      "Epoch 89/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9955\n",
      "Epoch 89: val_loss did not improve from 0.02273\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0143 - acc: 0.9955 - val_loss: 0.0292 - val_acc: 0.9887\n",
      "Epoch 90/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0140 - acc: 0.9951\n",
      "Epoch 90: val_loss improved from 0.02273 to 0.02074, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0144 - acc: 0.9953 - val_loss: 0.0207 - val_acc: 0.9907\n",
      "Epoch 91/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0147 - acc: 0.9959\n",
      "Epoch 91: val_loss improved from 0.02074 to 0.02037, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0146 - acc: 0.9959 - val_loss: 0.0204 - val_acc: 0.9917\n",
      "Epoch 92/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0138 - acc: 0.9958\n",
      "Epoch 92: val_loss improved from 0.02037 to 0.02029, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0137 - acc: 0.9959 - val_loss: 0.0203 - val_acc: 0.9913\n",
      "Epoch 93/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0141 - acc: 0.9955\n",
      "Epoch 93: val_loss did not improve from 0.02029\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0138 - acc: 0.9957 - val_loss: 0.0224 - val_acc: 0.9913\n",
      "Epoch 94/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0135 - acc: 0.9960\n",
      "Epoch 94: val_loss did not improve from 0.02029\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0133 - acc: 0.9958 - val_loss: 0.0228 - val_acc: 0.9917\n",
      "Epoch 95/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9957\n",
      "Epoch 95: val_loss did not improve from 0.02029\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.0224 - val_acc: 0.9913\n",
      "Epoch 96/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0133 - acc: 0.9958\n",
      "Epoch 96: val_loss did not improve from 0.02029\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0132 - acc: 0.9959 - val_loss: 0.0224 - val_acc: 0.9907\n",
      "Epoch 97/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9963\n",
      "Epoch 97: val_loss improved from 0.02029 to 0.02017, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0130 - acc: 0.9963 - val_loss: 0.0202 - val_acc: 0.9910\n",
      "Epoch 98/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9965\n",
      "Epoch 98: val_loss did not improve from 0.02017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0121 - acc: 0.9965 - val_loss: 0.0207 - val_acc: 0.9903\n",
      "Epoch 99/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0127 - acc: 0.9963\n",
      "Epoch 99: val_loss improved from 0.02017 to 0.01971, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0123 - acc: 0.9965 - val_loss: 0.0197 - val_acc: 0.9917\n",
      "Epoch 100/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9965\n",
      "Epoch 100: val_loss improved from 0.01971 to 0.01881, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.9965 - val_loss: 0.0188 - val_acc: 0.9920\n",
      "Epoch 101/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0117 - acc: 0.9967\n",
      "Epoch 101: val_loss improved from 0.01881 to 0.01851, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.9967 - val_loss: 0.0185 - val_acc: 0.9913\n",
      "Epoch 102/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9971\n",
      "Epoch 102: val_loss did not improve from 0.01851\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.9970 - val_loss: 0.0214 - val_acc: 0.9910\n",
      "Epoch 103/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9970\n",
      "Epoch 103: val_loss did not improve from 0.01851\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0225 - val_acc: 0.9910\n",
      "Epoch 104/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9957\n",
      "Epoch 104: val_loss improved from 0.01851 to 0.01839, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.9958 - val_loss: 0.0184 - val_acc: 0.9923\n",
      "Epoch 105/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0112 - acc: 0.9970\n",
      "Epoch 105: val_loss did not improve from 0.01839\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.0191 - val_acc: 0.9927\n",
      "Epoch 106/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0107 - acc: 0.9973\n",
      "Epoch 106: val_loss did not improve from 0.01839\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.9973 - val_loss: 0.0200 - val_acc: 0.9907\n",
      "Epoch 107/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0111 - acc: 0.9969\n",
      "Epoch 107: val_loss improved from 0.01839 to 0.01824, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.9969 - val_loss: 0.0182 - val_acc: 0.9920\n",
      "Epoch 108/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0105 - acc: 0.9968\n",
      "Epoch 108: val_loss improved from 0.01824 to 0.01764, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.0176 - val_acc: 0.9927\n",
      "Epoch 109/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0108 - acc: 0.9971\n",
      "Epoch 109: val_loss improved from 0.01764 to 0.01719, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0109 - acc: 0.9970 - val_loss: 0.0172 - val_acc: 0.9917\n",
      "Epoch 110/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0115 - acc: 0.9966\n",
      "Epoch 110: val_loss did not improve from 0.01719\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.9967 - val_loss: 0.0181 - val_acc: 0.9930\n",
      "Epoch 111/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0106 - acc: 0.9972\n",
      "Epoch 111: val_loss improved from 0.01719 to 0.01669, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.9970 - val_loss: 0.0167 - val_acc: 0.9930\n",
      "Epoch 112/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0094 - acc: 0.9978\n",
      "Epoch 112: val_loss did not improve from 0.01669\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 0.9975 - val_loss: 0.0312 - val_acc: 0.9883\n",
      "Epoch 113/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0109 - acc: 0.9966\n",
      "Epoch 113: val_loss did not improve from 0.01669\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0178 - val_acc: 0.9930\n",
      "Epoch 114/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9973\n",
      "Epoch 114: val_loss did not improve from 0.01669\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.0176 - val_acc: 0.9913\n",
      "Epoch 115/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9964\n",
      "Epoch 115: val_loss did not improve from 0.01669\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0186 - val_acc: 0.9927\n",
      "Epoch 116/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0096 - acc: 0.9975\n",
      "Epoch 116: val_loss did not improve from 0.01669\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0173 - val_acc: 0.9920\n",
      "Epoch 117/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0094 - acc: 0.9973\n",
      "Epoch 117: val_loss did not improve from 0.01669\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.9976 - val_loss: 0.0186 - val_acc: 0.9933\n",
      "Epoch 118/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0099 - acc: 0.9977\n",
      "Epoch 118: val_loss improved from 0.01669 to 0.01664, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0166 - val_acc: 0.9933\n",
      "Epoch 119/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9970\n",
      "Epoch 119: val_loss improved from 0.01664 to 0.01614, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.0161 - val_acc: 0.9930\n",
      "Epoch 120/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0093 - acc: 0.9973\n",
      "Epoch 120: val_loss did not improve from 0.01614\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0164 - val_acc: 0.9923\n",
      "Epoch 121/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9972\n",
      "Epoch 121: val_loss did not improve from 0.01614\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0091 - acc: 0.9973 - val_loss: 0.0181 - val_acc: 0.9920\n",
      "Epoch 122/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0083 - acc: 0.9975\n",
      "Epoch 122: val_loss did not improve from 0.01614\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0174 - val_acc: 0.9933\n",
      "Epoch 123/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 123: val_loss improved from 0.01614 to 0.01484, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.0148 - val_acc: 0.9947\n",
      "Epoch 124/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 124: val_loss did not improve from 0.01484\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0201 - val_acc: 0.9920\n",
      "Epoch 125/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 125: val_loss did not improve from 0.01484\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0196 - val_acc: 0.9923\n",
      "Epoch 126/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9965\n",
      "Epoch 126: val_loss improved from 0.01484 to 0.01464, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 0.9966 - val_loss: 0.0146 - val_acc: 0.9933\n",
      "Epoch 127/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0086 - acc: 0.9978\n",
      "Epoch 127: val_loss did not improve from 0.01464\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0083 - acc: 0.9979 - val_loss: 0.0150 - val_acc: 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0077 - acc: 0.9980\n",
      "Epoch 128: val_loss did not improve from 0.01464\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0152 - val_acc: 0.9950\n",
      "Epoch 129/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0085 - acc: 0.9981\n",
      "Epoch 129: val_loss did not improve from 0.01464\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0148 - val_acc: 0.9947\n",
      "Epoch 130/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9982\n",
      "Epoch 130: val_loss improved from 0.01464 to 0.01344, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0134 - val_acc: 0.9947\n",
      "Epoch 131/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0082 - acc: 0.9980\n",
      "Epoch 131: val_loss did not improve from 0.01344\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0147 - val_acc: 0.9937\n",
      "Epoch 132/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9982\n",
      "Epoch 132: val_loss did not improve from 0.01344\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0080 - acc: 0.9981 - val_loss: 0.0218 - val_acc: 0.9903\n",
      "Epoch 133/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0075 - acc: 0.9983\n",
      "Epoch 133: val_loss did not improve from 0.01344\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0146 - val_acc: 0.9943\n",
      "Epoch 134/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9981\n",
      "Epoch 134: val_loss improved from 0.01344 to 0.01261, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0075 - acc: 0.9981 - val_loss: 0.0126 - val_acc: 0.9950\n",
      "Epoch 135/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9984\n",
      "Epoch 135: val_loss did not improve from 0.01261\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 0.0144 - val_acc: 0.9937\n",
      "Epoch 136/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0074 - acc: 0.9979\n",
      "Epoch 136: val_loss did not improve from 0.01261\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.0155 - val_acc: 0.9933\n",
      "Epoch 137/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0071 - acc: 0.9985\n",
      "Epoch 137: val_loss did not improve from 0.01261\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0070 - acc: 0.9985 - val_loss: 0.0155 - val_acc: 0.9933\n",
      "Epoch 138/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0065 - acc: 0.9984\n",
      "Epoch 138: val_loss did not improve from 0.01261\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0065 - acc: 0.9984 - val_loss: 0.0176 - val_acc: 0.9923\n",
      "Epoch 139/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9979\n",
      "Epoch 139: val_loss did not improve from 0.01261\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.0128 - val_acc: 0.9943\n",
      "Epoch 140/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0066 - acc: 0.9982\n",
      "Epoch 140: val_loss improved from 0.01261 to 0.01229, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0123 - val_acc: 0.9950\n",
      "Epoch 141/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0066 - acc: 0.9986\n",
      "Epoch 141: val_loss improved from 0.01229 to 0.01214, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 0.9986 - val_loss: 0.0121 - val_acc: 0.9957\n",
      "Epoch 142/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0066 - acc: 0.9983\n",
      "Epoch 142: val_loss improved from 0.01214 to 0.01197, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0066 - acc: 0.9984 - val_loss: 0.0120 - val_acc: 0.9957\n",
      "Epoch 143/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9982\n",
      "Epoch 143: val_loss improved from 0.01197 to 0.01156, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0116 - val_acc: 0.9957\n",
      "Epoch 144/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0066 - acc: 0.9985\n",
      "Epoch 144: val_loss did not improve from 0.01156\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 0.9986 - val_loss: 0.0122 - val_acc: 0.9957\n",
      "Epoch 145/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9989\n",
      "Epoch 145: val_loss did not improve from 0.01156\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.9989 - val_loss: 0.0125 - val_acc: 0.9947\n",
      "Epoch 146/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0063 - acc: 0.9985\n",
      "Epoch 146: val_loss did not improve from 0.01156\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.9985 - val_loss: 0.0116 - val_acc: 0.9957\n",
      "Epoch 147/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0059 - acc: 0.9989\n",
      "Epoch 147: val_loss did not improve from 0.01156\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0123 - val_acc: 0.9950\n",
      "Epoch 148/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0064 - acc: 0.9985\n",
      "Epoch 148: val_loss did not improve from 0.01156\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.0133 - val_acc: 0.9947\n",
      "Epoch 149/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9986\n",
      "Epoch 149: val_loss did not improve from 0.01156\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.0117 - val_acc: 0.9957\n",
      "Epoch 150/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0060 - acc: 0.9987\n",
      "Epoch 150: val_loss improved from 0.01156 to 0.01090, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0109 - val_acc: 0.9957\n",
      "Epoch 151/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0062 - acc: 0.9985\n",
      "Epoch 151: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.9985 - val_loss: 0.0136 - val_acc: 0.9953\n",
      "Epoch 152/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9987\n",
      "Epoch 152: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0113 - val_acc: 0.9953\n",
      "Epoch 153/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0054 - acc: 0.9988\n",
      "Epoch 153: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.9988 - val_loss: 0.0114 - val_acc: 0.9960\n",
      "Epoch 154/200\n",
      "335/376 [=========================>....] - ETA: 0s - loss: 0.0056 - acc: 0.9989\n",
      "Epoch 154: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 0.9987 - val_loss: 0.0153 - val_acc: 0.9930\n",
      "Epoch 155/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9991\n",
      "Epoch 155: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0055 - acc: 0.9991 - val_loss: 0.0116 - val_acc: 0.9950\n",
      "Epoch 156/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0055 - acc: 0.9991\n",
      "Epoch 156: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0054 - acc: 0.9991 - val_loss: 0.0119 - val_acc: 0.9947\n",
      "Epoch 157/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0050 - acc: 0.9991\n",
      "Epoch 157: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.9992 - val_loss: 0.0124 - val_acc: 0.9953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9986\n",
      "Epoch 158: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.0126 - val_acc: 0.9950\n",
      "Epoch 159/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0053 - acc: 0.9995\n",
      "Epoch 159: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0110 - val_acc: 0.9953\n",
      "Epoch 160/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0050 - acc: 0.9991\n",
      "Epoch 160: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 0.9992 - val_loss: 0.0130 - val_acc: 0.9960\n",
      "Epoch 161/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0052 - acc: 0.9989\n",
      "Epoch 161: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0052 - acc: 0.9989 - val_loss: 0.0120 - val_acc: 0.9957\n",
      "Epoch 162/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9991\n",
      "Epoch 162: val_loss did not improve from 0.01090\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 0.9992 - val_loss: 0.0131 - val_acc: 0.9947\n",
      "Epoch 163/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9990\n",
      "Epoch 163: val_loss improved from 0.01090 to 0.01054, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.0105 - val_acc: 0.9960\n",
      "Epoch 164/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0047 - acc: 0.9991\n",
      "Epoch 164: val_loss did not improve from 0.01054\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0243 - val_acc: 0.9910\n",
      "Epoch 165/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9995\n",
      "Epoch 165: val_loss did not improve from 0.01054\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0130 - val_acc: 0.9943\n",
      "Epoch 166/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9992\n",
      "Epoch 166: val_loss improved from 0.01054 to 0.01020, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.9993 - val_loss: 0.0102 - val_acc: 0.9960\n",
      "Epoch 167/200\n",
      "328/376 [=========================>....] - ETA: 0s - loss: 0.0041 - acc: 0.9993\n",
      "Epoch 167: val_loss did not improve from 0.01020\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0116 - val_acc: 0.9957\n",
      "Epoch 168/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9990\n",
      "Epoch 168: val_loss did not improve from 0.01020\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.9989 - val_loss: 0.0114 - val_acc: 0.9953\n",
      "Epoch 169/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0047 - acc: 0.9993\n",
      "Epoch 169: val_loss improved from 0.01020 to 0.00982, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.9993 - val_loss: 0.0098 - val_acc: 0.9957\n",
      "Epoch 170/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0044 - acc: 0.9991\n",
      "Epoch 170: val_loss did not improve from 0.00982\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.0165 - val_acc: 0.9937\n",
      "Epoch 171/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9992\n",
      "Epoch 171: val_loss improved from 0.00982 to 0.00963, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 0.0096 - val_acc: 0.9967\n",
      "Epoch 172/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0039 - acc: 0.9997\n",
      "Epoch 172: val_loss did not improve from 0.00963\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.9997 - val_loss: 0.0144 - val_acc: 0.9953\n",
      "Epoch 173/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9991\n",
      "Epoch 173: val_loss did not improve from 0.00963\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0043 - acc: 0.9991 - val_loss: 0.0104 - val_acc: 0.9957\n",
      "Epoch 174/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0040 - acc: 0.9993\n",
      "Epoch 174: val_loss did not improve from 0.00963\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.9993 - val_loss: 0.0100 - val_acc: 0.9957\n",
      "Epoch 175/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0044 - acc: 0.9991\n",
      "Epoch 175: val_loss did not improve from 0.00963\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.9992 - val_loss: 0.0105 - val_acc: 0.9953\n",
      "Epoch 176/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9995\n",
      "Epoch 176: val_loss improved from 0.00963 to 0.00925, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.9995 - val_loss: 0.0093 - val_acc: 0.9960\n",
      "Epoch 177/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0038 - acc: 0.9994\n",
      "Epoch 177: val_loss did not improve from 0.00925\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0038 - acc: 0.9994 - val_loss: 0.0140 - val_acc: 0.9943\n",
      "Epoch 178/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0038 - acc: 0.9997\n",
      "Epoch 178: val_loss did not improve from 0.00925\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0038 - acc: 0.9997 - val_loss: 0.0146 - val_acc: 0.9943\n",
      "Epoch 179/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9994\n",
      "Epoch 179: val_loss improved from 0.00925 to 0.00915, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9963\n",
      "Epoch 180/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0035 - acc: 0.9994\n",
      "Epoch 180: val_loss did not improve from 0.00915\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0036 - acc: 0.9993 - val_loss: 0.0093 - val_acc: 0.9963\n",
      "Epoch 181/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0047 - acc: 0.9987\n",
      "Epoch 181: val_loss did not improve from 0.00915\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0105 - val_acc: 0.9950\n",
      "Epoch 182/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9997\n",
      "Epoch 182: val_loss did not improve from 0.00915\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.9997 - val_loss: 0.0105 - val_acc: 0.9957\n",
      "Epoch 183/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0042 - acc: 0.9993\n",
      "Epoch 183: val_loss did not improve from 0.00915\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.9993 - val_loss: 0.0093 - val_acc: 0.9957\n",
      "Epoch 184/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0034 - acc: 0.9997\n",
      "Epoch 184: val_loss improved from 0.00915 to 0.00847, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.0085 - val_acc: 0.9967\n",
      "Epoch 185/200\n",
      "329/376 [=========================>....] - ETA: 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 185: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 0.9998 - val_loss: 0.0089 - val_acc: 0.9960\n",
      "Epoch 186/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0032 - acc: 0.9995\n",
      "Epoch 186: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0128 - val_acc: 0.9943\n",
      "Epoch 187/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 187: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 0.9992 - val_loss: 0.0087 - val_acc: 0.9973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 188: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0032 - acc: 0.9998 - val_loss: 0.0090 - val_acc: 0.9963\n",
      "Epoch 189/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0031 - acc: 0.9997\n",
      "Epoch 189: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0031 - acc: 0.9998 - val_loss: 0.0118 - val_acc: 0.9953\n",
      "Epoch 190/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0033 - acc: 0.9994\n",
      "Epoch 190: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0034 - acc: 0.9993 - val_loss: 0.0106 - val_acc: 0.9960\n",
      "Epoch 191/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0039 - acc: 0.9993\n",
      "Epoch 191: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.9993 - val_loss: 0.0163 - val_acc: 0.9937\n",
      "Epoch 192/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9996\n",
      "Epoch 192: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0094 - val_acc: 0.9960\n",
      "Epoch 193/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9995\n",
      "Epoch 193: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0030 - acc: 0.9995 - val_loss: 0.0093 - val_acc: 0.9957\n",
      "Epoch 194/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9997\n",
      "Epoch 194: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0111 - val_acc: 0.9953\n",
      "Epoch 195/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 195: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0027 - acc: 0.9998 - val_loss: 0.0103 - val_acc: 0.9957\n",
      "Epoch 196/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0034 - acc: 0.9994\n",
      "Epoch 196: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0036 - acc: 0.9993 - val_loss: 0.0112 - val_acc: 0.9957\n",
      "Epoch 197/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0027 - acc: 0.9999\n",
      "Epoch 197: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0094 - val_acc: 0.9967\n",
      "Epoch 198/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 198: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 0.9998 - val_loss: 0.0087 - val_acc: 0.9963\n",
      "Epoch 199/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0046 - acc: 0.9989\n",
      "Epoch 199: val_loss did not improve from 0.00847\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 0.9990 - val_loss: 0.0119 - val_acc: 0.9960\n",
      "Epoch 200/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 200: val_loss improved from 0.00847 to 0.00816, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9970\n",
      "94/94 [==============================] - 0s 659us/step\n",
      "Epoch 1/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.3169 - acc: 0.8879\n",
      "Epoch 1: val_loss improved from inf to 0.17785, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.3054 - acc: 0.8921 - val_loss: 0.1779 - val_acc: 0.9341\n",
      "Epoch 2/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.1645 - acc: 0.9406\n",
      "Epoch 2: val_loss improved from 0.17785 to 0.13186, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1627 - acc: 0.9414 - val_loss: 0.1319 - val_acc: 0.9514\n",
      "Epoch 3/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.1347 - acc: 0.9532\n",
      "Epoch 3: val_loss improved from 0.13186 to 0.12227, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1344 - acc: 0.9529 - val_loss: 0.1223 - val_acc: 0.9517\n",
      "Epoch 4/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.1223 - acc: 0.9561\n",
      "Epoch 4: val_loss improved from 0.12227 to 0.10240, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1221 - acc: 0.9564 - val_loss: 0.1024 - val_acc: 0.9624\n",
      "Epoch 5/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9574\n",
      "Epoch 5: val_loss improved from 0.10240 to 0.09436, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1129 - acc: 0.9579 - val_loss: 0.0944 - val_acc: 0.9657\n",
      "Epoch 6/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.1061 - acc: 0.9609\n",
      "Epoch 6: val_loss improved from 0.09436 to 0.08869, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1070 - acc: 0.9610 - val_loss: 0.0887 - val_acc: 0.9660\n",
      "Epoch 7/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.1013 - acc: 0.9628\n",
      "Epoch 7: val_loss did not improve from 0.08869\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1025 - acc: 0.9624 - val_loss: 0.0924 - val_acc: 0.9697\n",
      "Epoch 8/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0965 - acc: 0.9656\n",
      "Epoch 8: val_loss improved from 0.08869 to 0.08095, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0962 - acc: 0.9655 - val_loss: 0.0809 - val_acc: 0.9714\n",
      "Epoch 9/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9661\n",
      "Epoch 9: val_loss improved from 0.08095 to 0.07667, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0916 - acc: 0.9663 - val_loss: 0.0767 - val_acc: 0.9734\n",
      "Epoch 10/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0877 - acc: 0.9680\n",
      "Epoch 10: val_loss improved from 0.07667 to 0.07627, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0875 - acc: 0.9681 - val_loss: 0.0763 - val_acc: 0.9720\n",
      "Epoch 11/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0864 - acc: 0.9679\n",
      "Epoch 11: val_loss improved from 0.07627 to 0.07025, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0855 - acc: 0.9682 - val_loss: 0.0702 - val_acc: 0.9720\n",
      "Epoch 12/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0804 - acc: 0.9702\n",
      "Epoch 12: val_loss improved from 0.07025 to 0.06726, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0806 - acc: 0.9699 - val_loss: 0.0673 - val_acc: 0.9724\n",
      "Epoch 13/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0795 - acc: 0.9697\n",
      "Epoch 13: val_loss improved from 0.06726 to 0.06469, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0785 - acc: 0.9703 - val_loss: 0.0647 - val_acc: 0.9727\n",
      "Epoch 14/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9707\n",
      "Epoch 14: val_loss improved from 0.06469 to 0.06419, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0774 - acc: 0.9707 - val_loss: 0.0642 - val_acc: 0.9747\n",
      "Epoch 15/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9724\n",
      "Epoch 15: val_loss improved from 0.06419 to 0.05983, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0726 - acc: 0.9723 - val_loss: 0.0598 - val_acc: 0.9760\n",
      "Epoch 16/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0721 - acc: 0.9728\n",
      "Epoch 16: val_loss improved from 0.05983 to 0.05770, saving model to best_model_simple.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0710 - acc: 0.9734 - val_loss: 0.0577 - val_acc: 0.9767\n",
      "Epoch 17/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0681 - acc: 0.9752\n",
      "Epoch 17: val_loss improved from 0.05770 to 0.05452, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0679 - acc: 0.9749 - val_loss: 0.0545 - val_acc: 0.9754\n",
      "Epoch 18/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0659 - acc: 0.9749\n",
      "Epoch 18: val_loss improved from 0.05452 to 0.05241, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0652 - acc: 0.9748 - val_loss: 0.0524 - val_acc: 0.9770\n",
      "Epoch 19/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9754\n",
      "Epoch 19: val_loss did not improve from 0.05241\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0643 - acc: 0.9758 - val_loss: 0.0575 - val_acc: 0.9744\n",
      "Epoch 20/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9773\n",
      "Epoch 20: val_loss improved from 0.05241 to 0.05168, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0614 - acc: 0.9774 - val_loss: 0.0517 - val_acc: 0.9777\n",
      "Epoch 21/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9778\n",
      "Epoch 21: val_loss did not improve from 0.05168\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0602 - acc: 0.9776 - val_loss: 0.0535 - val_acc: 0.9754\n",
      "Epoch 22/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0571 - acc: 0.9778\n",
      "Epoch 22: val_loss improved from 0.05168 to 0.04628, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0575 - acc: 0.9776 - val_loss: 0.0463 - val_acc: 0.9784\n",
      "Epoch 23/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9772\n",
      "Epoch 23: val_loss did not improve from 0.04628\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0573 - acc: 0.9774 - val_loss: 0.0464 - val_acc: 0.9784\n",
      "Epoch 24/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0534 - acc: 0.9796\n",
      "Epoch 24: val_loss improved from 0.04628 to 0.04389, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0539 - acc: 0.9794 - val_loss: 0.0439 - val_acc: 0.9820\n",
      "Epoch 25/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0523 - acc: 0.9792\n",
      "Epoch 25: val_loss did not improve from 0.04389\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0529 - acc: 0.9793 - val_loss: 0.0532 - val_acc: 0.9837\n",
      "Epoch 26/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9806\n",
      "Epoch 26: val_loss did not improve from 0.04389\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0522 - acc: 0.9807 - val_loss: 0.0439 - val_acc: 0.9780\n",
      "Epoch 27/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9813\n",
      "Epoch 27: val_loss improved from 0.04389 to 0.04184, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0506 - acc: 0.9812 - val_loss: 0.0418 - val_acc: 0.9850\n",
      "Epoch 28/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0499 - acc: 0.9800\n",
      "Epoch 28: val_loss improved from 0.04184 to 0.04044, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0490 - acc: 0.9807 - val_loss: 0.0404 - val_acc: 0.9840\n",
      "Epoch 29/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0490 - acc: 0.9806\n",
      "Epoch 29: val_loss improved from 0.04044 to 0.03982, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0489 - acc: 0.9807 - val_loss: 0.0398 - val_acc: 0.9847\n",
      "Epoch 30/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9817\n",
      "Epoch 30: val_loss did not improve from 0.03982\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0468 - acc: 0.9817 - val_loss: 0.0481 - val_acc: 0.9850\n",
      "Epoch 31/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0453 - acc: 0.9819\n",
      "Epoch 31: val_loss improved from 0.03982 to 0.03981, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0461 - acc: 0.9819 - val_loss: 0.0398 - val_acc: 0.9877\n",
      "Epoch 32/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0460 - acc: 0.9822\n",
      "Epoch 32: val_loss did not improve from 0.03981\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0457 - acc: 0.9824 - val_loss: 0.0410 - val_acc: 0.9863\n",
      "Epoch 33/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0444 - acc: 0.9831\n",
      "Epoch 33: val_loss improved from 0.03981 to 0.03686, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0441 - acc: 0.9828 - val_loss: 0.0369 - val_acc: 0.9824\n",
      "Epoch 34/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0441 - acc: 0.9828\n",
      "Epoch 34: val_loss improved from 0.03686 to 0.03633, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0445 - acc: 0.9829 - val_loss: 0.0363 - val_acc: 0.9867\n",
      "Epoch 35/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0420 - acc: 0.9831\n",
      "Epoch 35: val_loss did not improve from 0.03633\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0422 - acc: 0.9830 - val_loss: 0.0407 - val_acc: 0.9890\n",
      "Epoch 36/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9840\n",
      "Epoch 36: val_loss did not improve from 0.03633\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0415 - acc: 0.9839 - val_loss: 0.0374 - val_acc: 0.9824\n",
      "Epoch 37/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9837\n",
      "Epoch 37: val_loss improved from 0.03633 to 0.03612, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0427 - acc: 0.9837 - val_loss: 0.0361 - val_acc: 0.9883\n",
      "Epoch 38/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9846\n",
      "Epoch 38: val_loss improved from 0.03612 to 0.03398, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0408 - acc: 0.9845 - val_loss: 0.0340 - val_acc: 0.9857\n",
      "Epoch 39/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0408 - acc: 0.9849\n",
      "Epoch 39: val_loss did not improve from 0.03398\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0405 - acc: 0.9849 - val_loss: 0.0356 - val_acc: 0.9867\n",
      "Epoch 40/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0394 - acc: 0.9854\n",
      "Epoch 40: val_loss improved from 0.03398 to 0.03378, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0399 - acc: 0.9850 - val_loss: 0.0338 - val_acc: 0.9840\n",
      "Epoch 41/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9851\n",
      "Epoch 41: val_loss did not improve from 0.03378\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0383 - acc: 0.9851 - val_loss: 0.0377 - val_acc: 0.9890\n",
      "Epoch 42/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0382 - acc: 0.9853\n",
      "Epoch 42: val_loss improved from 0.03378 to 0.03222, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0388 - acc: 0.9851 - val_loss: 0.0322 - val_acc: 0.9857\n",
      "Epoch 43/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0378 - acc: 0.9849\n",
      "Epoch 43: val_loss improved from 0.03222 to 0.03196, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0372 - acc: 0.9850 - val_loss: 0.0320 - val_acc: 0.9860\n",
      "Epoch 44/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9852\n",
      "Epoch 44: val_loss improved from 0.03196 to 0.03157, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0374 - acc: 0.9852 - val_loss: 0.0316 - val_acc: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0389 - acc: 0.9847\n",
      "Epoch 45: val_loss improved from 0.03157 to 0.02986, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0382 - acc: 0.9851 - val_loss: 0.0299 - val_acc: 0.9900\n",
      "Epoch 46/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0368 - acc: 0.9856\n",
      "Epoch 46: val_loss did not improve from 0.02986\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0364 - acc: 0.9858 - val_loss: 0.0344 - val_acc: 0.9910\n",
      "Epoch 47/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0354 - acc: 0.9858\n",
      "Epoch 47: val_loss did not improve from 0.02986\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0359 - acc: 0.9857 - val_loss: 0.0310 - val_acc: 0.9873\n",
      "Epoch 48/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0347 - acc: 0.9868\n",
      "Epoch 48: val_loss improved from 0.02986 to 0.02902, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0357 - acc: 0.9866 - val_loss: 0.0290 - val_acc: 0.9880\n",
      "Epoch 49/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0349 - acc: 0.9860\n",
      "Epoch 49: val_loss did not improve from 0.02902\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0348 - acc: 0.9860 - val_loss: 0.0308 - val_acc: 0.9907\n",
      "Epoch 50/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0348 - acc: 0.9859\n",
      "Epoch 50: val_loss did not improve from 0.02902\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0345 - acc: 0.9859 - val_loss: 0.0294 - val_acc: 0.9887\n",
      "Epoch 51/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0355 - acc: 0.9862\n",
      "Epoch 51: val_loss did not improve from 0.02902\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0349 - acc: 0.9863 - val_loss: 0.0294 - val_acc: 0.9870\n",
      "Epoch 52/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0337 - acc: 0.9867\n",
      "Epoch 52: val_loss improved from 0.02902 to 0.02803, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0334 - acc: 0.9868 - val_loss: 0.0280 - val_acc: 0.9903\n",
      "Epoch 53/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0326 - acc: 0.9872\n",
      "Epoch 53: val_loss improved from 0.02803 to 0.02727, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0327 - acc: 0.9870 - val_loss: 0.0273 - val_acc: 0.9883\n",
      "Epoch 54/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9879\n",
      "Epoch 54: val_loss did not improve from 0.02727\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0328 - acc: 0.9876 - val_loss: 0.0279 - val_acc: 0.9917\n",
      "Epoch 55/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0325 - acc: 0.9867\n",
      "Epoch 55: val_loss improved from 0.02727 to 0.02702, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0321 - acc: 0.9868 - val_loss: 0.0270 - val_acc: 0.9890\n",
      "Epoch 56/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0318 - acc: 0.9877\n",
      "Epoch 56: val_loss did not improve from 0.02702\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0316 - acc: 0.9878 - val_loss: 0.0304 - val_acc: 0.9913\n",
      "Epoch 57/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9888\n",
      "Epoch 57: val_loss did not improve from 0.02702\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0307 - acc: 0.9887 - val_loss: 0.0296 - val_acc: 0.9860\n",
      "Epoch 58/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0299 - acc: 0.9882\n",
      "Epoch 58: val_loss did not improve from 0.02702\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0305 - acc: 0.9880 - val_loss: 0.0274 - val_acc: 0.9903\n",
      "Epoch 59/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0307 - acc: 0.9882\n",
      "Epoch 59: val_loss did not improve from 0.02702\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0305 - acc: 0.9882 - val_loss: 0.0272 - val_acc: 0.9917\n",
      "Epoch 60/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9890\n",
      "Epoch 60: val_loss improved from 0.02702 to 0.02558, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0296 - acc: 0.9886 - val_loss: 0.0256 - val_acc: 0.9877\n",
      "Epoch 61/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0308 - acc: 0.9879\n",
      "Epoch 61: val_loss did not improve from 0.02558\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0309 - acc: 0.9878 - val_loss: 0.0273 - val_acc: 0.9900\n",
      "Epoch 62/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0289 - acc: 0.9889\n",
      "Epoch 62: val_loss did not improve from 0.02558\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0289 - acc: 0.9889 - val_loss: 0.0258 - val_acc: 0.9907\n",
      "Epoch 63/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9892\n",
      "Epoch 63: val_loss improved from 0.02558 to 0.02554, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0286 - acc: 0.9893 - val_loss: 0.0255 - val_acc: 0.9873\n",
      "Epoch 64/200\n",
      "332/376 [=========================>....] - ETA: 0s - loss: 0.0273 - acc: 0.9896\n",
      "Epoch 64: val_loss improved from 0.02554 to 0.02484, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0281 - acc: 0.9893 - val_loss: 0.0248 - val_acc: 0.9880\n",
      "Epoch 65/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0281 - acc: 0.9890\n",
      "Epoch 65: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0281 - acc: 0.9890 - val_loss: 0.0274 - val_acc: 0.9907\n",
      "Epoch 66/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0292 - acc: 0.9885\n",
      "Epoch 66: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0297 - acc: 0.9881 - val_loss: 0.0301 - val_acc: 0.9890\n",
      "Epoch 67/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9896\n",
      "Epoch 67: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0270 - acc: 0.9895 - val_loss: 0.0251 - val_acc: 0.9917\n",
      "Epoch 68/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9899\n",
      "Epoch 68: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0272 - acc: 0.9897 - val_loss: 0.0293 - val_acc: 0.9897\n",
      "Epoch 69/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0277 - acc: 0.9895\n",
      "Epoch 69: val_loss improved from 0.02484 to 0.02338, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0234 - val_acc: 0.9913\n",
      "Epoch 70/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0264 - acc: 0.9884\n",
      "Epoch 70: val_loss improved from 0.02338 to 0.02275, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0267 - acc: 0.9884 - val_loss: 0.0228 - val_acc: 0.9913\n",
      "Epoch 71/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0263 - acc: 0.9897\n",
      "Epoch 71: val_loss did not improve from 0.02275\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0265 - acc: 0.9898 - val_loss: 0.0232 - val_acc: 0.9913\n",
      "Epoch 72/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0240 - acc: 0.9907\n",
      "Epoch 72: val_loss did not improve from 0.02275\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0254 - acc: 0.9902 - val_loss: 0.0252 - val_acc: 0.9910\n",
      "Epoch 73/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0250 - acc: 0.9902\n",
      "Epoch 73: val_loss did not improve from 0.02275\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0250 - acc: 0.9903 - val_loss: 0.0246 - val_acc: 0.9917\n",
      "Epoch 74/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0252 - acc: 0.9904\n",
      "Epoch 74: val_loss did not improve from 0.02275\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0251 - acc: 0.9903 - val_loss: 0.0307 - val_acc: 0.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9907\n",
      "Epoch 75: val_loss did not improve from 0.02275\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0249 - acc: 0.9907 - val_loss: 0.0247 - val_acc: 0.9923\n",
      "Epoch 76/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0250 - acc: 0.9906\n",
      "Epoch 76: val_loss improved from 0.02275 to 0.02249, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0252 - acc: 0.9905 - val_loss: 0.0225 - val_acc: 0.9917\n",
      "Epoch 77/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9910\n",
      "Epoch 77: val_loss did not improve from 0.02249\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0234 - acc: 0.9909 - val_loss: 0.0228 - val_acc: 0.9893\n",
      "Epoch 78/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9904\n",
      "Epoch 78: val_loss did not improve from 0.02249\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0241 - acc: 0.9904 - val_loss: 0.0271 - val_acc: 0.9903\n",
      "Epoch 79/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0242 - acc: 0.9910\n",
      "Epoch 79: val_loss improved from 0.02249 to 0.02109, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0243 - acc: 0.9908 - val_loss: 0.0211 - val_acc: 0.9913\n",
      "Epoch 80/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0223 - acc: 0.9916\n",
      "Epoch 80: val_loss did not improve from 0.02109\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0230 - acc: 0.9910 - val_loss: 0.0247 - val_acc: 0.9920\n",
      "Epoch 81/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0241 - acc: 0.9909\n",
      "Epoch 81: val_loss did not improve from 0.02109\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0236 - acc: 0.9912 - val_loss: 0.0211 - val_acc: 0.9917\n",
      "Epoch 82/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9922\n",
      "Epoch 82: val_loss improved from 0.02109 to 0.01992, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0223 - acc: 0.9922 - val_loss: 0.0199 - val_acc: 0.9927\n",
      "Epoch 83/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0220 - acc: 0.9915\n",
      "Epoch 83: val_loss did not improve from 0.01992\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0220 - acc: 0.9916 - val_loss: 0.0214 - val_acc: 0.9923\n",
      "Epoch 84/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0223 - acc: 0.9912\n",
      "Epoch 84: val_loss did not improve from 0.01992\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0223 - acc: 0.9913 - val_loss: 0.0209 - val_acc: 0.9927\n",
      "Epoch 85/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0218 - acc: 0.9918\n",
      "Epoch 85: val_loss did not improve from 0.01992\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0218 - acc: 0.9918 - val_loss: 0.0209 - val_acc: 0.9933\n",
      "Epoch 86/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0214 - acc: 0.9913\n",
      "Epoch 86: val_loss did not improve from 0.01992\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0215 - acc: 0.9913 - val_loss: 0.0223 - val_acc: 0.9920\n",
      "Epoch 87/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9913\n",
      "Epoch 87: val_loss did not improve from 0.01992\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0221 - acc: 0.9912 - val_loss: 0.0232 - val_acc: 0.9890\n",
      "Epoch 88/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0213 - acc: 0.9917\n",
      "Epoch 88: val_loss did not improve from 0.01992\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0217 - acc: 0.9915 - val_loss: 0.0301 - val_acc: 0.9907\n",
      "Epoch 89/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9924\n",
      "Epoch 89: val_loss did not improve from 0.01992\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0207 - acc: 0.9923 - val_loss: 0.0220 - val_acc: 0.9920\n",
      "Epoch 90/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9925\n",
      "Epoch 90: val_loss did not improve from 0.01992\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0206 - acc: 0.9925 - val_loss: 0.0208 - val_acc: 0.9907\n",
      "Epoch 91/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0201 - acc: 0.9926\n",
      "Epoch 91: val_loss improved from 0.01992 to 0.01926, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0202 - acc: 0.9925 - val_loss: 0.0193 - val_acc: 0.9930\n",
      "Epoch 92/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9925\n",
      "Epoch 92: val_loss did not improve from 0.01926\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0198 - acc: 0.9925 - val_loss: 0.0216 - val_acc: 0.9923\n",
      "Epoch 93/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0218 - acc: 0.9922\n",
      "Epoch 93: val_loss did not improve from 0.01926\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0218 - acc: 0.9922 - val_loss: 0.0243 - val_acc: 0.9920\n",
      "Epoch 94/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0199 - acc: 0.9923\n",
      "Epoch 94: val_loss did not improve from 0.01926\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0196 - acc: 0.9924 - val_loss: 0.0204 - val_acc: 0.9930\n",
      "Epoch 95/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0195 - acc: 0.9923\n",
      "Epoch 95: val_loss did not improve from 0.01926\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0195 - acc: 0.9923 - val_loss: 0.0196 - val_acc: 0.9920\n",
      "Epoch 96/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0195 - acc: 0.9923\n",
      "Epoch 96: val_loss did not improve from 0.01926\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0195 - acc: 0.9923 - val_loss: 0.0197 - val_acc: 0.9923\n",
      "Epoch 97/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9929\n",
      "Epoch 97: val_loss did not improve from 0.01926\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0189 - acc: 0.9928 - val_loss: 0.0205 - val_acc: 0.9930\n",
      "Epoch 98/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0192 - acc: 0.9934\n",
      "Epoch 98: val_loss did not improve from 0.01926\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0192 - acc: 0.9933 - val_loss: 0.0213 - val_acc: 0.9927\n",
      "Epoch 99/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0201 - acc: 0.9930\n",
      "Epoch 99: val_loss improved from 0.01926 to 0.01871, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0197 - acc: 0.9932 - val_loss: 0.0187 - val_acc: 0.9933\n",
      "Epoch 100/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9936\n",
      "Epoch 100: val_loss improved from 0.01871 to 0.01817, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0177 - acc: 0.9937 - val_loss: 0.0182 - val_acc: 0.9930\n",
      "Epoch 101/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0179 - acc: 0.9936\n",
      "Epoch 101: val_loss did not improve from 0.01817\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0181 - acc: 0.9936 - val_loss: 0.0185 - val_acc: 0.9937\n",
      "Epoch 102/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0177 - acc: 0.9938\n",
      "Epoch 102: val_loss did not improve from 0.01817\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0178 - acc: 0.9938 - val_loss: 0.0182 - val_acc: 0.9943\n",
      "Epoch 103/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0184 - acc: 0.9932\n",
      "Epoch 103: val_loss did not improve from 0.01817\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0184 - acc: 0.9932 - val_loss: 0.0195 - val_acc: 0.9920\n",
      "Epoch 104/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0176 - acc: 0.9938\n",
      "Epoch 104: val_loss improved from 0.01817 to 0.01794, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0178 - acc: 0.9937 - val_loss: 0.0179 - val_acc: 0.9940\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/376 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9934\n",
      "Epoch 105: val_loss did not improve from 0.01794\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0175 - acc: 0.9936 - val_loss: 0.0195 - val_acc: 0.9927\n",
      "Epoch 106/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0181 - acc: 0.9934\n",
      "Epoch 106: val_loss did not improve from 0.01794\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0180 - acc: 0.9934 - val_loss: 0.0191 - val_acc: 0.9943\n",
      "Epoch 107/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9939\n",
      "Epoch 107: val_loss improved from 0.01794 to 0.01793, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0167 - acc: 0.9938 - val_loss: 0.0179 - val_acc: 0.9930\n",
      "Epoch 108/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0171 - acc: 0.9939\n",
      "Epoch 108: val_loss did not improve from 0.01793\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0168 - acc: 0.9941 - val_loss: 0.0187 - val_acc: 0.9923\n",
      "Epoch 109/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0171 - acc: 0.9942\n",
      "Epoch 109: val_loss did not improve from 0.01793\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0185 - val_acc: 0.9937\n",
      "Epoch 110/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0161 - acc: 0.9950\n",
      "Epoch 110: val_loss improved from 0.01793 to 0.01756, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0176 - val_acc: 0.9933\n",
      "Epoch 111/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0166 - acc: 0.9941\n",
      "Epoch 111: val_loss improved from 0.01756 to 0.01697, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0164 - acc: 0.9943 - val_loss: 0.0170 - val_acc: 0.9940\n",
      "Epoch 112/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0167 - acc: 0.9941\n",
      "Epoch 112: val_loss did not improve from 0.01697\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0165 - acc: 0.9943 - val_loss: 0.0192 - val_acc: 0.9927\n",
      "Epoch 113/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0169 - acc: 0.9938\n",
      "Epoch 113: val_loss did not improve from 0.01697\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0162 - acc: 0.9942 - val_loss: 0.0175 - val_acc: 0.9930\n",
      "Epoch 114/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0160 - acc: 0.9941\n",
      "Epoch 114: val_loss did not improve from 0.01697\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0161 - acc: 0.9942 - val_loss: 0.0178 - val_acc: 0.9937\n",
      "Epoch 115/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0161 - acc: 0.9947\n",
      "Epoch 115: val_loss did not improve from 0.01697\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0163 - acc: 0.9945 - val_loss: 0.0383 - val_acc: 0.9883\n",
      "Epoch 116/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0148 - acc: 0.9950\n",
      "Epoch 116: val_loss did not improve from 0.01697\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0157 - acc: 0.9944 - val_loss: 0.0175 - val_acc: 0.9940\n",
      "Epoch 117/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9944\n",
      "Epoch 117: val_loss did not improve from 0.01697\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0151 - acc: 0.9943 - val_loss: 0.0176 - val_acc: 0.9923\n",
      "Epoch 118/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0148 - acc: 0.9945\n",
      "Epoch 118: val_loss did not improve from 0.01697\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0147 - acc: 0.9947 - val_loss: 0.0181 - val_acc: 0.9933\n",
      "Epoch 119/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9947\n",
      "Epoch 119: val_loss did not improve from 0.01697\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0148 - acc: 0.9948 - val_loss: 0.0177 - val_acc: 0.9940\n",
      "Epoch 120/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0146 - acc: 0.9953\n",
      "Epoch 120: val_loss did not improve from 0.01697\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0183 - val_acc: 0.9937\n",
      "Epoch 121/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0146 - acc: 0.9948\n",
      "Epoch 121: val_loss did not improve from 0.01697\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0145 - acc: 0.9948 - val_loss: 0.0183 - val_acc: 0.9923\n",
      "Epoch 122/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0140 - acc: 0.9958\n",
      "Epoch 122: val_loss improved from 0.01697 to 0.01659, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0143 - acc: 0.9956 - val_loss: 0.0166 - val_acc: 0.9933\n",
      "Epoch 123/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0150 - acc: 0.9940\n",
      "Epoch 123: val_loss did not improve from 0.01659\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0149 - acc: 0.9942 - val_loss: 0.0167 - val_acc: 0.9943\n",
      "Epoch 124/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0137 - acc: 0.9962\n",
      "Epoch 124: val_loss improved from 0.01659 to 0.01596, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 0.9962 - val_loss: 0.0160 - val_acc: 0.9940\n",
      "Epoch 125/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9949\n",
      "Epoch 125: val_loss did not improve from 0.01596\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0143 - acc: 0.9949 - val_loss: 0.0190 - val_acc: 0.9930\n",
      "Epoch 126/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0134 - acc: 0.9956\n",
      "Epoch 126: val_loss improved from 0.01596 to 0.01588, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0134 - acc: 0.9957 - val_loss: 0.0159 - val_acc: 0.9940\n",
      "Epoch 127/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9946\n",
      "Epoch 127: val_loss improved from 0.01588 to 0.01543, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0140 - acc: 0.9948 - val_loss: 0.0154 - val_acc: 0.9940\n",
      "Epoch 128/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9956\n",
      "Epoch 128: val_loss did not improve from 0.01543\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.0156 - val_acc: 0.9943\n",
      "Epoch 129/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 129: val_loss did not improve from 0.01543\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0256 - val_acc: 0.9913\n",
      "Epoch 130/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9958\n",
      "Epoch 130: val_loss did not improve from 0.01543\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0128 - acc: 0.9958 - val_loss: 0.0160 - val_acc: 0.9927\n",
      "Epoch 131/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9961\n",
      "Epoch 131: val_loss did not improve from 0.01543\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0134 - acc: 0.9960 - val_loss: 0.0167 - val_acc: 0.9927\n",
      "Epoch 132/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0133 - acc: 0.9953\n",
      "Epoch 132: val_loss did not improve from 0.01543\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0137 - acc: 0.9952 - val_loss: 0.0244 - val_acc: 0.9923\n",
      "Epoch 133/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0129 - acc: 0.9959\n",
      "Epoch 133: val_loss did not improve from 0.01543\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0210 - val_acc: 0.9933\n",
      "Epoch 134/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0126 - acc: 0.9956\n",
      "Epoch 134: val_loss did not improve from 0.01543\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.9956 - val_loss: 0.0333 - val_acc: 0.9920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0144 - acc: 0.9954\n",
      "Epoch 135: val_loss did not improve from 0.01543\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0143 - acc: 0.9954 - val_loss: 0.0157 - val_acc: 0.9947\n",
      "Epoch 136/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0126 - acc: 0.9958\n",
      "Epoch 136: val_loss did not improve from 0.01543\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0162 - val_acc: 0.9943\n",
      "Epoch 137/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9965\n",
      "Epoch 137: val_loss improved from 0.01543 to 0.01455, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.9965 - val_loss: 0.0145 - val_acc: 0.9950\n",
      "Epoch 138/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0117 - acc: 0.9970\n",
      "Epoch 138: val_loss did not improve from 0.01455\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0121 - acc: 0.9969 - val_loss: 0.0147 - val_acc: 0.9940\n",
      "Epoch 139/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0115 - acc: 0.9966\n",
      "Epoch 139: val_loss did not improve from 0.01455\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0161 - val_acc: 0.9943\n",
      "Epoch 140/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0123 - acc: 0.9960\n",
      "Epoch 140: val_loss did not improve from 0.01455\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0145 - val_acc: 0.9950\n",
      "Epoch 141/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0113 - acc: 0.9972\n",
      "Epoch 141: val_loss did not improve from 0.01455\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.9970 - val_loss: 0.0194 - val_acc: 0.9940\n",
      "Epoch 142/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0130 - acc: 0.9958\n",
      "Epoch 142: val_loss did not improve from 0.01455\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0131 - acc: 0.9958 - val_loss: 0.0167 - val_acc: 0.9943\n",
      "Epoch 143/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0113 - acc: 0.9963\n",
      "Epoch 143: val_loss did not improve from 0.01455\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9963 - val_loss: 0.0149 - val_acc: 0.9937\n",
      "Epoch 144/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0117 - acc: 0.9960\n",
      "Epoch 144: val_loss improved from 0.01455 to 0.01417, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0119 - acc: 0.9956 - val_loss: 0.0142 - val_acc: 0.9933\n",
      "Epoch 145/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9968\n",
      "Epoch 145: val_loss did not improve from 0.01417\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0150 - val_acc: 0.9950\n",
      "Epoch 146/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0115 - acc: 0.9959\n",
      "Epoch 146: val_loss improved from 0.01417 to 0.01388, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0114 - acc: 0.9959 - val_loss: 0.0139 - val_acc: 0.9950\n",
      "Epoch 147/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0109 - acc: 0.9967\n",
      "Epoch 147: val_loss improved from 0.01388 to 0.01380, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0138 - val_acc: 0.9950\n",
      "Epoch 148/200\n",
      "374/376 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 148: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.0167 - val_acc: 0.9953\n",
      "Epoch 149/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 149: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0114 - acc: 0.9964 - val_loss: 0.0143 - val_acc: 0.9947\n",
      "Epoch 150/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 150: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9968 - val_loss: 0.0201 - val_acc: 0.9933\n",
      "Epoch 151/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9967\n",
      "Epoch 151: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0144 - val_acc: 0.9943\n",
      "Epoch 152/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9965\n",
      "Epoch 152: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.0141 - val_acc: 0.9947\n",
      "Epoch 153/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0102 - acc: 0.9974\n",
      "Epoch 153: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0106 - acc: 0.9973 - val_loss: 0.0169 - val_acc: 0.9947\n",
      "Epoch 154/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0109 - acc: 0.9965\n",
      "Epoch 154: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0141 - val_acc: 0.9943\n",
      "Epoch 155/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0097 - acc: 0.9978\n",
      "Epoch 155: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.9977 - val_loss: 0.0140 - val_acc: 0.9947\n",
      "Epoch 156/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 156: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0141 - val_acc: 0.9943\n",
      "Epoch 157/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9969\n",
      "Epoch 157: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0158 - val_acc: 0.9950\n",
      "Epoch 158/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9975\n",
      "Epoch 158: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 0.9973 - val_loss: 0.0143 - val_acc: 0.9943\n",
      "Epoch 159/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9971\n",
      "Epoch 159: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0102 - acc: 0.9971 - val_loss: 0.0144 - val_acc: 0.9947\n",
      "Epoch 160/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0093 - acc: 0.9978\n",
      "Epoch 160: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0158 - val_acc: 0.9943\n",
      "Epoch 161/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0098 - acc: 0.9973\n",
      "Epoch 161: val_loss did not improve from 0.01380\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9975 - val_loss: 0.0164 - val_acc: 0.9953\n",
      "Epoch 162/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9973\n",
      "Epoch 162: val_loss improved from 0.01380 to 0.01334, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.9973 - val_loss: 0.0133 - val_acc: 0.9943\n",
      "Epoch 163/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0089 - acc: 0.9980\n",
      "Epoch 163: val_loss did not improve from 0.01334\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0200 - val_acc: 0.9933\n",
      "Epoch 164/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 164: val_loss did not improve from 0.01334\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.0185 - val_acc: 0.9940\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0094 - acc: 0.9974\n",
      "Epoch 165: val_loss did not improve from 0.01334\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0161 - val_acc: 0.9943\n",
      "Epoch 166/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0092 - acc: 0.9972\n",
      "Epoch 166: val_loss did not improve from 0.01334\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0231 - val_acc: 0.9883\n",
      "Epoch 167/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9971\n",
      "Epoch 167: val_loss did not improve from 0.01334\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0138 - val_acc: 0.9943\n",
      "Epoch 168/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0088 - acc: 0.9977\n",
      "Epoch 168: val_loss improved from 0.01334 to 0.01248, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0089 - acc: 0.9976 - val_loss: 0.0125 - val_acc: 0.9950\n",
      "Epoch 169/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0090 - acc: 0.9968\n",
      "Epoch 169: val_loss did not improve from 0.01248\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0161 - val_acc: 0.9953\n",
      "Epoch 170/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0087 - acc: 0.9974\n",
      "Epoch 170: val_loss did not improve from 0.01248\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.0131 - val_acc: 0.9950\n",
      "Epoch 171/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0092 - acc: 0.9976\n",
      "Epoch 171: val_loss did not improve from 0.01248\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0091 - acc: 0.9976 - val_loss: 0.0208 - val_acc: 0.9943\n",
      "Epoch 172/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0078 - acc: 0.9985\n",
      "Epoch 172: val_loss did not improve from 0.01248\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0368 - val_acc: 0.9890\n",
      "Epoch 173/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0091 - acc: 0.9971\n",
      "Epoch 173: val_loss improved from 0.01248 to 0.01216, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0122 - val_acc: 0.9953\n",
      "Epoch 174/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9984\n",
      "Epoch 174: val_loss did not improve from 0.01216\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0086 - acc: 0.9984 - val_loss: 0.0151 - val_acc: 0.9950\n",
      "Epoch 175/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9978\n",
      "Epoch 175: val_loss did not improve from 0.01216\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0154 - val_acc: 0.9953\n",
      "Epoch 176/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9975\n",
      "Epoch 176: val_loss improved from 0.01216 to 0.01192, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0119 - val_acc: 0.9953\n",
      "Epoch 177/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0080 - acc: 0.9982\n",
      "Epoch 177: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0133 - val_acc: 0.9947\n",
      "Epoch 178/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0085 - acc: 0.9980\n",
      "Epoch 178: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0085 - acc: 0.9978 - val_loss: 0.0125 - val_acc: 0.9947\n",
      "Epoch 179/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0089 - acc: 0.9974\n",
      "Epoch 179: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0085 - acc: 0.9977 - val_loss: 0.0172 - val_acc: 0.9943\n",
      "Epoch 180/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0083 - acc: 0.9976\n",
      "Epoch 180: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0123 - val_acc: 0.9947\n",
      "Epoch 181/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0076 - acc: 0.9981\n",
      "Epoch 181: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0076 - acc: 0.9981 - val_loss: 0.0137 - val_acc: 0.9950\n",
      "Epoch 182/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0077 - acc: 0.9984\n",
      "Epoch 182: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0077 - acc: 0.9984 - val_loss: 0.0126 - val_acc: 0.9947\n",
      "Epoch 183/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9980\n",
      "Epoch 183: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0078 - acc: 0.9979 - val_loss: 0.0120 - val_acc: 0.9953\n",
      "Epoch 184/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0138 - acc: 0.9979\n",
      "Epoch 184: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.9978 - val_loss: 0.0174 - val_acc: 0.9940\n",
      "Epoch 185/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0074 - acc: 0.9986\n",
      "Epoch 185: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 0.9984 - val_loss: 0.0177 - val_acc: 0.9933\n",
      "Epoch 186/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0070 - acc: 0.9984\n",
      "Epoch 186: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0071 - acc: 0.9984 - val_loss: 0.0164 - val_acc: 0.9950\n",
      "Epoch 187/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9985\n",
      "Epoch 187: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0070 - acc: 0.9986 - val_loss: 0.0134 - val_acc: 0.9947\n",
      "Epoch 188/200\n",
      "332/376 [=========================>....] - ETA: 0s - loss: 0.0069 - acc: 0.9987\n",
      "Epoch 188: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0138 - val_acc: 0.9950\n",
      "Epoch 189/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0072 - acc: 0.9981\n",
      "Epoch 189: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0126 - val_acc: 0.9950\n",
      "Epoch 190/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0069 - acc: 0.9987\n",
      "Epoch 190: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0197 - val_acc: 0.9930\n",
      "Epoch 191/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0069 - acc: 0.9983\n",
      "Epoch 191: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0133 - val_acc: 0.9950\n",
      "Epoch 192/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0065 - acc: 0.9989\n",
      "Epoch 192: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0068 - acc: 0.9986 - val_loss: 0.0137 - val_acc: 0.9943\n",
      "Epoch 193/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0067 - acc: 0.9987\n",
      "Epoch 193: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0173 - val_acc: 0.9947\n",
      "Epoch 194/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0083 - acc: 0.9976\n",
      "Epoch 194: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0134 - val_acc: 0.9940\n",
      "Epoch 195/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9981\n",
      "Epoch 195: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0130 - val_acc: 0.9943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0073 - acc: 0.9983\n",
      "Epoch 196: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0139 - val_acc: 0.9953\n",
      "Epoch 197/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0064 - acc: 0.9984\n",
      "Epoch 197: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0145 - val_acc: 0.9953\n",
      "Epoch 198/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0064 - acc: 0.9989\n",
      "Epoch 198: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.9989 - val_loss: 0.0181 - val_acc: 0.9957\n",
      "Epoch 199/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9985\n",
      "Epoch 199: val_loss did not improve from 0.01192\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 0.0170 - val_acc: 0.9953\n",
      "Epoch 200/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0065 - acc: 0.9989\n",
      "Epoch 200: val_loss improved from 0.01192 to 0.01172, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0117 - val_acc: 0.9950\n",
      "94/94 [==============================] - 0s 639us/step\n",
      "Epoch 1/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.3218 - acc: 0.8887\n",
      "Epoch 1: val_loss improved from inf to 0.19029, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.3206 - acc: 0.8893 - val_loss: 0.1903 - val_acc: 0.9304\n",
      "Epoch 2/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.1693 - acc: 0.9389\n",
      "Epoch 2: val_loss improved from 0.19029 to 0.13896, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1681 - acc: 0.9395 - val_loss: 0.1390 - val_acc: 0.9477\n",
      "Epoch 3/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9519\n",
      "Epoch 3: val_loss improved from 0.13896 to 0.13173, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1342 - acc: 0.9517 - val_loss: 0.1317 - val_acc: 0.9510\n",
      "Epoch 4/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.1206 - acc: 0.9567\n",
      "Epoch 4: val_loss improved from 0.13173 to 0.10838, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.1206 - acc: 0.9567 - val_loss: 0.1084 - val_acc: 0.9610\n",
      "Epoch 5/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.1074 - acc: 0.9609\n",
      "Epoch 5: val_loss improved from 0.10838 to 0.10145, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1090 - acc: 0.9601 - val_loss: 0.1015 - val_acc: 0.9657\n",
      "Epoch 6/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.1033 - acc: 0.9636\n",
      "Epoch 6: val_loss improved from 0.10145 to 0.09602, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.1020 - acc: 0.9639 - val_loss: 0.0960 - val_acc: 0.9637\n",
      "Epoch 7/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0966 - acc: 0.9630\n",
      "Epoch 7: val_loss improved from 0.09602 to 0.08999, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0969 - acc: 0.9636 - val_loss: 0.0900 - val_acc: 0.9670\n",
      "Epoch 8/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0913 - acc: 0.9650\n",
      "Epoch 8: val_loss improved from 0.08999 to 0.08693, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0909 - acc: 0.9653 - val_loss: 0.0869 - val_acc: 0.9694\n",
      "Epoch 9/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0886 - acc: 0.9661\n",
      "Epoch 9: val_loss did not improve from 0.08693\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0876 - acc: 0.9666 - val_loss: 0.0872 - val_acc: 0.9677\n",
      "Epoch 10/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0847 - acc: 0.9678\n",
      "Epoch 10: val_loss improved from 0.08693 to 0.07942, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0835 - acc: 0.9680 - val_loss: 0.0794 - val_acc: 0.9724\n",
      "Epoch 11/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9692\n",
      "Epoch 11: val_loss improved from 0.07942 to 0.07554, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0805 - acc: 0.9690 - val_loss: 0.0755 - val_acc: 0.9750\n",
      "Epoch 12/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0764 - acc: 0.9707\n",
      "Epoch 12: val_loss improved from 0.07554 to 0.07394, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0765 - acc: 0.9708 - val_loss: 0.0739 - val_acc: 0.9744\n",
      "Epoch 13/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0741 - acc: 0.9723\n",
      "Epoch 13: val_loss improved from 0.07394 to 0.07101, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0741 - acc: 0.9720 - val_loss: 0.0710 - val_acc: 0.9764\n",
      "Epoch 14/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0715 - acc: 0.9718\n",
      "Epoch 14: val_loss did not improve from 0.07101\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0712 - acc: 0.9723 - val_loss: 0.0798 - val_acc: 0.9697\n",
      "Epoch 15/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0697 - acc: 0.9735\n",
      "Epoch 15: val_loss improved from 0.07101 to 0.06879, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0697 - acc: 0.9734 - val_loss: 0.0688 - val_acc: 0.9767\n",
      "Epoch 16/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0650 - acc: 0.9748\n",
      "Epoch 16: val_loss did not improve from 0.06879\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0672 - acc: 0.9739 - val_loss: 0.0729 - val_acc: 0.9734\n",
      "Epoch 17/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0632 - acc: 0.9763\n",
      "Epoch 17: val_loss improved from 0.06879 to 0.06383, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0641 - acc: 0.9756 - val_loss: 0.0638 - val_acc: 0.9784\n",
      "Epoch 18/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0622 - acc: 0.9759\n",
      "Epoch 18: val_loss improved from 0.06383 to 0.06221, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0623 - acc: 0.9759 - val_loss: 0.0622 - val_acc: 0.9787\n",
      "Epoch 19/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9769\n",
      "Epoch 19: val_loss improved from 0.06221 to 0.05937, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0610 - acc: 0.9769 - val_loss: 0.0594 - val_acc: 0.9784\n",
      "Epoch 20/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0597 - acc: 0.9766\n",
      "Epoch 20: val_loss did not improve from 0.05937\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0601 - acc: 0.9764 - val_loss: 0.0603 - val_acc: 0.9790\n",
      "Epoch 21/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9770\n",
      "Epoch 21: val_loss did not improve from 0.05937\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0588 - acc: 0.9769 - val_loss: 0.0644 - val_acc: 0.9760\n",
      "Epoch 22/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9784\n",
      "Epoch 22: val_loss improved from 0.05937 to 0.05926, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0567 - acc: 0.9785 - val_loss: 0.0593 - val_acc: 0.9794\n",
      "Epoch 23/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0546 - acc: 0.9797\n",
      "Epoch 23: val_loss did not improve from 0.05926\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0552 - acc: 0.9795 - val_loss: 0.0691 - val_acc: 0.9740\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0547 - acc: 0.9782\n",
      "Epoch 24: val_loss improved from 0.05926 to 0.05535, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0538 - acc: 0.9786 - val_loss: 0.0553 - val_acc: 0.9800\n",
      "Epoch 25/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0525 - acc: 0.9798\n",
      "Epoch 25: val_loss did not improve from 0.05535\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0527 - acc: 0.9798 - val_loss: 0.0569 - val_acc: 0.9797\n",
      "Epoch 26/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0533 - acc: 0.9794\n",
      "Epoch 26: val_loss improved from 0.05535 to 0.05408, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0525 - acc: 0.9799 - val_loss: 0.0541 - val_acc: 0.9807\n",
      "Epoch 27/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0506 - acc: 0.9805\n",
      "Epoch 27: val_loss did not improve from 0.05408\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0496 - acc: 0.9809 - val_loss: 0.0549 - val_acc: 0.9807\n",
      "Epoch 28/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0486 - acc: 0.9814\n",
      "Epoch 28: val_loss did not improve from 0.05408\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0496 - acc: 0.9811 - val_loss: 0.0542 - val_acc: 0.9817\n",
      "Epoch 29/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0474 - acc: 0.9811\n",
      "Epoch 29: val_loss improved from 0.05408 to 0.05074, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0478 - acc: 0.9808 - val_loss: 0.0507 - val_acc: 0.9807\n",
      "Epoch 30/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9814\n",
      "Epoch 30: val_loss did not improve from 0.05074\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0471 - acc: 0.9818 - val_loss: 0.0567 - val_acc: 0.9800\n",
      "Epoch 31/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9810\n",
      "Epoch 31: val_loss did not improve from 0.05074\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0470 - acc: 0.9810 - val_loss: 0.0513 - val_acc: 0.9807\n",
      "Epoch 32/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0447 - acc: 0.9827\n",
      "Epoch 32: val_loss did not improve from 0.05074\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0451 - acc: 0.9827 - val_loss: 0.0509 - val_acc: 0.9814\n",
      "Epoch 33/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9826\n",
      "Epoch 33: val_loss improved from 0.05074 to 0.05012, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0442 - acc: 0.9827 - val_loss: 0.0501 - val_acc: 0.9814\n",
      "Epoch 34/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0412 - acc: 0.9843\n",
      "Epoch 34: val_loss improved from 0.05012 to 0.04938, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0426 - acc: 0.9834 - val_loss: 0.0494 - val_acc: 0.9837\n",
      "Epoch 35/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0437 - acc: 0.9826\n",
      "Epoch 35: val_loss did not improve from 0.04938\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0421 - acc: 0.9831 - val_loss: 0.0574 - val_acc: 0.9797\n",
      "Epoch 36/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0418 - acc: 0.9830\n",
      "Epoch 36: val_loss improved from 0.04938 to 0.04724, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0418 - acc: 0.9833 - val_loss: 0.0472 - val_acc: 0.9833\n",
      "Epoch 37/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0403 - acc: 0.9835\n",
      "Epoch 37: val_loss did not improve from 0.04724\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0406 - acc: 0.9836 - val_loss: 0.0494 - val_acc: 0.9840\n",
      "Epoch 38/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0418 - acc: 0.9840\n",
      "Epoch 38: val_loss improved from 0.04724 to 0.04596, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0405 - acc: 0.9843 - val_loss: 0.0460 - val_acc: 0.9830\n",
      "Epoch 39/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0409 - acc: 0.9835\n",
      "Epoch 39: val_loss improved from 0.04596 to 0.04510, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0406 - acc: 0.9838 - val_loss: 0.0451 - val_acc: 0.9843\n",
      "Epoch 40/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0387 - acc: 0.9848\n",
      "Epoch 40: val_loss did not improve from 0.04510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0387 - acc: 0.9848 - val_loss: 0.0468 - val_acc: 0.9824\n",
      "Epoch 41/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0375 - acc: 0.9854\n",
      "Epoch 41: val_loss did not improve from 0.04510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0383 - acc: 0.9852 - val_loss: 0.0493 - val_acc: 0.9804\n",
      "Epoch 42/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0362 - acc: 0.9864\n",
      "Epoch 42: val_loss did not improve from 0.04510\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0370 - acc: 0.9863 - val_loss: 0.0456 - val_acc: 0.9840\n",
      "Epoch 43/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0364 - acc: 0.9865\n",
      "Epoch 43: val_loss did not improve from 0.04510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0366 - acc: 0.9859 - val_loss: 0.0469 - val_acc: 0.9847\n",
      "Epoch 44/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0372 - acc: 0.9859\n",
      "Epoch 44: val_loss did not improve from 0.04510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0364 - acc: 0.9863 - val_loss: 0.0572 - val_acc: 0.9847\n",
      "Epoch 45/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0360 - acc: 0.9857\n",
      "Epoch 45: val_loss did not improve from 0.04510\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0363 - acc: 0.9858 - val_loss: 0.0480 - val_acc: 0.9810\n",
      "Epoch 46/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0353 - acc: 0.9862\n",
      "Epoch 46: val_loss improved from 0.04510 to 0.04397, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0349 - acc: 0.9863 - val_loss: 0.0440 - val_acc: 0.9837\n",
      "Epoch 47/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0340 - acc: 0.9868\n",
      "Epoch 47: val_loss improved from 0.04397 to 0.04246, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0342 - acc: 0.9868 - val_loss: 0.0425 - val_acc: 0.9847\n",
      "Epoch 48/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0336 - acc: 0.9866\n",
      "Epoch 48: val_loss did not improve from 0.04246\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0334 - acc: 0.9868 - val_loss: 0.0434 - val_acc: 0.9843\n",
      "Epoch 49/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0333 - acc: 0.9872\n",
      "Epoch 49: val_loss did not improve from 0.04246\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0332 - acc: 0.9871 - val_loss: 0.0454 - val_acc: 0.9837\n",
      "Epoch 50/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0324 - acc: 0.9876\n",
      "Epoch 50: val_loss did not improve from 0.04246\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0324 - acc: 0.9875 - val_loss: 0.0427 - val_acc: 0.9830\n",
      "Epoch 51/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0322 - acc: 0.9874\n",
      "Epoch 51: val_loss did not improve from 0.04246\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0327 - acc: 0.9868 - val_loss: 0.0475 - val_acc: 0.9827\n",
      "Epoch 52/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0313 - acc: 0.9877\n",
      "Epoch 52: val_loss did not improve from 0.04246\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0313 - acc: 0.9877 - val_loss: 0.0427 - val_acc: 0.9847\n",
      "Epoch 53/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0313 - acc: 0.9877\n",
      "Epoch 53: val_loss did not improve from 0.04246\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0315 - acc: 0.9875 - val_loss: 0.0435 - val_acc: 0.9830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0313 - acc: 0.9882\n",
      "Epoch 54: val_loss improved from 0.04246 to 0.04044, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.9883 - val_loss: 0.0404 - val_acc: 0.9857\n",
      "Epoch 55/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0298 - acc: 0.9888\n",
      "Epoch 55: val_loss did not improve from 0.04044\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0301 - acc: 0.9883 - val_loss: 0.0421 - val_acc: 0.9853\n",
      "Epoch 56/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9878\n",
      "Epoch 56: val_loss improved from 0.04044 to 0.04039, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0304 - acc: 0.9878 - val_loss: 0.0404 - val_acc: 0.9863\n",
      "Epoch 57/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0294 - acc: 0.9884\n",
      "Epoch 57: val_loss did not improve from 0.04039\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0298 - acc: 0.9884 - val_loss: 0.0439 - val_acc: 0.9824\n",
      "Epoch 58/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0302 - acc: 0.9878\n",
      "Epoch 58: val_loss improved from 0.04039 to 0.03929, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0295 - acc: 0.9883 - val_loss: 0.0393 - val_acc: 0.9857\n",
      "Epoch 59/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0277 - acc: 0.9898\n",
      "Epoch 59: val_loss did not improve from 0.03929\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0286 - acc: 0.9893 - val_loss: 0.0407 - val_acc: 0.9860\n",
      "Epoch 60/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0288 - acc: 0.9888\n",
      "Epoch 60: val_loss did not improve from 0.03929\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0291 - acc: 0.9887 - val_loss: 0.0405 - val_acc: 0.9853\n",
      "Epoch 61/200\n",
      "348/376 [==========================>...] - ETA: 0s - loss: 0.0285 - acc: 0.9890\n",
      "Epoch 61: val_loss did not improve from 0.03929\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0289 - acc: 0.9888 - val_loss: 0.0395 - val_acc: 0.9860\n",
      "Epoch 62/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0268 - acc: 0.9899\n",
      "Epoch 62: val_loss improved from 0.03929 to 0.03764, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0273 - acc: 0.9898 - val_loss: 0.0376 - val_acc: 0.9867\n",
      "Epoch 63/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0273 - acc: 0.9898\n",
      "Epoch 63: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0274 - acc: 0.9895 - val_loss: 0.0406 - val_acc: 0.9870\n",
      "Epoch 64/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0271 - acc: 0.9890\n",
      "Epoch 64: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0273 - acc: 0.9891 - val_loss: 0.0415 - val_acc: 0.9863\n",
      "Epoch 65/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0262 - acc: 0.9895\n",
      "Epoch 65: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0264 - acc: 0.9898 - val_loss: 0.0398 - val_acc: 0.9860\n",
      "Epoch 66/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0266 - acc: 0.9893\n",
      "Epoch 66: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0264 - acc: 0.9895 - val_loss: 0.0437 - val_acc: 0.9827\n",
      "Epoch 67/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9896\n",
      "Epoch 67: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0259 - acc: 0.9898 - val_loss: 0.0409 - val_acc: 0.9870\n",
      "Epoch 68/200\n",
      "336/376 [=========================>....] - ETA: 0s - loss: 0.0250 - acc: 0.9905\n",
      "Epoch 68: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0256 - acc: 0.9902 - val_loss: 0.0452 - val_acc: 0.9827\n",
      "Epoch 69/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9897\n",
      "Epoch 69: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0281 - acc: 0.9898 - val_loss: 0.0406 - val_acc: 0.9840\n",
      "Epoch 70/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9906\n",
      "Epoch 70: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0253 - acc: 0.9904 - val_loss: 0.0394 - val_acc: 0.9877\n",
      "Epoch 71/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0251 - acc: 0.9896\n",
      "Epoch 71: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0251 - acc: 0.9895 - val_loss: 0.0419 - val_acc: 0.9847\n",
      "Epoch 72/200\n",
      "370/376 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9902\n",
      "Epoch 72: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0247 - acc: 0.9903 - val_loss: 0.0392 - val_acc: 0.9873\n",
      "Epoch 73/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9912\n",
      "Epoch 73: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0242 - acc: 0.9912 - val_loss: 0.0418 - val_acc: 0.9847\n",
      "Epoch 74/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9905\n",
      "Epoch 74: val_loss did not improve from 0.03764\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0239 - acc: 0.9906 - val_loss: 0.0394 - val_acc: 0.9860\n",
      "Epoch 75/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0234 - acc: 0.9916\n",
      "Epoch 75: val_loss improved from 0.03764 to 0.03680, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0237 - acc: 0.9914 - val_loss: 0.0368 - val_acc: 0.9870\n",
      "Epoch 76/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0239 - acc: 0.9904\n",
      "Epoch 76: val_loss improved from 0.03680 to 0.03555, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0236 - acc: 0.9905 - val_loss: 0.0356 - val_acc: 0.9883\n",
      "Epoch 77/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9912\n",
      "Epoch 77: val_loss did not improve from 0.03555\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0239 - acc: 0.9912 - val_loss: 0.0367 - val_acc: 0.9870\n",
      "Epoch 78/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0222 - acc: 0.9920\n",
      "Epoch 78: val_loss did not improve from 0.03555\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0234 - acc: 0.9916 - val_loss: 0.0391 - val_acc: 0.9873\n",
      "Epoch 79/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9916\n",
      "Epoch 79: val_loss improved from 0.03555 to 0.03460, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0226 - acc: 0.9916 - val_loss: 0.0346 - val_acc: 0.9863\n",
      "Epoch 80/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0235 - acc: 0.9915\n",
      "Epoch 80: val_loss did not improve from 0.03460\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0234 - acc: 0.9916 - val_loss: 0.0370 - val_acc: 0.9880\n",
      "Epoch 81/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0220 - acc: 0.9919\n",
      "Epoch 81: val_loss did not improve from 0.03460\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0223 - acc: 0.9917 - val_loss: 0.0396 - val_acc: 0.9873\n",
      "Epoch 82/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0216 - acc: 0.9923\n",
      "Epoch 82: val_loss did not improve from 0.03460\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0215 - acc: 0.9923 - val_loss: 0.0436 - val_acc: 0.9887\n",
      "Epoch 83/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0225 - acc: 0.9916\n",
      "Epoch 83: val_loss did not improve from 0.03460\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0224 - acc: 0.9914 - val_loss: 0.0406 - val_acc: 0.9880\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/376 [=========================>....] - ETA: 0s - loss: 0.0228 - acc: 0.9914\n",
      "Epoch 84: val_loss did not improve from 0.03460\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0227 - acc: 0.9917 - val_loss: 0.0356 - val_acc: 0.9870\n",
      "Epoch 85/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0207 - acc: 0.9924\n",
      "Epoch 85: val_loss did not improve from 0.03460\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0209 - acc: 0.9923 - val_loss: 0.0374 - val_acc: 0.9887\n",
      "Epoch 86/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0216 - acc: 0.9917\n",
      "Epoch 86: val_loss did not improve from 0.03460\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0220 - acc: 0.9914 - val_loss: 0.0351 - val_acc: 0.9890\n",
      "Epoch 87/200\n",
      "337/376 [=========================>....] - ETA: 0s - loss: 0.0219 - acc: 0.9926\n",
      "Epoch 87: val_loss improved from 0.03460 to 0.03393, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0215 - acc: 0.9928 - val_loss: 0.0339 - val_acc: 0.9893\n",
      "Epoch 88/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0215 - acc: 0.9922\n",
      "Epoch 88: val_loss improved from 0.03393 to 0.03324, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0216 - acc: 0.9921 - val_loss: 0.0332 - val_acc: 0.9887\n",
      "Epoch 89/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0207 - acc: 0.9927\n",
      "Epoch 89: val_loss did not improve from 0.03324\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0207 - acc: 0.9928 - val_loss: 0.0360 - val_acc: 0.9883\n",
      "Epoch 90/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0209 - acc: 0.9919\n",
      "Epoch 90: val_loss did not improve from 0.03324\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0215 - acc: 0.9918 - val_loss: 0.0342 - val_acc: 0.9893\n",
      "Epoch 91/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9927\n",
      "Epoch 91: val_loss did not improve from 0.03324\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0204 - acc: 0.9928 - val_loss: 0.0394 - val_acc: 0.9837\n",
      "Epoch 92/200\n",
      "368/376 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9921\n",
      "Epoch 92: val_loss did not improve from 0.03324\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0205 - acc: 0.9920 - val_loss: 0.0353 - val_acc: 0.9880\n",
      "Epoch 93/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0203 - acc: 0.9927\n",
      "Epoch 93: val_loss did not improve from 0.03324\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0199 - acc: 0.9928 - val_loss: 0.0349 - val_acc: 0.9863\n",
      "Epoch 94/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0197 - acc: 0.9927\n",
      "Epoch 94: val_loss improved from 0.03324 to 0.03164, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0195 - acc: 0.9928 - val_loss: 0.0316 - val_acc: 0.9900\n",
      "Epoch 95/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0198 - acc: 0.9927\n",
      "Epoch 95: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0195 - acc: 0.9928 - val_loss: 0.0390 - val_acc: 0.9840\n",
      "Epoch 96/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0192 - acc: 0.9931\n",
      "Epoch 96: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0197 - acc: 0.9927 - val_loss: 0.0339 - val_acc: 0.9887\n",
      "Epoch 97/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0192 - acc: 0.9925\n",
      "Epoch 97: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0189 - acc: 0.9927 - val_loss: 0.0342 - val_acc: 0.9893\n",
      "Epoch 98/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0192 - acc: 0.9929\n",
      "Epoch 98: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0190 - acc: 0.9928 - val_loss: 0.0344 - val_acc: 0.9877\n",
      "Epoch 99/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0183 - acc: 0.9932\n",
      "Epoch 99: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0182 - acc: 0.9933 - val_loss: 0.0332 - val_acc: 0.9880\n",
      "Epoch 100/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0179 - acc: 0.9938\n",
      "Epoch 100: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0186 - acc: 0.9930 - val_loss: 0.0317 - val_acc: 0.9903\n",
      "Epoch 101/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0187 - acc: 0.9936\n",
      "Epoch 101: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0182 - acc: 0.9937 - val_loss: 0.0337 - val_acc: 0.9890\n",
      "Epoch 102/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9935\n",
      "Epoch 102: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0181 - acc: 0.9936 - val_loss: 0.0358 - val_acc: 0.9870\n",
      "Epoch 103/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0170 - acc: 0.9945\n",
      "Epoch 103: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0179 - acc: 0.9938 - val_loss: 0.0360 - val_acc: 0.9900\n",
      "Epoch 104/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0180 - acc: 0.9938\n",
      "Epoch 104: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0176 - acc: 0.9940 - val_loss: 0.0368 - val_acc: 0.9863\n",
      "Epoch 105/200\n",
      "331/376 [=========================>....] - ETA: 0s - loss: 0.0172 - acc: 0.9939\n",
      "Epoch 105: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0176 - acc: 0.9937 - val_loss: 0.0361 - val_acc: 0.9903\n",
      "Epoch 106/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0177 - acc: 0.9941\n",
      "Epoch 106: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0175 - acc: 0.9941 - val_loss: 0.0347 - val_acc: 0.9907\n",
      "Epoch 107/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0175 - acc: 0.9943\n",
      "Epoch 107: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0174 - acc: 0.9942 - val_loss: 0.0335 - val_acc: 0.9887\n",
      "Epoch 108/200\n",
      "331/376 [=========================>....] - ETA: 0s - loss: 0.0165 - acc: 0.9949\n",
      "Epoch 108: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0384 - val_acc: 0.9910\n",
      "Epoch 109/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0173 - acc: 0.9945\n",
      "Epoch 109: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0171 - acc: 0.9943 - val_loss: 0.0361 - val_acc: 0.9890\n",
      "Epoch 110/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0172 - acc: 0.9947\n",
      "Epoch 110: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.0345 - val_acc: 0.9870\n",
      "Epoch 111/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0160 - acc: 0.9945\n",
      "Epoch 111: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0165 - acc: 0.9945 - val_loss: 0.0388 - val_acc: 0.9853\n",
      "Epoch 112/200\n",
      "352/376 [===========================>..] - ETA: 0s - loss: 0.0172 - acc: 0.9942\n",
      "Epoch 112: val_loss did not improve from 0.03164\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0170 - acc: 0.9941 - val_loss: 0.0373 - val_acc: 0.9883\n",
      "Epoch 113/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0174 - acc: 0.9943\n",
      "Epoch 113: val_loss improved from 0.03164 to 0.03110, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0174 - acc: 0.9943 - val_loss: 0.0311 - val_acc: 0.9897\n",
      "Epoch 114/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0172 - acc: 0.9938\n",
      "Epoch 114: val_loss did not improve from 0.03110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0166 - acc: 0.9941 - val_loss: 0.0335 - val_acc: 0.9887\n",
      "Epoch 115/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0162 - acc: 0.9949\n",
      "Epoch 115: val_loss improved from 0.03110 to 0.03064, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0306 - val_acc: 0.9897\n",
      "Epoch 116/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0150 - acc: 0.9945\n",
      "Epoch 116: val_loss improved from 0.03064 to 0.03032, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0158 - acc: 0.9940 - val_loss: 0.0303 - val_acc: 0.9913\n",
      "Epoch 117/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0158 - acc: 0.9946\n",
      "Epoch 117: val_loss did not improve from 0.03032\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0156 - acc: 0.9947 - val_loss: 0.0341 - val_acc: 0.9880\n",
      "Epoch 118/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0172 - acc: 0.9949\n",
      "Epoch 118: val_loss did not improve from 0.03032\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0172 - acc: 0.9949 - val_loss: 0.0320 - val_acc: 0.9913\n",
      "Epoch 119/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0159 - acc: 0.9943\n",
      "Epoch 119: val_loss did not improve from 0.03032\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0161 - acc: 0.9943 - val_loss: 0.0306 - val_acc: 0.9907\n",
      "Epoch 120/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0155 - acc: 0.9954\n",
      "Epoch 120: val_loss did not improve from 0.03032\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0153 - acc: 0.9955 - val_loss: 0.0325 - val_acc: 0.9907\n",
      "Epoch 121/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0145 - acc: 0.9956\n",
      "Epoch 121: val_loss did not improve from 0.03032\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0151 - acc: 0.9954 - val_loss: 0.0310 - val_acc: 0.9910\n",
      "Epoch 122/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0162 - acc: 0.9952\n",
      "Epoch 122: val_loss did not improve from 0.03032\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0159 - acc: 0.9953 - val_loss: 0.0322 - val_acc: 0.9893\n",
      "Epoch 123/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0166 - acc: 0.9940\n",
      "Epoch 123: val_loss did not improve from 0.03032\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0163 - acc: 0.9942 - val_loss: 0.0328 - val_acc: 0.9903\n",
      "Epoch 124/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0152 - acc: 0.9951\n",
      "Epoch 124: val_loss did not improve from 0.03032\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0149 - acc: 0.9952 - val_loss: 0.0317 - val_acc: 0.9900\n",
      "Epoch 125/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0152 - acc: 0.9949\n",
      "Epoch 125: val_loss did not improve from 0.03032\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0147 - acc: 0.9950 - val_loss: 0.0366 - val_acc: 0.9870\n",
      "Epoch 126/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0138 - acc: 0.9960\n",
      "Epoch 126: val_loss improved from 0.03032 to 0.02867, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0287 - val_acc: 0.9907\n",
      "Epoch 127/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0147 - acc: 0.9954\n",
      "Epoch 127: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0334 - val_acc: 0.9893\n",
      "Epoch 128/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0147 - acc: 0.9947\n",
      "Epoch 128: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0145 - acc: 0.9949 - val_loss: 0.0309 - val_acc: 0.9897\n",
      "Epoch 129/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9951\n",
      "Epoch 129: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0144 - acc: 0.9951 - val_loss: 0.0322 - val_acc: 0.9913\n",
      "Epoch 130/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9958\n",
      "Epoch 130: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 0.9958 - val_loss: 0.0336 - val_acc: 0.9910\n",
      "Epoch 131/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9954\n",
      "Epoch 131: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0371 - val_acc: 0.9877\n",
      "Epoch 132/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9954\n",
      "Epoch 132: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0334 - val_acc: 0.9917\n",
      "Epoch 133/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0134 - acc: 0.9957\n",
      "Epoch 133: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0342 - val_acc: 0.9893\n",
      "Epoch 134/200\n",
      "369/376 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9955\n",
      "Epoch 134: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0138 - acc: 0.9956 - val_loss: 0.0343 - val_acc: 0.9897\n",
      "Epoch 135/200\n",
      "367/376 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9958\n",
      "Epoch 135: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0134 - acc: 0.9958 - val_loss: 0.0364 - val_acc: 0.9913\n",
      "Epoch 136/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0134 - acc: 0.9955\n",
      "Epoch 136: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0133 - acc: 0.9956 - val_loss: 0.0314 - val_acc: 0.9913\n",
      "Epoch 137/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0127 - acc: 0.9966\n",
      "Epoch 137: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0131 - acc: 0.9964 - val_loss: 0.0335 - val_acc: 0.9910\n",
      "Epoch 138/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0140 - acc: 0.9949\n",
      "Epoch 138: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0140 - acc: 0.9949 - val_loss: 0.0322 - val_acc: 0.9910\n",
      "Epoch 139/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9957\n",
      "Epoch 139: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.0353 - val_acc: 0.9880\n",
      "Epoch 140/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9959\n",
      "Epoch 140: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0127 - acc: 0.9959 - val_loss: 0.0307 - val_acc: 0.9910\n",
      "Epoch 141/200\n",
      "332/376 [=========================>....] - ETA: 0s - loss: 0.0124 - acc: 0.9960\n",
      "Epoch 141: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.9963 - val_loss: 0.0325 - val_acc: 0.9907\n",
      "Epoch 142/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9964\n",
      "Epoch 142: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0128 - acc: 0.9963 - val_loss: 0.0382 - val_acc: 0.9917\n",
      "Epoch 143/200\n",
      "349/376 [==========================>...] - ETA: 0s - loss: 0.0134 - acc: 0.9953\n",
      "Epoch 143: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0134 - acc: 0.9953 - val_loss: 0.0370 - val_acc: 0.9910\n",
      "Epoch 144/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0125 - acc: 0.9962\n",
      "Epoch 144: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0351 - val_acc: 0.9913\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9954\n",
      "Epoch 145: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0345 - val_acc: 0.9887\n",
      "Epoch 146/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0119 - acc: 0.9960\n",
      "Epoch 146: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0122 - acc: 0.9963 - val_loss: 0.0309 - val_acc: 0.9897\n",
      "Epoch 147/200\n",
      "373/376 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 147: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0288 - val_acc: 0.9897\n",
      "Epoch 148/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 148: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0319 - val_acc: 0.9920\n",
      "Epoch 149/200\n",
      "334/376 [=========================>....] - ETA: 0s - loss: 0.0121 - acc: 0.9962\n",
      "Epoch 149: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0341 - val_acc: 0.9900\n",
      "Epoch 150/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9970\n",
      "Epoch 150: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.9970 - val_loss: 0.0296 - val_acc: 0.9913\n",
      "Epoch 151/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0120 - acc: 0.9958\n",
      "Epoch 151: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.9958 - val_loss: 0.0326 - val_acc: 0.9897\n",
      "Epoch 152/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0119 - acc: 0.9964\n",
      "Epoch 152: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.0315 - val_acc: 0.9917\n",
      "Epoch 153/200\n",
      "372/376 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9965\n",
      "Epoch 153: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0117 - acc: 0.9965 - val_loss: 0.0404 - val_acc: 0.9837\n",
      "Epoch 154/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0123 - acc: 0.9962\n",
      "Epoch 154: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0123 - acc: 0.9962 - val_loss: 0.0360 - val_acc: 0.9920\n",
      "Epoch 155/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0115 - acc: 0.9963\n",
      "Epoch 155: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0116 - acc: 0.9962 - val_loss: 0.0306 - val_acc: 0.9903\n",
      "Epoch 156/200\n",
      "345/376 [==========================>...] - ETA: 0s - loss: 0.0119 - acc: 0.9962\n",
      "Epoch 156: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0341 - val_acc: 0.9907\n",
      "Epoch 157/200\n",
      "356/376 [===========================>..] - ETA: 0s - loss: 0.0110 - acc: 0.9965\n",
      "Epoch 157: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.9963 - val_loss: 0.0308 - val_acc: 0.9900\n",
      "Epoch 158/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0110 - acc: 0.9971\n",
      "Epoch 158: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.9970 - val_loss: 0.0325 - val_acc: 0.9917\n",
      "Epoch 159/200\n",
      "343/376 [==========================>...] - ETA: 0s - loss: 0.0107 - acc: 0.9968\n",
      "Epoch 159: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0318 - val_acc: 0.9917\n",
      "Epoch 160/200\n",
      "355/376 [===========================>..] - ETA: 0s - loss: 0.0113 - acc: 0.9967\n",
      "Epoch 160: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.0322 - val_acc: 0.9920\n",
      "Epoch 161/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 161: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.0334 - val_acc: 0.9897\n",
      "Epoch 162/200\n",
      "341/376 [==========================>...] - ETA: 0s - loss: 0.0130 - acc: 0.9960\n",
      "Epoch 162: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.0382 - val_acc: 0.9897\n",
      "Epoch 163/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 163: val_loss did not improve from 0.02867\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.9968 - val_loss: 0.0338 - val_acc: 0.9883\n",
      "Epoch 164/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0103 - acc: 0.9972\n",
      "Epoch 164: val_loss improved from 0.02867 to 0.02819, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0105 - acc: 0.9969 - val_loss: 0.0282 - val_acc: 0.9917\n",
      "Epoch 165/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0108 - acc: 0.9964\n",
      "Epoch 165: val_loss did not improve from 0.02819\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0290 - val_acc: 0.9917\n",
      "Epoch 166/200\n",
      "360/376 [===========================>..] - ETA: 0s - loss: 0.0101 - acc: 0.9977\n",
      "Epoch 166: val_loss improved from 0.02819 to 0.02765, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.9975 - val_loss: 0.0277 - val_acc: 0.9920\n",
      "Epoch 167/200\n",
      "363/376 [===========================>..] - ETA: 0s - loss: 0.0100 - acc: 0.9972\n",
      "Epoch 167: val_loss improved from 0.02765 to 0.02628, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0263 - val_acc: 0.9913\n",
      "Epoch 168/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0102 - acc: 0.9974\n",
      "Epoch 168: val_loss improved from 0.02628 to 0.02484, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 0.9974 - val_loss: 0.0248 - val_acc: 0.9923\n",
      "Epoch 169/200\n",
      "364/376 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9971\n",
      "Epoch 169: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.9971 - val_loss: 0.0259 - val_acc: 0.9930\n",
      "Epoch 170/200\n",
      "366/376 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9974\n",
      "Epoch 170: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 0.9972 - val_loss: 0.0386 - val_acc: 0.9860\n",
      "Epoch 171/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0100 - acc: 0.9970\n",
      "Epoch 171: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.9971 - val_loss: 0.0252 - val_acc: 0.9923\n",
      "Epoch 172/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9971\n",
      "Epoch 172: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.9970 - val_loss: 0.0302 - val_acc: 0.9920\n",
      "Epoch 173/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0100 - acc: 0.9979\n",
      "Epoch 173: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 0.9978 - val_loss: 0.0327 - val_acc: 0.9893\n",
      "Epoch 174/200\n",
      "357/376 [===========================>..] - ETA: 0s - loss: 0.0096 - acc: 0.9971\n",
      "Epoch 174: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0343 - val_acc: 0.9920\n",
      "Epoch 175/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0105 - acc: 0.9968\n",
      "Epoch 175: val_loss did not improve from 0.02484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0105 - acc: 0.9968 - val_loss: 0.0265 - val_acc: 0.9917\n",
      "Epoch 176/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0103 - acc: 0.9965\n",
      "Epoch 176: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0284 - val_acc: 0.9920\n",
      "Epoch 177/200\n",
      "338/376 [=========================>....] - ETA: 0s - loss: 0.0093 - acc: 0.9977\n",
      "Epoch 177: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0094 - acc: 0.9976 - val_loss: 0.0327 - val_acc: 0.9923\n",
      "Epoch 178/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0101 - acc: 0.9970\n",
      "Epoch 178: val_loss did not improve from 0.02484\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0325 - val_acc: 0.9903\n",
      "Epoch 179/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0113 - acc: 0.9967\n",
      "Epoch 179: val_loss improved from 0.02484 to 0.02459, saving model to best_model_simple.hdf5\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0111 - acc: 0.9968 - val_loss: 0.0246 - val_acc: 0.9937\n",
      "Epoch 180/200\n",
      "340/376 [==========================>...] - ETA: 0s - loss: 0.0092 - acc: 0.9976\n",
      "Epoch 180: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.0287 - val_acc: 0.9900\n",
      "Epoch 181/200\n",
      "365/376 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9979\n",
      "Epoch 181: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0090 - acc: 0.9979 - val_loss: 0.0248 - val_acc: 0.9927\n",
      "Epoch 182/200\n",
      "371/376 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9975\n",
      "Epoch 182: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0091 - acc: 0.9975 - val_loss: 0.0302 - val_acc: 0.9937\n",
      "Epoch 183/200\n",
      "354/376 [===========================>..] - ETA: 0s - loss: 0.0088 - acc: 0.9978\n",
      "Epoch 183: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.0286 - val_acc: 0.9933\n",
      "Epoch 184/200\n",
      "351/376 [===========================>..] - ETA: 0s - loss: 0.0088 - acc: 0.9980\n",
      "Epoch 184: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0090 - acc: 0.9978 - val_loss: 0.0320 - val_acc: 0.9933\n",
      "Epoch 185/200\n",
      "333/376 [=========================>....] - ETA: 0s - loss: 0.0092 - acc: 0.9976\n",
      "Epoch 185: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0306 - val_acc: 0.9913\n",
      "Epoch 186/200\n",
      "342/376 [==========================>...] - ETA: 0s - loss: 0.0097 - acc: 0.9973\n",
      "Epoch 186: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.0326 - val_acc: 0.9917\n",
      "Epoch 187/200\n",
      "361/376 [===========================>..] - ETA: 0s - loss: 0.0085 - acc: 0.9978\n",
      "Epoch 187: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0083 - acc: 0.9979 - val_loss: 0.0304 - val_acc: 0.9927\n",
      "Epoch 188/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0090 - acc: 0.9969\n",
      "Epoch 188: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0312 - val_acc: 0.9923\n",
      "Epoch 189/200\n",
      "344/376 [==========================>...] - ETA: 0s - loss: 0.0088 - acc: 0.9975\n",
      "Epoch 189: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0292 - val_acc: 0.9920\n",
      "Epoch 190/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0088 - acc: 0.9978\n",
      "Epoch 190: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0086 - acc: 0.9978 - val_loss: 0.0316 - val_acc: 0.9923\n",
      "Epoch 191/200\n",
      "350/376 [==========================>...] - ETA: 0s - loss: 0.0082 - acc: 0.9985\n",
      "Epoch 191: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.0337 - val_acc: 0.9910\n",
      "Epoch 192/200\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.0088 - acc: 0.9978\n",
      "Epoch 192: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0088 - acc: 0.9978 - val_loss: 0.0362 - val_acc: 0.9930\n",
      "Epoch 193/200\n",
      "347/376 [==========================>...] - ETA: 0s - loss: 0.0078 - acc: 0.9986\n",
      "Epoch 193: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0079 - acc: 0.9985 - val_loss: 0.0347 - val_acc: 0.9937\n",
      "Epoch 194/200\n",
      "353/376 [===========================>..] - ETA: 0s - loss: 0.0084 - acc: 0.9981\n",
      "Epoch 194: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0343 - val_acc: 0.9927\n",
      "Epoch 195/200\n",
      "375/376 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9968\n",
      "Epoch 195: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.9968 - val_loss: 0.0304 - val_acc: 0.9933\n",
      "Epoch 196/200\n",
      "362/376 [===========================>..] - ETA: 0s - loss: 0.0090 - acc: 0.9974\n",
      "Epoch 196: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.0310 - val_acc: 0.9930\n",
      "Epoch 197/200\n",
      "358/376 [===========================>..] - ETA: 0s - loss: 0.0084 - acc: 0.9971\n",
      "Epoch 197: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0324 - val_acc: 0.9903\n",
      "Epoch 198/200\n",
      "359/376 [===========================>..] - ETA: 0s - loss: 0.0079 - acc: 0.9984\n",
      "Epoch 198: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 0s 1ms/step - loss: 0.0078 - acc: 0.9985 - val_loss: 0.0327 - val_acc: 0.9923\n",
      "Epoch 199/200\n",
      "346/376 [==========================>...] - ETA: 0s - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 199: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 2ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.0315 - val_acc: 0.9920\n",
      "Epoch 200/200\n",
      "339/376 [==========================>...] - ETA: 0s - loss: 0.0079 - acc: 0.9984\n",
      "Epoch 200: val_loss did not improve from 0.02459\n",
      "376/376 [==============================] - 1s 1ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0277 - val_acc: 0.9933\n",
      "94/94 [==============================] - 0s 650us/step\n",
      "Accuracy on train data: [0.9990010261535645, 0.9996669888496399, 0.9999167323112488, 0.9983350038528442, 0.9983350038528442] 0.9990509510040283\n",
      "Accuracy on test data: [0.9913420081138611, 0.9943389892578125, 0.9970030188560486, 0.9950050115585327, 0.9936729669570923] 0.9942723989486695\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Kfold implementation, written by Paul Boersma\n",
    "def kfold_index(df, k=5):\n",
    "    N = len(df)\n",
    "    minimum_number_of_points_per_slice = N // k\n",
    "    remaining_number_of_points = N % k\n",
    "    starting_point = 0\n",
    "    out = []\n",
    "    for islice in range(0, k):\n",
    "        end_point = starting_point + minimum_number_of_points_per_slice + ( islice < remaining_number_of_points )\n",
    "        out.append((starting_point, end_point))\n",
    "        starting_point = end_point\n",
    "    return out\n",
    "\n",
    "# Run kfold for given featureset\n",
    "def execute_kfold(version, feature_type, denoise, k=5):\n",
    "    acc_train = []\n",
    "    acc_test = []\n",
    "    cm = np.zeros((2,2))\n",
    "    df = build_features(version, feature_type, denoise)\n",
    "    X, Y = feature_target_split(df)\n",
    "    for start, end in kfold_index(df, k):\n",
    "        X_train = np.concatenate((X[:start], X[end:]))\n",
    "        Y_train = np.concatenate((Y[:start], Y[end:]))\n",
    "        X_test = X[start:end]\n",
    "        Y_test = Y[start:end]\n",
    "        \n",
    "        model = train(X_train, X_test, Y_train, Y_test, version, feature_type, denoise)\n",
    "        acc_train.append(model.evaluate(X_train, Y_train, verbose=0)[1])\n",
    "        acc_test.append(model.evaluate(X_test, Y_test, verbose=0)[1])\n",
    "        cm += confusion_matrix(Y_test, [1 if prediction > .5 else 0 for prediction in model.predict(X_test)[:,0]])\n",
    "        \n",
    "    print('Accuracy on train data:', acc_train, np.mean(acc_train))\n",
    "    print('Accuracy on test data:', acc_test, np.mean(acc_test))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])\n",
    "    disp.plot(cmap=\"Greens\", values_format='')\n",
    "\n",
    "execute_kfold(1, 'fft', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "FORMAT = pyaudio.paFloat32      # audio format (bytes per sample?)\n",
    "CHANNELS = 1                    # single channel for microphone\n",
    "SR = 48000                      # samples per second\n",
    "CHUNK = int((SR / 1000) * STEP) # chunk size\n",
    "WAVE_OUTPUT_FILENAME = \"file.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whistle likelihood: 100.0%\n",
      "finished recording\n"
     ]
    }
   ],
   "source": [
    "def live_detect(feature_type, version, denoise, record_seconds=15, write=False):\n",
    "    # load model\n",
    "    try:\n",
    "        model = load_model(\"model_v\" + str(version) + \"_\" + feature_type + \"_\" + str(denoise) + \".h5\")\n",
    "    except:\n",
    "        _, _, model = train_model(version, feature_type, denoise)\n",
    "    \n",
    "    # pyaudio class instance\n",
    "    p = pyaudio.PyAudio()\n",
    "    buffer = [False] * 10\n",
    "\n",
    "    # stream object to get data from microphone\n",
    "    stream = p.open(\n",
    "        format=FORMAT,\n",
    "        channels=CHANNELS,\n",
    "        rate=SR,\n",
    "        input=True,\n",
    "        output=True,\n",
    "        frames_per_buffer=CHUNK\n",
    "    )\n",
    "\n",
    "    print(\"recording...\")\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(SR / CHUNK * record_seconds)):\n",
    "        # read chunk\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "        \n",
    "        # fetch features\n",
    "        sample = np.frombuffer(data, dtype=np.float32)\n",
    "        if feature_type == \"fft\":\n",
    "            features = np.mean(np.abs(librosa.stft(sample, n_fft=512, hop_length=256, win_length=512)).T, axis=0)\n",
    "        elif feature_type == \"mfcc\":\n",
    "            features = np.mean(librosa.feature.mfcc(y=sample, sr=SR, n_mfcc=40).T, axis=0)\n",
    "        \n",
    "        # make prediction\n",
    "        features = np.expand_dims(features, axis=0)\n",
    "        is_whistle = model.predict(features, verbose=0)[0][0]\n",
    "        \n",
    "        # print current certainty\n",
    "        buffer.pop(0)\n",
    "        buffer.append(is_whistle > .5)\n",
    "        clear_output(wait=True)\n",
    "        print(\"whistle likelihood:\", str((sum(buffer)/len(buffer)) * 100) + \"%\")\n",
    "        \n",
    "        \n",
    "    print(\"finished recording\")\n",
    "\n",
    "    # stop recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # write to file\n",
    "    if write:       \n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(SR)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "        \n",
    "live_detect(\"fft\", 1, True, write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
