{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs & Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import IPython\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "# Training neural networks\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Live detection\n",
    "import pyaudio\n",
    "from IPython.display import clear_output\n",
    "import wave\n",
    "\n",
    "# ms per chunk\n",
    "STEP = 50\n",
    "PATH = \"whistle_dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The chunk processor will get a sample with a feature type, and will utilize these to process said chunk into features. The chunk processor is used in both featurizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def chunk_processor(sample, sample_rate, feature_type, target, false_window = 1, true_window= 1/50):\n",
    "#def chunk_processor(sample, sample_rate, feature_type, target, false_window = 10, true_window= 1/5):\n",
    "def chunk_processor(sample, sample_rate, feature_type, target, false_window = 25, true_window= 1/2):\n",
    "    \n",
    "    # get correct window variable\n",
    "    if target:\n",
    "        window = true_window\n",
    "    else:\n",
    "        window = false_window\n",
    "        \n",
    "    # calculate chunk size\n",
    "    chunk = int((sample_rate / 1000) * STEP)\n",
    "    \n",
    "    # iterate over sample and fetch features\n",
    "    for i in tqdm(range(0, len(sample) - chunk, int(chunk * window)), leave=False):\n",
    "        if feature_type == \"fft\":\n",
    "            chunk_features = np.mean(np.abs(librosa.stft(sample[i:i+chunk], n_fft=512, hop_length=256, win_length=512)).T, axis=0)\n",
    "        elif feature_type == \"mfcc\":\n",
    "            chunk_features = np.mean(librosa.feature.mfcc(y=sample[i:i+chunk], sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        \n",
    "        try:\n",
    "            features = np.append(features, np.array([chunk_features]), axis=0)\n",
    "        except:\n",
    "            features = np.array([chunk_features])\n",
    "            \n",
    "    return features, np.full(len(features), int(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurizer V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Featurizer 1 only uses the whistle, and the segments before and after (same length). This is how a 2:1 label ratio is managed. Sequential samples also have 50% overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old windows were 1/5\n",
    "def build_feature_dataframe_v1(feature_type, denoise=False):\n",
    "    \"\"\"Convert all whistles and small fragments before and after said whistles into features\"\"\"\n",
    "    \n",
    "    # See if csv has been calculated before (saving time)\n",
    "    try:\n",
    "        df = pd.read_csv(\"data_v1_\" + feature_type + \"_\" + str(denoise) + \".csv\", index_col=0)\n",
    "        print(\"Dataframe succesfully loaded from csv!\")\n",
    "        return df\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # get the labels\n",
    "    target = []\n",
    "    with open(PATH + \"whistledb.json\") as json_file:\n",
    "        labels = json.load(json_file)[\"audioFiles\"]\n",
    "        labels = {entry[\"path\"] : entry[\"channels\"][1][\"whistleLabels\"] for entry in labels}\n",
    "    \n",
    "    # iterate over all audiofiles\n",
    "    for file_name in tqdm(os.listdir(PATH)):\n",
    "        # skip json file\n",
    "        if file_name.split(\".\")[-1] != \"wav\":\n",
    "            continue\n",
    "\n",
    "        # load file & meta data\n",
    "        sample, sample_rate = librosa.load(PATH + file_name, sr=None)\n",
    "        if denoise == True:\n",
    "            sample = nr.reduce_noise(y=sample,  y_noise=sample[0:5000], sr=sample_rate)\n",
    "\n",
    "        # for all positive intervals get part before and after aswell and featurize\n",
    "        for times in tqdm(labels[file_name], leave=False):\n",
    "            delta_time = times[\"end\"] - times[\"start\"]\n",
    "            \n",
    "            label = False\n",
    "            for i in range(times[\"start\"]-delta_time, times[\"end\"]+delta_time, delta_time):\n",
    "                if i >= 0 and i + delta_time <= len(sample):\n",
    "                    features, targets = chunk_processor(sample[i:i+delta_time], sample_rate, feature_type, label, \n",
    "                                                        false_window = 1/2, true_window= 1/2)\n",
    "                    label = not(label)\n",
    "                    try:\n",
    "                        out = np.append(out, features, axis=0)\n",
    "                        target = np.append(target, targets)\n",
    "                    except:\n",
    "                        out = features\n",
    "                        target = targets\n",
    "                else:\n",
    "                    print(file_name, i, 'no fit ;(')\n",
    "\n",
    "    # save them in dataframe\n",
    "    df = pd.DataFrame(out)\n",
    "    df=(df-df.min())/(df.max()-df.min())\n",
    "    df.insert(0, \"target\", target)\n",
    "    df.to_csv(\"data_v1_\" + feature_type + \"_\" + str(denoise) + \".csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurizer V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Featurizer 2 utilises two different overlap values. True labels have 1/2 overlap, meaning that sequential samples have 50% overlap. False labels have a overlap value of 25, meaning that after each sample taken 24 are skipped. This insures that a 2:1 label ratio is kept while still taking a more fair representation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_dataframe_v2(feature_type, denoise=False):\n",
    "    \n",
    "    # See if csv has been calculated before (saving time)\n",
    "    try:\n",
    "        df = pd.read_csv(\"data_v2_\" + feature_type + \"_\" + str(denoise) + \".csv\", index_col=0)\n",
    "        print(\"Dataframe succesfully loaded from csv!\")\n",
    "        return df\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # get the labels\n",
    "    target = []\n",
    "    with open(PATH + \"whistledb.json\") as json_file:\n",
    "        labels = json.load(json_file)[\"audioFiles\"]\n",
    "        labels = {entry[\"path\"] : entry[\"channels\"][1][\"whistleLabels\"] for entry in labels}\n",
    "    \n",
    "    # iterate over all audiofiles\n",
    "    for file_name in tqdm(os.listdir(PATH)):\n",
    "        # skip json file\n",
    "        if file_name.split(\".\")[-1] != \"wav\":\n",
    "            continue\n",
    "\n",
    "        # load file & meta data\n",
    "        sample, sample_rate = librosa.load(PATH + file_name, sr=None)\n",
    "        if denoise == True:\n",
    "            sample = nr.reduce_noise(y=sample,  y_noise=sample[0:5000], sr=sample_rate)\n",
    "        \n",
    "        # create time intervals\n",
    "        times_list = [0]\n",
    "        for times in labels[file_name]:\n",
    "            times_list += [times[\"start\"], times[\"end\"]]\n",
    "        if times_list[-1] < len(sample):\n",
    "            times_list.append(len(sample))\n",
    "        \n",
    "        label = False\n",
    "        for i in tqdm(range(len(times_list)-1), leave=False):\n",
    "            features, targets = chunk_processor(sample[times_list[i]:times_list[i+1]], sample_rate, feature_type, label)\n",
    "            label = not(label)\n",
    "            try:\n",
    "                out = np.append(out, features, axis=0)\n",
    "                target = np.append(target, targets)\n",
    "            except:\n",
    "                out = features\n",
    "                target = targets\n",
    "\n",
    "    # save them in dataframe\n",
    "    df = pd.DataFrame(out)\n",
    "    df=(df-df.min())/(df.max()-df.min())\n",
    "    df.insert(0, \"target\", target)\n",
    "    df.to_csv(\"data_v2_\" + feature_type + \"_\" + str(denoise) + \".csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(version, feature_type, denoise):\n",
    "    if version == 1:\n",
    "        return build_feature_dataframe_v1(feature_type, denoise)\n",
    "    elif version == 2:\n",
    "        return build_feature_dataframe_v2(feature_type, denoise)\n",
    "    else:\n",
    "        print(\"invalid version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_data = build_features(1, \"mfcc\", False)\n",
    "print(\"True label ratio:\", round((len(mass_data[mass_data[\"target\"] == 1]) / len(mass_data[\"target\"])) * 100, 1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following code allows for any whistle sample to be extracted in order to check if they are labeled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose recording\n",
    "i = -1\n",
    "fname = os.listdir(PATH)[i]\n",
    "print(fname)\n",
    "\n",
    "with open(PATH + \"whistledb.json\") as json_file:\n",
    "    labels = json.load(json_file)[\"audioFiles\"]\n",
    "    labels = {entry[\"path\"] : entry[\"channels\"][1][\"whistleLabels\"] for entry in labels}\n",
    "print(labels[fname], len(labels[fname]))\n",
    "\n",
    "sample_tts, sr = librosa.load(PATH + fname, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose whistle number\n",
    "i = -1\n",
    "print(os.listdir(PATH))\n",
    "print(labels[fname][i][\"start\"],labels[fname][i][\"end\"])\n",
    "\n",
    "IPython.display.Audio(sample_tts[labels[fname][i][\"start\"]:labels[fname][i][\"end\"]], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomise and split dataframe into X and Y\n",
    "def feature_target_split(df, shuffle=True):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac = 1)\n",
    "    \n",
    "    dataset = df.values\n",
    "    X = dataset[:,1:].astype(float)\n",
    "    \n",
    "    Y = dataset[:,0]\n",
    "    encoder = sklearn.preprocessing.LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "    Y = encoder.transform(Y)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_integrated(X):\n",
    "    inputs = Input(shape= (X.shape[1],))\n",
    "    layer = Dense(128, activation=\"relu\")(inputs)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(layer)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(loss = \"binary_crossentropy\",optimizer = \"adam\",metrics = [\"acc\"])\n",
    "    mc = ModelCheckpoint(\"best_model_whistle.hdf5\", monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "    return model, mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(X_train, X_test, Y_train, Y_test, version, feature_type, denoise, plot=False):\n",
    "    \n",
    "    # model training\n",
    "    model, model_checkpoint = two_layer_integrated(X_train)\n",
    "    history = model.fit(X_train, Y_train ,epochs=500, callbacks=[model_checkpoint], batch_size=32, \n",
    "                        validation_data=(X_test, Y_test))\n",
    "\n",
    "    # load the best model weights\n",
    "    model.load_weights('best_model_whistle.hdf5')\n",
    "    \n",
    "    # save model\n",
    "    model.save(\"model_v\" + str(version) + \"_\" + feature_type + \"_\" + str(denoise) + \".h5\")\n",
    "\n",
    "    # summarize history for loss\n",
    "    if plot:\n",
    "        plt.plot(history.history[\"acc\"], c=\"#181818\")\n",
    "        plt.plot(history.history[\"val_acc\"], c=\"#1ED760\")\n",
    "        plt.title(\"Model accuracy V\" + str(version) + \"_\" + feature_type + \"_\" + str(denoise))\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend([\"Train\", \"Val\"], loc=\"lower right\")\n",
    "        plt.ylim([0.83,1.01])\n",
    "        plt.show()\n",
    "        \n",
    "    return model\n",
    "\n",
    "def train_model(version, feature_type, denoise):\n",
    "    # load data\n",
    "    mass_data = build_features(version, feature_type, denoise)\n",
    "    \n",
    "    # train test split\n",
    "    X, Y = feature_target_split(mass_data)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, \n",
    "                                                        random_state=12, shuffle=True)\n",
    "    \n",
    "    return X_test, Y_test, train(X_train, X_test, Y_train, Y_test, version, feature_type, denoise, plot=True)\n",
    "        \n",
    "\n",
    "X_test, Y_test, model = train_model(2, \"mfcc\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test, [1 if prediction > .5 else 0 for prediction in model.predict(X_test)[:,0]])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])\n",
    "print(\"acc:\", model.evaluate(X_test, Y_test, verbose=0)[1])\n",
    "disp.plot(cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_decompose(version, feature_type, denoise):\n",
    "    # load data\n",
    "    df = build_features(version, feature_type, denoise)\n",
    "    \n",
    "    # pca decomposition\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(df.loc[:, df.columns != \"target\"])\n",
    "    pca_df = pd.DataFrame(data = principalComponents, columns = [\"dim_1\", \"dim_2\"])\n",
    "    pca_df.insert (0, \"target\", df[\"target\"])\n",
    "    \n",
    "    # plot\n",
    "    colors = [\"#181818\", \"#1ED760\"]\n",
    "    for i, label in enumerate(pca_df[\"target\"].unique()):\n",
    "        pca_label = pca_df[pca_df[\"target\"] == label]\n",
    "        plt.scatter(pca_label[\"dim_1\"], pca_label[\"dim_2\"], label = bool(label), alpha=0.3, c = colors[i])\n",
    "    plt.title(\"PCA decomposition V\" + str(version) + \"_\" + feature_type + \"_\" + str(denoise))\n",
    "    plt.xlim([-1,1.5])\n",
    "    plt.ylim([-1,1.5])\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "pca_decompose(2, \"mfcc\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold implementation, written by Paul Boersma\n",
    "def kfold_index(df, k=5):\n",
    "    N = len(df)\n",
    "    minimum_number_of_points_per_slice = N // k\n",
    "    remaining_number_of_points = N % k\n",
    "    starting_point = 0\n",
    "    out = []\n",
    "    for islice in range(0, k):\n",
    "        end_point = starting_point + minimum_number_of_points_per_slice + ( islice < remaining_number_of_points )\n",
    "        out.append((starting_point, end_point))\n",
    "        starting_point = end_point\n",
    "    return out\n",
    "\n",
    "# Run kfold for given featureset\n",
    "def execute_kfold(version, feature_type, denoise, k=5):\n",
    "    acc_train = []\n",
    "    acc_test = []\n",
    "    cm = np.zeros((2,2))\n",
    "    df = build_features(version, feature_type, denoise)\n",
    "    X, Y = feature_target_split(df)\n",
    "    for start, end in kfold_index(df, k):\n",
    "        X_train = np.concatenate((X[:start], X[end:]))\n",
    "        Y_train = np.concatenate((Y[:start], Y[end:]))\n",
    "        X_test = X[start:end]\n",
    "        Y_test = Y[start:end]\n",
    "        \n",
    "        model = train(X_train, X_test, Y_train, Y_test, version, feature_type, denoise)\n",
    "        acc_train.append(model.evaluate(X_train, Y_train, verbose=0)[1])\n",
    "        acc_test.append(model.evaluate(X_test, Y_test, verbose=0)[1])\n",
    "        cm += confusion_matrix(Y_test, [1 if prediction > .5 else 0 for prediction in model.predict(X_test)[:,0]])\n",
    "        \n",
    "    print('Accuracy on train data:', acc_train, np.mean(acc_train))\n",
    "    print('Accuracy on test data:', acc_test, np.mean(acc_test))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])\n",
    "    disp.plot(cmap=\"Greens\", values_format='')\n",
    "\n",
    "#execute_kfold(1, 'fft', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "FORMAT = pyaudio.paFloat32      # audio format (bytes per sample?)\n",
    "CHANNELS = 1                    # single channel for microphone\n",
    "SR = 48000                      # samples per second\n",
    "CHUNK = int((SR / 1000) * STEP) # chunk size\n",
    "WAVE_OUTPUT_FILENAME = \"file.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_detect(feature_type, version, denoise, record_seconds=15, write=False):\n",
    "    # load model\n",
    "    try:\n",
    "        model = load_model(\"model_v\" + str(version) + \"_\" + feature_type + \"_\" + str(denoise) + \".h5\")\n",
    "    except:\n",
    "        _, _, model = train_model(version, feature_type, denoise)\n",
    "    \n",
    "    # pyaudio class instance\n",
    "    p = pyaudio.PyAudio()\n",
    "    buffer = [False] * 10\n",
    "\n",
    "    # stream object to get data from microphone\n",
    "    stream = p.open(\n",
    "        format=FORMAT,\n",
    "        channels=CHANNELS,\n",
    "        rate=SR,\n",
    "        input=True,\n",
    "        output=True,\n",
    "        frames_per_buffer=CHUNK\n",
    "    )\n",
    "\n",
    "    print(\"recording...\")\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(SR / CHUNK * record_seconds)):\n",
    "        # read chunk\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "        \n",
    "        # fetch features\n",
    "        sample = np.frombuffer(data, dtype=np.float32)\n",
    "        if feature_type == \"fft\":\n",
    "            features = np.mean(np.abs(librosa.stft(sample, n_fft=512, hop_length=256, win_length=512)).T, axis=0)\n",
    "        elif feature_type == \"mfcc\":\n",
    "            features = np.mean(librosa.feature.mfcc(y=sample, sr=SR, n_mfcc=40).T, axis=0)\n",
    "        \n",
    "        # make prediction\n",
    "        features = np.expand_dims(features, axis=0)\n",
    "        is_whistle = model.predict(features, verbose=0)[0][0]\n",
    "        \n",
    "        # print current certainty\n",
    "        buffer.pop(0)\n",
    "        buffer.append(is_whistle > .5)\n",
    "        clear_output(wait=True)\n",
    "        print(\"whistle likelihood:\", str((sum(buffer)/len(buffer)) * 100) + \"%\")\n",
    "        \n",
    "        \n",
    "    print(\"finished recording\")\n",
    "\n",
    "    # stop recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # write to file\n",
    "    if write:       \n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(SR)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "        \n",
    "live_detect(\"mfcc\", 2, False, write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
